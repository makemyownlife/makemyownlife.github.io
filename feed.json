{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "勇哥Java实战",
  "home_page_url": "https://javayong.cn/",
  "feed_url": "https://javayong.cn/feed.json",
  "description": "Java 基础、高并发三剑客（缓存、消息队列、分库分表）、实战项目讲解。",
  "favicon": "https://javayong.cn/favicon.ico",
  "items": [
    {
      "title": "聊聊本地缓存和分布式缓存",
      "url": "https://javayong.cn/cache/00localandclustercache.html",
      "id": "https://javayong.cn/cache/00localandclustercache.html",
      "summary": "缓存的世界很广阔，对于应用系统来讲，我们经常将缓存划分为本地缓存和分布式缓存。 本地缓存 ：应用中的缓存组件，缓存组件和应用在同一进程中，缓存的读写非常快，没有网络开销。但各应用或集群的各节点都需要维护自己的单独缓存，无法共享缓存。 分布式缓存：和应用分离的缓存组件或服务，与本地应用隔离，多个应用可直接共享缓存。 1 缓存的本质 我们常常会讲：“加了缓存，我们的系统就会更快” 。",
      "content_html": "<p>缓存的世界很广阔，对于<strong>应用系统</strong>来讲，我们经常将缓存划分为<strong>本地缓存</strong>和<strong>分布式缓存</strong>。</p>\n<p><strong>本地缓存</strong> ：应用中的缓存组件，缓存组件和应用在同一进程中，缓存的读写非常快，没有网络开销。但各应用或集群的各节点都需要维护自己的单独缓存，无法共享缓存。</p>\n<p><strong>分布式缓存</strong>：和应用分离的缓存组件或服务，与本地应用隔离，多个应用可直接共享缓存。</p>\n<h2> 1 缓存的本质</h2>\n<p>我们常常会讲：“加了缓存，我们的系统就会更快” 。</p>\n<p>所谓的“更快”，本质上做到了如下两点：</p>\n<ul>\n<li>\n<p>减小 CPU 消耗</p>\n<p>将原来需要实时计算的内容提前算好、把一些公用的数据进行复用，这可以减少 CPU 消耗，从而提升响应性能。</p>\n</li>\n<li>\n<p>减小 I/O 消耗</p>\n<p>将原来对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问，从而提升响应性能。</p>\n</li>\n</ul>\n<p>假如可以通过增强 CPU、I/O 本身的性能来满足需求的话，<strong>升级硬件往往是更好的解决方案</strong>，即使需要一些额外的投入成本，也通常要优于引入缓存后可能带来的风险。</p>\n<p>从开发角度来说，引入缓存会提高系统复杂度，因为你要考虑缓存的失效、更新、一致性等问题。</p>\n<p>从运维角度来说，缓存会掩盖掉一些缺陷，让问题在更久的时间以后，出现在距离发生现场更远的位置上。</p>\n<p>从安全角度来说，缓存可能泄漏某些保密数据，也是容易受到攻击的薄弱点。</p>\n<p>因此，<strong>缓存是把双刃剑</strong>。</p>\n<h2> 2 本地缓存 JDK Map</h2>\n<p>JDK Map 经常用于缓存实现：</p>\n<ul>\n<li>\n<p>HashMap</p>\n<p>HashMap 是一种基于哈希表的集合类，它提供了快速的插入、查找和删除操作。可以将键值对作为缓存项的存储方式，将键作为缓存项的唯一标识符，值作为缓存项的内容。</p>\n</li>\n<li>\n<p>ConcurrentHashMap</p>\n<p>ConcurrentHashMap 是线程安全的 HashMap，它在多线程环境下可以保证高效的并发读写操作。</p>\n</li>\n<li>\n<p>LinkedHashMap</p>\n<p>LinkedHashMap 是一种有序的 HashMap ，它保留了元素插入的顺序，可以按照插入顺序或者访问顺序进行遍历。</p>\n</li>\n<li>\n<p>TreeMap</p>\n<p>TreeMap 是一种基于红黑树的有序 Map，它可以按照键的顺序进行遍历。</p>\n</li>\n</ul>\n<p>笔者曾经负责艺龙红包系统，<strong>红包活动</strong>就是<strong>存储在</strong> <strong>ConcurrentHashMap</strong> 中 ，通过<strong>定时任务刷新缓存</strong> 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//up-c95ec12a6b7f24b5be368bc5fad03be5bdd.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>核心流程：</p>\n<p>1、红包系统启动后，初始化一个 ConcurrentHashMap 作为红包活动缓存 ；</p>\n<p>2、数据库查询所有的红包活动 , 并将活动信息存储在 Map 中 ;</p>\n<p>3、定时任务每隔 30 秒 ，执行缓存加载方法，刷新缓存。</p>\n<p>为什么红包系统会将红包活动信息存储在本地内存 ConcurrentHashMap 呢 ？</p>\n<ul>\n<li>\n<p>红包系统是高并发应用，快速将请求结果响应给前端，大大提升用户体验；</p>\n</li>\n<li>\n<p>红包活动数量并不多，就算全部放入到 Map 里也不会产生内存溢出的问题；</p>\n</li>\n<li>\n<p>定时任务刷新缓存并不会影响红包系统的业务。</p>\n</li>\n</ul>\n<p>笔者见过很多<strong>单体应用</strong>都使用这种方案，该方案的特点是简洁易用，工程实现也容易 。</p>\n<h2> 3 本地缓存框架</h2>\n<p>虽然使用 JDK Map 能快捷构建缓存，但缓存的功能还是比较孱弱的。</p>\n<p>因为现实场景里，我们可能需要给缓存添加<strong>缓存统计</strong>、<strong>过期失效</strong>、<strong>淘汰策略</strong>等功能。</p>\n<p>于是，<strong>本地缓存框架</strong>应运而生。</p>\n<p>流行的 Java 缓存框架包括： Ehcache , Google Guava ,  Caffeine Cache 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//up-ce94ccdd52ecb8650adc02ecbcb8314e22c.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>下图展示了 Caffeine 框架的使用示例。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//up-7e823491b7efd6f3cc2a370d3acb91c541b.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>虽然本地缓存框架的功能很强大，但是本地缓存的缺陷依然明显。</p>\n<p>1、高并发的场景，<strong>应用重启之后，本地缓存就失效了，系统的负载就比较大</strong>，需要花较长的时间才能恢复；</p>\n<p>2、每个应用节点都会维护自己的单独缓存，<strong>缓存同步比较头疼</strong>。</p>\n<h2> 4 分布式缓存</h2>\n<p>分布式缓存是指将缓存数据分布在多台机器上，以提高缓存容量和并发读写能力的缓存系统。分布式缓存通常由多台机器组成一个集群，每台机器上都运行着相同的缓存服务进程，缓存数据被均匀地分布在集群中的各个节点上。</p>\n<p>Redis 是分布式缓存的首选，甚至我们一提到缓存，很多后端工程师首先想到的就它。</p>\n<p>下图是神州专车订单的 Redis 集群架构 。将 Redis 集群拆分成四个分片，每个分片包含一主一从，主从可以切换。 应用 A 根据不同的缓存 key 访问不同的分片。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//up-3081e4dc2134380f257af5a411382aac0e1.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>与本地缓存相比，分布式缓存具有以下优点：</p>\n<p><strong>1、容量和性能可扩展</strong></p>\n<p>通过增加集群中的机器数量，可以扩展缓存的容量和并发读写能力。同时，缓存数据对于应用来讲都是共享的。</p>\n<p><strong>2、高可用性</strong></p>\n<p>由于数据被分布在多台机器上，即使其中一台机器故障，缓存服务也能继续提供服务。</p>\n<p>但是分布式缓存的缺点同样不容忽视。</p>\n<p><strong>1、网络延迟</strong></p>\n<p>分布式缓存通常需要通过网络通信来进行数据读写，可能会出现网络延迟等问题，相对于本地缓存而言，响应时间更长。</p>\n<p><strong>2、复杂性</strong></p>\n<p>分布式缓存需要考虑序列化、数据分片、缓存大小等问题，相对于本地缓存而言更加复杂。</p>\n<p>笔者曾经也认为无脑上分布式缓存  ，系统就一定更快，但直到一次事故，对于分布式缓存的观念才彻底改变。</p>\n<p>2014年，同事开发了比分直播的系统，所有的请求都是从分布式缓存 Memcached 中获取后直接响应。常规情况下，从缓存中查询数据非常快，但在线用户稍微多一点，整个系统就会特别卡。</p>\n<p>通过 jstat 命令发现 GC 频率极高，几次请求就将新生代占满了，而且 CPU 的消耗都在 GC 线程上。初步判断是缓存值过大导致的，果不其然，缓存大小在 300k 到 500k 左右。</p>\n<p>解决过程还比较波折，分为两个步骤：</p>\n<ol>\n<li><strong>修改新生代大小</strong>，从原来的 2G 修改成 4G，并精简缓存数据大小 (从平均 300k 左右降为 80k 左右)；</li>\n<li>把<strong>缓存拆成两个部分</strong>，第一部分是<strong>全量数据</strong>，第二部分是<strong>增量数据</strong>（数据量很小）。页面第一次请求拉取全量数据，当比分有变化的时候，通过 websocket 推送增量数据。</li>\n</ol>\n<p>经过这次优化，笔者理解到：缓存虽然可以提升整体速度，但是在高并发场景下，缓存对象大小依然是需要关注的点，稍不留神就会产生事故。另外我们也需要合理地控制读取策略，最大程度减少 GC 的频率 , 从而提升整体性能。</p>\n<h2> 5 多级缓存</h2>\n<p>开源中国网站最开始完全是用本地缓存框架 Ehcache 。</p>\n<p>后来随着访问量的激增，出现了一个可怕的问题：“因为 Java 程序更新很频繁，每次更新的时候都要重启。一旦重启后，整个 Ehcache 缓存里的数据都被清掉。重启后若大量访问进来的话，开源中国的数据库基本上很快就会崩掉”。</p>\n<p>于是，开源中国开发了多级缓存框架  <strong>J2Cache</strong>，使用了多级缓存 <strong>Ehcache + Redis</strong> 。</p>\n<p>多级缓存有如下优势：</p>\n<ol>\n<li>离用户越近，速度越快；</li>\n<li>减少分布式缓存查询频率，降低序列化和反序列化的 CPU 消耗；</li>\n<li>大幅度减少网络 IO 以及带宽消耗。</li>\n</ol>\n<p>本地缓存做为一级缓存，分布式缓存做为二级缓存，首先从一级缓存中查询，若能查询到数据则直接返回，否则从二级缓存中查询，若二级缓存中可以查询到数据，则回填到一级缓存中，并返回数据。若二级缓存也查询不到，则从数据源中查询，将结果分别回填到一级缓存，二级缓存中。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//up-15ad6ae5ee11e2033883b25177a7e6864c5.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>2018年，笔者服务的一家电商公司需要进行 app 首页接口的性能优化。笔者花了大概两天的时间完成了整个方案，采取的是两级缓存模式，同时利用了 Guava 的惰性加载机制，整体架构如下图所示：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//510c833e-95e2-4222-9d54-d8f97abc2888.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>缓存读取流程如下：</p>\n<p>1、业务网关刚启动时，本地缓存没有数据，读取 Redis 缓存，如果 Redis 缓存也没数据，则通过 RPC 调用导购服务读取数据，然后再将数据写入本地缓存和 Redis 中；若 Redis 缓存不为空，则将缓存数据写入本地缓存中。</p>\n<p>2、由于步骤1已经对本地缓存预热，后续请求直接读取本地缓存，返回给用户端。</p>\n<p>3、Guava 配置了 refresh 机制，每隔一段时间会调用自定义 LoadingCache 线程池（5个最大线程，5个核心线程）去导购服务同步数据到本地缓存和 Redis 中。</p>\n<p>优化后，性能表现很好，平均耗时在 5ms 左右。最开始我以为出现问题的几率很小，可是有一天晚上，突然发现 app 端首页显示的数据时而相同，时而不同。</p>\n<p>也就是说： 虽然 LoadingCache 线程一直在调用接口更新缓存信息，但是各个 服务器本地缓存中的数据并非完成一致。 说明了两个很重要的点：</p>\n<p>1、惰性加载仍然可能造成多台机器的数据不一致</p>\n<p>2、LoadingCache 线程池数量配置的不太合理,  导致了线程堆积</p>\n<p>最终，我们的解决方案是：</p>\n<p>1、惰性加载结合消息机制来更新缓存数据，也就是：当导购服务的配置发生变化时，通知业务网关重新拉取数据，更新缓存。</p>\n<p>2、适当调大 LoadigCache 的线程池参数，并在线程池埋点，监控线程池的使用情况，当线程繁忙时能发出告警，然后动态修改线程池参数。</p>\n<h2> 6 没有银弹</h2>\n<p><strong>没有银弹</strong>是 Fred Brooks 在 1987 年所发表的一篇关于软件工程的经典论文。</p>\n<p>论文强调真正的银弹并不存在，而所谓的银弹则是指没有任何一项技术或方法可以能让软件工程的生产力在十年内提高十倍。</p>\n<p>通俗来讲：<strong>在技术领域中没有一种通用的解决方案可以解决所有问题</strong>。</p>\n<p>技术本质上是为了解决问题而存在的，每个问题都有其独特的环境和限制条件，没有一种通用的技术或工具可以完美地解决所有问题。</p>\n<p>虽然技术不断发展和进步，但是对于复杂的问题，仍需要结合多种技术和方法，进行系统性的思考和综合性的解决方案设计，才能得到最优解决方案。</p>\n<p>回到文章开头的问题 ，如何说服技术老大用 Redis ？</p>\n<p>假如应用就是一个单体应用，缓存可以不共享，通过定时任务刷新缓存对业务没有影响，而且本地内存可以 Hold 住缓存的对象大小，那么你的技术老大的方案没有问题。</p>\n<p>假如应用业务比较复杂，需要使用缓存提升系统的性能，同时分布式缓存共享的特性对于研发来讲开发更加快捷，Redis 确实是个不错的选择，可以从研发成本、代码维护、人力模型等多个角度和技术老大提出自己的观点。</p>\n<p>总而言之，<strong>在技术领域中，没有银弹</strong>。我们需要不断探索和研究新的技术，但同时也需要认识到技术的局限性，不盲目追求所谓的“银弹”，而是结合具体问题和需求，选择最适合的解决方案。</p>\n",
      "image": "https://www.javayong.cn/pics/temp//up-c95ec12a6b7f24b5be368bc5fad03be5bdd.png",
      "date_published": "2023-11-17T13:31:29.000Z",
      "date_modified": "2023-11-17T13:31:29.000Z",
      "authors": [],
      "tags": [
        "cache"
      ]
    },
    {
      "title": "",
      "url": "https://javayong.cn/googlef80b0a25b49e7dc1.html",
      "id": "https://javayong.cn/googlef80b0a25b49e7dc1.html",
      "summary": "google-site-verification: googlef80b0a25b49e7dc1.html",
      "content_html": "<p>google-site-verification: googlef80b0a25b49e7dc1.html</p>\n",
      "date_published": "2023-11-17T11:08:04.000Z",
      "date_modified": "2023-11-17T11:08:04.000Z",
      "authors": [],
      "tags": []
    },
    {
      "title": "四种强大的JDK本地缓存",
      "url": "https://javayong.cn/cache/01fourJDKlocalcache.html",
      "id": "https://javayong.cn/cache/01fourJDKlocalcache.html",
      "summary": "这篇文章，笔者想聊聊那些在业务系统中较少被使用，但却活跃于中间件或者框架里，强大却又低调的缓存，笔者愿称他们为缓存世界的扫地僧。 1 HashMap/ConcurrentHashMap 配置缓存 HashMap 是一种基于哈希表的集合类，它提供了快速的插入、查找和删除操作。",
      "content_html": "<p>这篇文章，笔者想聊聊那些在业务系统中较少被使用，但却活跃于中间件或者框架里，强大却又低调的缓存，<strong>笔者愿称他们为缓存世界的扫地僧</strong>。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/cachesaodisheng.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 HashMap/ConcurrentHashMap 配置缓存</h2>\n<p>HashMap 是一种基于哈希表的集合类，它提供了快速的插入、查找和删除操作。</p>\n<p>HashMap 是很多程序员接触的第一种缓存 , 因为现实业务场景里，我们可能需要给缓存添加<strong>缓存统计</strong>、<strong>过期失效</strong>、<strong>淘汰策略</strong>等功能，HashMap 的功能就显得孱弱 ，所以 HashMap 在业务系统中使用得并不算多。</p>\n<p>但 <strong>HashMap 在中间件中却是香饽饽</strong>，我们消息中间件 RocketMQ 为例。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/rocketmq架构.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>上图是 RocketMQ 的集群模式 ，Broker 分为 Master 与 Slave，一个 Master 可以对应多个 Slave，但是一个 Slave 只能对应一个 Master 。</p>\n<p>每个 Broker 与 Name Server 集群中的所有节点建立长连接，定时每隔 30 秒注册 <strong>主题的路由信息</strong>到所有 Name Server。</p>\n<p>消息发送者、消息消费者，在同一时间只会连接  Name Server 集群中的一台服务器，并且会每隔 30s 会定时更新 Topic 的路由信息。</p>\n<p>我们可以理解 Name Server 集群的作用就是<strong>注册中心</strong>，注册中心会保存<strong>路由信息</strong>（主题的读写队列数、操作权限等），路由信息就是保存在 <strong>HashMap</strong> 中 。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/rocketmqhash.webp?\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>路由信息通过几个 HashMap 来保存，当 Broker 向 Nameserver 发送心跳包（路由信息），Nameserver 需要对 HashMap 进行数据更新，但我们都知道 HashMap 并不是线程安全的，高并发场景下，容易出现 CPU 100% 问题，所以更新 HashMap 时需要加锁，RocketMQ 使用了 JDK 的读写锁 ReentrantReadWriteLock 。</p>\n<p>下面我们看下路由信息如何更新和读取：</p>\n<p><strong>1、写操作：更新路由信息，操作写锁</strong></p>\n<figure><img src=\"https://javayong.cn/pics/cache/读写锁.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>2、读操作：查询主题信息，操作读锁</strong></p>\n<figure><img src=\"https://javayong.cn/pics/cache/readlock.webp?\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>同时，我们需要注意 Name Server 维护路由信息还需要定时任务的支撑。</p>\n<ul>\n<li>每个 Broker 定时每隔 30 秒注册 <strong>主题的路由信息</strong>到所有 Name Server</li>\n<li>Name Server 定时任务每隔10 秒清除已宕机的 Broker</li>\n</ul>\n<p>我们做一个小小的总结，Name Server 维护路由的模式是： <strong>HashMap + 读写锁 + 定时任务更新</strong>。</p>\n<ul>\n<li>HashMap 作为存储容器</li>\n<li>读写锁控制锁的颗粒度</li>\n<li>定时任务定时更新缓存</li>\n</ul>\n<p>写到这里，我们不禁想到 ConcurrentHashMap  。</p>\n<p>ConcurrentHashMap 可以保证线程安全，JDK1.7 之前使用<strong>分段锁机制</strong>实现，JDK1.8 则使用<strong>数组+链表+红黑树</strong>数据结构和<strong>CAS原子操作</strong>实现。</p>\n<p>Broker 使用不同的 ConcurrentHashMap 分别用来存储消费组、消费进度、消息过滤信息等。</p>\n<p>那么名字服务为什么不使用 ConcurrentHashMap 作为存储容器呢 ？</p>\n<p>最核心的原因在于：路由信息由多个 HashMap 组成，通过每次写操作可能要操作多个对象 ，为了保证其一致性，所以才需要加读写锁。</p>\n<h2> 2 LinkedHashMap 最近最少使用缓存</h2>\n<p>LinkedHashMap 是 HashMap 的子类，但是内部还有一个双向链表维护键值对的顺序，每个键值对既位于哈希表中，也位于双向链表中。</p>\n<p>LinkedHashMap 支持两种顺序<strong>插入顺序 、 访问顺序</strong>。</p>\n<ul>\n<li><strong>插入顺序</strong>：先添加的在前面，后添加的在后面，修改操作并不影响顺序</li>\n<li><strong>访问顺序</strong>：问指的是 get/put 操作，对一个键执行 get/put 操作后，其对应的键值对会移动到链表末尾，所以最末尾的是最近访问的，最开始的是最久没有被访问的，这就是访问顺序。</li>\n</ul>\n<p>LinkedHashMap 经典的用法是作为 LruCache (最近最少使用缓存) ，而 MyBatis 的二级缓存的淘汰机制就是使用的 LinkedHashMap 。</p>\n<p>MyBatis 的二级缓存是使用<strong>责任链</strong>+ <strong>装饰器</strong>的设计模式实现的。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/mybatisjar.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>上图中，装饰器包目录下 Cache 接口有不同的实现类，比如<strong>过期淘汰</strong>、<strong>日志记录</strong>等。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/lrucache.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>LruCache 使用了装饰器模式 ，使用 LinkedHashMap 默认保存 1024 个缓存 key ，当 key 最久未被访问，并且 keyMap 的大小超过 1024 时 ，记录最老的 key ，当下次添加缓存对象时，删除最老的 key。</p>\n<p>使用 LinkedHashMap 重点需要做到<strong>使用访问顺序模式</strong>和<strong>重写 removeEldestEntry 方法</strong>。 因为 LinkedHashMap 并不是线程安全的，Mybatis 二级缓存责任链中 SynchronizedCache 对象可以实现线程安全的对缓存读写。</p>\n<h2> 3 TreeMap 排序对象缓存</h2>\n<p>TreeMap 是一种基于红黑树的有序 Map，它可以按照键的顺序进行遍历。</p>\n<p>TreeMap 有两种应用场景让笔者印象极为深刻 ，他们分别是一致性哈希算法和 RocketMQ 消费快照 。</p>\n<p>本文重点介绍 TreeMap 在一致性哈希算法中的应用。</p>\n<p>一致性哈希（Consistent Hashing）算法被广泛应用于缓存系统、分布式数据库、负载均衡器等分布式系统中，以实现高性能和高可用性。它解决了传统哈希算法在动态环境下扩展性和负载均衡性能的问题。</p>\n<p>一致性哈希的主要优点是在节点增减时，只有少量的数据需要重新映射，因为只有那些直接或间接与新增或删除节点相邻的数据项需要迁移。这大大减少了系统的迁移开销和影响，使得系统更具扩展性和可伸缩性。</p>\n<p>TreeMap 在一致性哈希中可以用作节点/虚拟节点的存储结构，用来维护节点在哈希环上的位置和键的有序性。</p>\n<p><strong>1、我们定义一个 TreeMap 存储节点/虚拟节点 。</strong></p>\n<figure><img src=\"https://javayong.cn/pics/cache/consistenttreemap.png?\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>2、初始化节点</strong></p>\n<p>构造函数包含三个部分：物理节点集合、每个物理节点对应的虚拟节点个数、哈希函数 。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/consistentainit.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们重点看下添加节点逻辑：</p>\n<figure><img src=\"https://javayong.cn/pics/cache/consistentaddnode.png?a=123\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>3、按照 key 查询节点</strong></p>\n<p>添加完节点之后，节点分布类似下图：</p>\n<figure><img src=\"https://javayong.cn/pics/cache/hashring0.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://javayong.cn/pics/cache/consistentroute.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>当需要定位某个 key 属于哪个节点时，先通过哈希函数计算 key 的哈希值，并在环上顺时针方向找到第一个大于等于该哈希值的节点位置。该节点即为数据的归属节点 。</p>\n<p>我们添加一个新的节点 node5 , 从下图中，我们可以看到，影响的范围（深黄色）并不大 ，这也就是一致性哈希算法的优势。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/hashring1.png?\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 4 ByteBuffer 网络编程缓冲池</h2>\n<p>ByteBuffer 是字节缓冲区，主要用于用户读取和缓存字节数据，多用于网络编程、文件 IO 处理等。</p>\n<p>笔者第一次接触 ByteBuffer 是在分库分表中间件 Cobar 中 。在网络编程里，经常需要分配内存，在高并发场景下，性能压力比较大。</p>\n<p>Cobar 抽象了一个 NIOProcessor 类用来处理网络请求，每个处理器初始化的时候都会创建一个缓冲池 BufferPool 。 BufferPool 用于池化 ByteBuffer ，这和我们平常使用的数据库连接池的思路是一致的。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/cobarbufferpool.png?a=1\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>下图展示了缓冲池 BufferPool 的源码：</p>\n<figure><img src=\"https://javayong.cn/pics/cache/cobarbytebuffer.png?b=2\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>缓冲池 BufferPool 的核心功能是<strong>分配缓存</strong>和<strong>回收缓存</strong> ，通过将缓存池化，可以大大提升系统的性能。</p>\n<p>如今 ，Netty 内置了更为强大的内存池化工具 ByteBuf ，我们会在后面的文章里详聊。</p>\n<h2> 5 写到最后</h2>\n<p>这篇文章，笔者总结了四种<strong>强大且低调</strong>的缓存。</p>\n<p>1、HashMap/ConcurrentHashMap 经常用于配置缓存，对于 HashMap 来讲，<strong>HashMap + 读写锁 + 定时任务更新</strong>是常用的模式。而 ConcurrentHashMap 广泛存在于各种中间件，线程安全且灵活易用。</p>\n<p>2、LinkedHashMap 经常被用于创建最近最少使用缓存 LruCache 。推荐学习 Mybatis 二级缓存的设计，它使用<strong>责任链</strong>+ <strong>装饰器</strong>的设计模式，内置 LruCache 的实现就是使用 LinkedHashMap 。</p>\n<p>3、TreeMap 是一种基于红黑树的有序 Map 。TreeMap 在一致性哈希中可以用作节点/虚拟节点的存储结构，用来维护节点在哈希环上的位置和键的有序性。</p>\n<p>4、ByteBuffer 是字节缓冲区，主要用于用户读取和缓存字节数据，多用于网络编程、文件 IO 处理等。分库分表中间件 Cobar 在网络请求处理中，创建了缓冲池 BufferPool 用于池化 ByteBuffer ，从而大大提升系统的性能。</p>\n",
      "image": "https://javayong.cn/pics/cache/cachesaodisheng.png",
      "date_published": "2023-11-16T08:17:07.000Z",
      "date_modified": "2023-11-16T08:17:07.000Z",
      "authors": [],
      "tags": [
        "cache"
      ]
    },
    {
      "title": "聊聊分页列表缓存",
      "url": "https://javayong.cn/cache/02pagelistcache.html",
      "id": "https://javayong.cn/cache/02pagelistcache.html",
      "summary": "开源中国的红薯哥写了很多关于缓存的文章，其中多级缓存思路，分页列表缓存这些知识点给了我很大的启发性。 写这篇文章，我们聊聊分页列表缓存，希望能帮助大家提升缓存技术认知。 1 直接缓存分页列表结果 显而易见，这是最简单易懂的方式。",
      "content_html": "<p>开源中国的红薯哥写了很多关于缓存的文章，其中多级缓存思路，分页列表缓存这些知识点给了我很大的启发性。</p>\n<p>写这篇文章，我们聊聊<strong>分页列表缓存</strong>，希望能帮助大家提升缓存技术认知。</p>\n<h2> 1 直接缓存分页列表结果</h2>\n<p>显而易见，这是最简单易懂的方式。</p>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161536756-1162415241.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们按照不同的分页条件来缓存分页结果 ，伪代码如下：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>这种方案的优点是工程简单，性能也快，但是有一个非常明显的缺陷基因：<strong>列表缓存的颗粒度非常大</strong>。</p>\n<p>假如列表中数据发生增删，为了保证数据的一致性，需要修改分页列表缓存。</p>\n<p>有两种方式 ：</p>\n<p>1、依靠缓存过期来惰性的实现 ，但业务场景必须包容；</p>\n<p>2、使用 Redis 的 keys 找到该业务的分页缓存，执行删除指令。 但 keys 命令对性能影响很大，会导致 Redis 很大的延迟 。</p>\n<h2> 2 查询对象ID列表，再缓存每个对象条目</h2>\n<p>缓存分页结果虽然好用，但缓存的颗粒度太大，保证数据一致性比较麻烦。</p>\n<p>所以我们的目标是<strong>更细粒度的控制缓存</strong> 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161535770-925522893.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们查询出商品分页对象ID列表，然后为每一个商品对象创建缓存 ,  通过商品ID和商品对象缓存聚合成列表返回给前端。</p>\n<p>伪代码如下：<img src=\"https://www.javayong.cn/pics/cache//2487169-20230523161536367-1808772045.png\" alt=\"\"></p>\n<p>核心流程：</p>\n<p><strong>1、从数据库中查询分页 ID 列表</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>对应的 SQL 类似：</p>\n<div class=\"language-sql line-numbers-mode\" data-ext=\"sql\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>2、批量从缓存中获取商品对象</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>假如我们使用本地缓存，直接一条一条从本地缓存中聚合也极快。</p>\n<p>假如我们使用分布式缓存，Redis 天然支持批量查询的命令 ，比如 mget ，hmget 。</p>\n<p><strong>3、组装没有命中的商品ID</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>因为缓存中可能因为过期或者其他原因导致缓存没有命中的情况，所以我们需要找到哪些商品没有在缓存里。</p>\n<p><strong>4、批量从数据库查询未命中的商品信息列表，重新加载到缓存</strong></p>\n<p>首先从数据库里<strong>批量</strong>查询出未命中的商品信息列表 ，请注意是<strong>批量</strong>。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>参数是未命中缓存的商品ID列表，组装成对应的 SQL，这样性能更快 ：</p>\n<div class=\"language-SQL line-numbers-mode\" data-ext=\"SQL\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>然后这些未命中的商品信息存储到缓存里 , 使用 Redis 的 mset 命令。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>5、 遍历商品ID列表，组装对象列表</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>当前方案里，缓存都有命中的情况下，经过两次网络 IO ，第一次数据库查询 IO ，第二次 Redis 查询 IO ,  性能都会比较好。</p>\n<p>所有的操作都是批量操作，就算有缓存没有命中的情况，整体速度也较快。</p>\n<p>”<strong>查询对象ID列表，再缓存每个对象条目</strong>“ 这个方案比较灵活，当我们<strong>查询对象ID列表</strong>，可以不限于数据库，还可以是搜索引擎，Redis 等等。</p>\n<p>下图是开源中国的搜索流程：</p>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161535579-752010347.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>精髓在于：<strong>搜索的分页结果只包含业务对象 ID  ，对象的详细资料需要从缓存 + MySQL 中获取。</strong></p>\n<h2> 3 缓存对象ID列表,同时缓存每个对象条目</h2>\n<p>笔者曾经重构过类似朋友圈的服务，进入班级页面 ，瀑布流的形式展示班级成员的所有动态。</p>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161536234-1479945726.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们使用推模式将每一条动态 ID 存储在 Redis  ZSet 数据结构中 。Redis ZSet 是一种类型为有序集合的数据结构，它由多个有序的唯一的字符串元素组成，每个元素都关联着一个浮点数分值。</p>\n<p>ZSet 使用的是 member -&gt; score 结构 ：</p>\n<ul>\n<li>member : 被排序的标识，也是默认的第二排序维度（ score 相同时，Redis 以 member 的字典序排列）</li>\n<li>score : 被排序的分值，存储类型是 double</li>\n</ul>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161536124-570559847.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>如上图所示：<strong>ZSet 存储动态 ID 列表  ,  member 的值是动态编号 , score 值是创建时间</strong>。</p>\n<p>通过 ZSet 的 <strong>ZREVRANGE 命令</strong>就可以实现分页的效果。</p>\n<p>ZREVRANGE 是 Redis 中用于有序集合（sorted set）的命令之一，它用于按照成员的分数从大到小返回有序集合中的指定范围的成员。</p>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161535893-748949994.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>为了达到分页的效果，传递如下的分页参数 ：</p>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161535058-1294698241.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>通过 ZREVRANGE 命令，我们可以查询出动态 ID 列表。</p>\n<p>查询出动态 ID 列表后，还需要缓存每个动态对象条目，动态对象包含了详情，评论，点赞，收藏这些功能数据 ，我们需要为这些数据提供单独做缓存配置。</p>\n<figure><img src=\"https://www.javayong.cn/pics/cache/2487169-20230523161536578-881577270.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>无论是查询缓存，还是重新写入缓存，为了提升系统性能，批量操作效率更高。</p>\n<p>若**缓存对象结构简单，使用 mget 、hmget 命令；若结构复杂，可以考虑使用 pipleline，Lua 脚本模式 。**笔者选择的批量方案是 Redis 的 pipleline 功能。</p>\n<p>我们再来模拟获取动态分页列表的流程：</p>\n<ol>\n<li>使用 ZSet 的 ZREVRANGE 命令 ，传入分页参数，查询出动态 ID 列表 ；</li>\n<li>传递动态 ID 列表参数，通过 Redis 的 pipleline 功能从缓存中批量获取动态的详情，评论，点赞，收藏这些功能数据 ，组装成列表 。</li>\n</ol>\n<h2> 4 总结</h2>\n<p>本文介绍了实现分页列表缓存的三种方式：</p>\n<ol>\n<li>\n<p>直接缓存分页列表结果</p>\n</li>\n<li>\n<p>查询对象ID列表，只缓存每个对象条目</p>\n</li>\n<li>\n<p>缓存对象ID列表，同时缓存每个对象条目</p>\n</li>\n</ol>\n<p>这三种方式是一层一层递进的，要诀是：</p>\n<p><strong>细粒度的控制缓存</strong>和<strong>批量加载对象</strong>。</p>\n",
      "image": "https://www.javayong.cn/pics/cache/2487169-20230523161536756-1162415241.png",
      "date_published": "2023-11-16T08:17:07.000Z",
      "date_modified": "2023-11-16T13:16:12.000Z",
      "authors": [],
      "tags": [
        "cache"
      ]
    },
    {
      "title": "详解布隆过滤器",
      "url": "https://javayong.cn/cache/05boolfilter.html",
      "id": "https://javayong.cn/cache/05boolfilter.html",
      "summary": "布隆过滤器是一个精巧而且经典的数据结构。 你可能没想到： RocketMQ、 Hbase 、Cassandra 、LevelDB 、RocksDB 这些知名项目中都有布隆过滤器的身影。 对于后端程序员来讲，学习和理解布隆过滤器有很大的必要性。来吧，我们一起品味布隆过滤器的设计之美。 1 缓存穿透",
      "content_html": "<p>布隆过滤器是一个精巧而且经典的数据结构。</p>\n<p>你可能没想到： RocketMQ、 Hbase 、Cassandra 、LevelDB 、RocksDB 这些知名项目中都有布隆过滤器的身影。</p>\n<p>对于后端程序员来讲，学习和理解布隆过滤器有很大的必要性。来吧，我们一起品味布隆过滤器的设计之美。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//gGTKn38KyF.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h1> 1 缓存穿透</h1>\n<p>我们先来看一个商品服务查询详情的接口：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><figure><img src=\"https://www.javayong.cn/pics/temp//szzXnQVHGA.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>假设此商品既不存储在缓存中，也不存在数据库中，则没有办法<strong>回写缓存</strong>，当有类似这样大量的请求访问服务时，数据库的压力就会极大。</p>\n<p>这是一个典型的缓存穿透的场景。</p>\n<p>为了解决这个问题呢，通常我们可以向分布式缓存中写入一个过期时间较短的空值占位，但这样会占用较多的存储空间，性价比不足。</p>\n<p>问题的本质是：\"<strong>如何以极小的代价检索一个元素是否在一个集合中</strong>？\"</p>\n<p>我们的主角<strong>布隆过滤器</strong>出场了，它就能游刃有余的<strong>平衡好时间和空间两种维度</strong>。</p>\n<h1> 2 原理解析</h1>\n<p><strong>布隆过滤器</strong>（英语：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的<strong>二进制向量</strong>和一系列<strong>随机映射函数</strong>。</p>\n<p>布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是<strong>空间效率</strong>和<strong>查询时间</strong>都<strong>远远超过一般的算法</strong>，缺点是有一定的误识别率和删除困难。</p>\n<p>布隆过滤器的原理：当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个位数组中的 K 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：如果这<strong>些点有任何一个 0</strong>，则<strong>被检元素一定不在</strong>；如果<strong>都是 1</strong>，则被检元素<strong>很可能在</strong>。</p>\n<p>简单来说就是准备一个长度为 m 的位数组并初始化所有元素为 0，用 k 个散列函数对元素进行 k 次散列运算跟 len (m) 取余得到 k 个位置并将 m 中对应位置设置为 1。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//Qcb9oB5g1v.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>如上图，位数组的长度是８，散列函数个数是 3，先后保持两个元素ｘ，ｙ。这两个元素都经过三次哈希函数生成三个哈希值，并映射到位数组的不同的位置，并置为1。元素 x 映射到位数组的第０位，第４位，第７位，元素ｙ映射到数组的位数组的第１位，第４位，第６位。</p>\n<p>保存元素 x 后，位数组的第4位被设置为1之后，在处理元素 y 时第4位会被覆盖，同样也会设置为 1。</p>\n<p>当布隆过滤器<strong>保存的元素越多</strong>，<strong>被置为 1 的 bit 位也会越来越多</strong>，元素 x 即便没有存储过，假设哈希函数映射到位数组的三个位都被其他值设置为 1 了，对于布隆过滤器的机制来讲，元素 x 这个值也是存在的，也就是说布隆过滤器<strong>存在一定的误判率</strong>。</p>\n<p><strong>▍ 误判率</strong></p>\n<p>布隆过滤器包含如下四个属性：</p>\n<ul>\n<li>\n<p>k : 哈希函数个数</p>\n</li>\n<li>\n<p>m : 位数组长度</p>\n</li>\n<li>\n<p>n : 插入的元素个数</p>\n</li>\n<li>\n<p>p : 误判率</p>\n</li>\n</ul>\n<p>若位数组长度太小则会导致所有 bit 位很快都会被置为 1 ，那么检索任意值都会返回”可能存在“ ， 起不到过滤的效果。 位数组长度越大，则误判率越小。</p>\n<p>同时，哈希函数的个数也需要考量，哈希函数的个数越大，检索的速度会越慢，误判率也越小，反之，则误判率越高。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//9JhROcXyEi.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>从张图我们可以观察到相同位数组长度的情况下，随着哈希函数的个人的增长，误判率显著的下降。</p>\n<p>误判率 p 的公式是<img src=\"https://www.javayong.cn/pics/temp//NntKce0NiK.webp!large\" alt=\"\"></p>\n<p>1. k 次哈希函数某一 bit 位未被置为 1 的概率为<img src=\"https://www.javayong.cn/pics/temp//AeAm0pE51W.webp!large\" alt=\"\"></p>\n<p>2. 插入 n 个元素后某一 bit 位依旧为 0 的概率为<img src=\"https://www.javayong.cn/pics/temp//JWSFwFmn1w.webp!large\" alt=\"\"></p>\n<p>3. 那么插入 n 个元素后某一 bit 位置为1的概率为<img src=\"https://www.javayong.cn/pics/temp//45NmbP5AEk.webp!large\" alt=\"\">\n4. 整体误判率为 <img src=\"https://www.javayong.cn/pics/temp//786m1xNDFG.webp!large\" alt=\"\">，当 m 足够大时，误判率会越小，该公式约等于<img src=\"https://www.javayong.cn/pics/temp//VsYuYA5bWH.webp!large\" alt=\"\"></p>\n<p>我们会预估布隆过滤器的误判率 p 以及待插入的元素个数 n 分别推导出最合适的位数组长度 m 和 哈希函数个数 k。</p>\n<img src=\"https://www.javayong.cn/pics/temp//up-f6c28a2073b26b6a18f7615b2a34c4fbf98.jpg\" style=\"zoom:43%;\">\n<p><strong>▍ 布隆过滤器支持删除吗</strong></p>\n<p>布隆过滤器其实并不支持删除元素，因为多个元素可能哈希到一个布隆过滤器的同一个位置，如果直接删除该位置的元素，则会影响其他元素的判断。</p>\n<p><strong>▍ 时间和空间效率</strong></p>\n<p>布隆过滤器的空间复杂度为 O(m) ，插入和查询时间复杂度都是 O(k) 。 存储空间和插入、查询时间都不会随元素增加而增大。 空间、时间效率都很高。</p>\n<p><strong>▍哈希函数类型</strong></p>\n<p>Murmur3，FNV 系列和 Jenkins 等非密码学哈希函数适合，因为 Murmur3 算法简单，能够平衡好速度和随机分布，很多开源产品经常选用它作为哈希函数。</p>\n<h1> 3 Guava实现</h1>\n<p>Google Guava是 Google 开发和维护的开源 Java开发库，它包含许多基本的工具类，例如字符串处理、集合、并发工具、I/O和数学函数等等。</p>\n<p><strong>1、添加Maven依赖</strong></p>\n<div class=\"language-xml line-numbers-mode\" data-ext=\"xml\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>2、创建布隆过滤器</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>3、添加数据</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>4、判断数据是否存在</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>接下来，我们查看 Guava 源码中布隆过滤器是如何实现的 ？</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>Guava 的计算位数组长度和哈希次数和原理解析这一节展示的公式保持一致。</p>\n<p>重点来了，Bloom filter 是如何判断元素存在的 ？</p>\n<p>方法名就非常有 google 特色 ， ”<strong>mightContain</strong>“ 的中文表意是：”可能存在“ 。<strong>方法的返回值为 true ，元素可能存在，但若返回值为 false ，元素必定不存在。</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h1> 4 Redisson实现</h1>\n<p>Redisson 是一个用 Java 编写的 Redis 客户端，它实现了分布式对象和服务，包括集合、映射、锁、队列等。Redisson的API简单易用，使得在分布式环境下使用Redis 更加容易和高效。</p>\n<p><strong>1、添加Maven依赖</strong></p>\n<div class=\"language-xml line-numbers-mode\" data-ext=\"xml\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>2、配置 Redisson 客户端</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>3、初始化</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>4、判断数据是否存在</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>好，我们来从源码分析 Redisson 布隆过滤器是如何实现的 ？</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><figure><img src=\"https://www.javayong.cn/pics/temp//nSbowXJ8Dk.webp!large\" alt=\"Bf配置信息\" tabindex=\"0\"><figcaption>Bf配置信息</figcaption></figure>\n<p>Redisson 布隆过滤器初始化的时候，会创建一个 Hash 数据结构的 key ，存储布隆过滤器的4个核心属性。</p>\n<p>那么 Redisson 布隆过滤器如何保存元素呢 ？</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>从源码中，我们发现 Redisson 布隆过滤器操作的对象是 <strong>位图（bitMap）</strong> 。</p>\n<p>在 Redis 中，位图本质上是 string 数据类型，Redis 中一个字符串类型的值最多能存储 512 MB 的内容，每个字符串由多个字节组成，每个字节又由 8 个 Bit 位组成。位图结构正是使用“位”来实现存储的，它通过将比特位设置为 0 或 1来达到数据存取的目的，它存储上限为 <code>2^32 </code>，我们可以使用<code>getbit/setbit</code>命令来处理这个位数组。</p>\n<p>为了方便大家理解，我做了一个简单的测试。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//9GDwxhCukO.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>通过 Redisson API 创建 key 为 <code>mybitset </code>的 位图 ，设置索引 3 ，5，6，8 位为 1 ，右侧的<strong>二进制值</strong>也完全匹配。</p>\n<h1> 5 实战要点</h1>\n<p>通过 Guava 和 Redisson 创建和使用布隆过滤器比较简单，我们下面讨论实战层面的注意事项。</p>\n<p><strong>1、缓存穿透场景</strong></p>\n<p>首先我们需要<strong>初始化</strong>布隆过滤器，然后当用户请求时，判断过滤器中是否包含该元素，若不包含该元素，则直接返回不存在。</p>\n<p>若包含则从缓存中查询数据，若缓存中也没有，则查询数据库并回写到缓存里，最后给前端返回。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//f6Avy1Movi.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>2、元素删除场景</strong></p>\n<p>现实场景，元素不仅仅是只有增加，还存在删除元素的场景，比如说商品的删除。</p>\n<p>原理解析这一节，我们已经知晓：<strong>布隆过滤器其实并不支持删除元素，因为多个元素可能哈希到一个布隆过滤器的同一个位置，如果直接删除该位置的元素，则会影响其他元素的判断</strong>。</p>\n<p>从工程角度来看，<strong>定时重新构建布隆过滤器</strong>这个方案可行也可靠，同时也相对简单。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//wp53mfGqZW.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ol>\n<li>定时任务触发全量商品查询 ;</li>\n<li>将商品编号添加到新的布隆过滤器 ;</li>\n<li>任务完成，修改商品布隆过滤器的映射（从旧 A 修改成 新 B ）;</li>\n<li>商品服务根据布隆过滤器的映射，选择新的布隆过滤器 B进行相关的查询操作 ；</li>\n<li>选择合适的时间点，删除旧的布隆过滤器 A。</li>\n</ol>\n<h1> 6 总结</h1>\n<p><strong>布隆过滤器</strong>是一个很长的<strong>二进制向量</strong>和一系列<strong>随机映射函数</strong>，用于<strong>检索一个元素是否在一个集合中</strong>。</p>\n<p>它的<strong>空间效率</strong>和<strong>查询时间</strong>都<strong>远远超过一般的算法</strong>，但是有一定的误判率 （函数返回 true , 意味着元素可能存在，函数返回 false ，元素必定不存在）。</p>\n<p>布隆过滤器的四个核心属性：</p>\n<ul>\n<li>\n<p>k : 哈希函数个数</p>\n</li>\n<li>\n<p>m : 位数组长度</p>\n</li>\n<li>\n<p>n : 插入的元素个数</p>\n</li>\n<li>\n<p>p : 误判率</p>\n</li>\n</ul>\n<p>Java 世界里 ，通过 Guava 和 Redisson 创建和使用布隆过滤器非常简单。</p>\n<p>布隆过滤器无法删除元素，但我们可以通过<strong>定时重新构建布隆过滤器</strong>方案实现删除元素的效果。</p>\n<p>为什么这么多的开源项目中使用布隆过滤器 ？</p>\n<p>因为它的设计精巧且简洁，工程上实现非常容易，效能高，虽然有一定的误判率，但软件设计不就是要 trade off 吗 ？</p>\n<hr>\n<p>参考资料：</p>\n<blockquote>\n<p>https://hackernoon.com/probabilistic-data-structures-bloom-filter-5374112a7832</p>\n</blockquote>\n",
      "image": "https://www.javayong.cn/pics/temp//gGTKn38KyF.webp!large",
      "date_published": "2023-11-16T08:17:07.000Z",
      "date_modified": "2023-11-17T07:53:52.000Z",
      "authors": [],
      "tags": [
        "cache"
      ]
    },
    {
      "title": "聊聊 Redis 事务",
      "url": "https://javayong.cn/cache/07Redistransaction.html",
      "id": "https://javayong.cn/cache/07Redistransaction.html",
      "summary": "准确的讲，Redis 事务包含两种模式 : 事务模式 和 Lua 脚本。 先说结论： Redis 的事务模式具备如下特点： 保证隔离性； 无法保证持久性； 具备了一定的原子性，但不支持回滚； 一致性的概念有分歧，假设在一致性的核心是约束的语意下，Redis 的事务可以保证一致性。 但 Lua 脚本更具备实用场景，它是另一种形式的事务，他具备一定的原子性，但脚本报错的情况下，事务并不会回滚。Lua 脚本可以保证隔离性，而且可以完美的支持后面的步骤依赖前面步骤的结果。",
      "content_html": "<p>准确的讲，Redis 事务包含两种模式 : <strong>事务模式</strong> 和 <strong>Lua 脚本</strong>。</p>\n<p>先说结论：</p>\n<p>Redis 的事务模式具备如下特点：</p>\n<ul>\n<li>保证隔离性；</li>\n<li>无法保证持久性；</li>\n<li>具备了一定的原子性，但不支持回滚；</li>\n<li>一致性的概念有分歧，假设在一致性的核心是约束的语意下，Redis 的事务可以保证一致性。</li>\n</ul>\n<p>但 Lua 脚本更具备实用场景，它是另一种形式的事务，他具备一定的原子性，但脚本报错的情况下，事务并不会回滚。Lua 脚本可以保证隔离性，而且可以完美的支持<strong>后面的步骤依赖前面步骤的结果</strong>。</p>\n<p><strong>Lua 脚本模式的身影几乎无处不在，比如分布式锁、延迟队列、抢红包等场景。</strong></p>\n<h2> 1 事务原理</h2>\n<p>Redis 的事务包含如下命令：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">序号</th>\n<th style=\"text-align:left\">命令及描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">MULTI 标记一个事务块的开始。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">EXEC 执行所有事务块内的命令。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">DISCARD 取消事务，放弃执行事务块内的所有命令。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">WATCH key [key ...] 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">UNWATCH 取消 WATCH 命令对所有 key 的监视。</td>\n</tr>\n</tbody>\n</table>\n<p>事务包含三个阶段：</p>\n<ol>\n<li>事务开启，使用 MULTI , 该命令标志着执行该命令的客户端从非事务状态切换至事务状态 ；</li>\n<li>命令入队，MULTI 开启事务之后，客户端的命令并不会被立即执行，而是放入一个事务队列 ；</li>\n<li>执行事务或者丢弃。如果收到 EXEC 的命令，事务队列里的命令将会被执行 ，如果是 DISCARD 则事务被丢弃。</li>\n</ol>\n<p>下面展示一个事务的例子。</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>这里有一个疑问？在开启事务的时候，Redis key 可以被修改吗？</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//zgcHEZMogT.webp!large\" alt=\"img\" tabindex=\"0\"><figcaption>img</figcaption></figure>\n<p><strong>在事务执行 EXEC 命令之前 ，Redis key 依然可以被修改</strong>。</p>\n<p>在事务开启之前，我们可以 watch 命令监听 Redis key 。在事务执行之前，我们修改 key 值 ，事务执行失败，返回 <strong>nil</strong> 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//s5X2lsfqGT.webp!large\" alt=\"img\" tabindex=\"0\"><figcaption>img</figcaption></figure>\n<p>通过上面的例子，watch 命令可以<strong>实现类似乐观锁的效果</strong> 。</p>\n<h1> 2 事务的ACID</h1>\n<h2> 2.1 原子性</h2>\n<p>原子性是指：一个事务中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。</p>\n<p>第一个例子：</p>\n<p>在执行 EXEC 命令前，客户端发送的操作命令错误，比如：语法错误或者使用了不存在的命令。</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>在这个例子中，我们使用了不存在的命令，导致入队失败，整个事务都将无法执行 。</p>\n<p>第二个例子：</p>\n<p>事务操作入队时，命令和操作的数据类型不匹配 ，入队列正常，但执行 EXEC 命令异常 。</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>这个例子里，Redis 在执行 EXEC 命令时，如果出现了错误，Redis 不会终止其它命令的执行，事务也不会因为某个命令执行失败而回滚 。</p>\n<p>综上，我对 Redis 事务原子性的理解如下：</p>\n<ol>\n<li>命令入队时报错， 会放弃事务执行，保证原子性；</li>\n<li>命令入队时正常，执行 EXEC 命令后报错，不保证原子性；</li>\n</ol>\n<p>也就是：<strong>Redis 事务在特定条件下，才具备一定的原子性</strong> 。</p>\n<h2> 2.2 隔离性</h2>\n<p>数据库的隔离性是指：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</p>\n<p>事务隔离分为不同级别 ，分别是：</p>\n<ul>\n<li>未提交读（read uncommitted）</li>\n<li>提交读（read committed）</li>\n<li>可重复读（repeatable read）</li>\n<li>串行化（serializable）</li>\n</ul>\n<p>首先，需要明确一点：Redis 并没有事务隔离级别的概念。这里我们讨论 Redis 的隔离性是指：<strong>并发场景下，事务之间是否可以做到互不干扰</strong>。</p>\n<p>我们可以将事务执行可以分为 <strong>EXEC 命令执行前</strong>和 <strong>EXEC 命令执行后</strong>两个阶段，分开讨论。</p>\n<ol>\n<li>EXEC 命令执行前</li>\n</ol>\n<p>在事务原理这一小节，我们发现在事务执行之前 ，Redis key 依然可以被修改。此时，可以使用 <strong>WATCH 机制</strong>来实现乐观锁的效果。</p>\n<ol>\n<li>EXEC 命令执行后</li>\n</ol>\n<p>因为 Redis 是单线程执行操作命令， EXEC 命令执行后，Redis 会保证命令队列中的所有命令执行完 。 这样就可以保证事务的隔离性。</p>\n<h2> 2.3 持久性</h2>\n<p>数据库的持久性是指 ：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p>\n<p>Redis 的数据是否持久化取决于 Redis 的持久化配置模式 。</p>\n<ol>\n<li>没有配置 RDB 或者 AOF ，事务的持久性无法保证；</li>\n<li>使用了 RDB模式，在一个事务执行后，下一次的 RDB 快照还未执行前，如果发生了实例宕机，事务的持久性同样无法保证；</li>\n<li>使用了 AOF 模式；AOF 模式的三种配置选项 no 、everysec 都会存在数据丢失的情况  。always 可以保证事务的持久性，但因为性能太差，在生产环境一般不推荐使用。</li>\n</ol>\n<p>综上，<strong>redis 事务的持久性是无法保证的</strong> 。</p>\n<h2> 2.4 一致性</h2>\n<p>一致性的概念一直很让人困惑，在我搜寻的资料里，有两类不同的定义。</p>\n<ol>\n<li>维基百科</li>\n</ol>\n<p>我们先看下维基百科上一致性的定义：</p>\n<blockquote>\n<p>Consistency ensures that a transaction can only bring the database from one valid state to another, maintaining database invariants: any data written to the database must be valid according to all defined rules, including constraints, cascades, triggers, and any combination thereof. This prevents database corruption by an illegal transaction, but does not guarantee that a transaction is correct. Referential integrity guarantees the primary key – foreign key relationship.</p>\n</blockquote>\n<p>在这段文字里，一致性的核心是“<strong>约束</strong>”，“<strong>any data written to the database must be valid according to all defined rules</strong> ”。</p>\n<p>如何理解约束？这里引用知乎问题 <strong>如何理解数据库的内部一致性和外部一致性</strong>，蚂蚁金服 OceanBase 研发专家韩富晟回答的一段话：</p>\n<blockquote>\n<p>“约束”由数据库的使用者告诉数据库，使用者要求数据一定符合这样或者那样的约束。当数据发生修改时，数据库会检查数据是否还符合约束条件，如果约束条件不再被满足，那么修改操作不会发生。</p>\n<p>关系数据库最常见的两类约束是“唯一性约束”和“完整性约束”，表格中定义的主键和唯一键都保证了指定的数据项绝不会出现重复，表格之间定义的参照完整性也保证了同一个属性在不同表格中的一致性。</p>\n<p>“ Consistency in ACID ”是如此的好用，以至于已经融化在大部分使用者的血液里了，使用者会在表格设计的时候自觉的加上需要的约束条件，数据库也会严格的执行这个约束条件。</p>\n</blockquote>\n<p>所以<strong>事务的一致性和预先定义的约束有关，保证了约束即保证了一致性</strong>。</p>\n<p>我们细细品一品这句话： <strong>This prevents database corruption by an illegal transaction, but does not guarantee that a transaction is correct</strong>。</p>\n<p>写到这里可能大家还是有点模糊，我们举经典<strong>转账</strong>的案例。</p>\n<p>我们开启一个事务，张三和李四账号上的初始余额都是1000元，并且余额字段没有任何约束。张三给李四转账1200元。张三的余额更新为 -200 ， 李四的余额更新为2200。</p>\n<p>从应用层面来看，这个事务明显不合法，因为现实场景中，用户余额不可能小于 0 ， 但是它完全遵循数据库的约束，所以从数据库层面来看，这个事务依然保证了一致性。</p>\n<p>Redis 的事务一致性是指：Redis 事务在执行过程中符合数据库的约束，没有包含非法或者无效的错误数据。</p>\n<p>我们分三种异常场景分别讨论：</p>\n<ol>\n<li>执行 EXEC 命令前，客户端发送的操作命令错误，事务终止，数据保持一致性；</li>\n<li>执行 EXEC 命令后，命令和操作的数据类型不匹配，错误的命令会报错，但事务不会因为错误的命令而终止，而是会继续执行。正确的命令正常执行，错误的命令报错，从这个角度来看，数据也可以保持一致性；</li>\n<li>执行事务的过程中，Redis 服务宕机。这里需要考虑服务配置的持久化模式。\n<ul>\n<li>无持久化的内存模式：服务重启之后，数据库没有保持数据，因此数据都是保持一致性的；</li>\n<li>RDB / AOF 模式： 服务重启后，Redis 通过 RDB / AOF 文件恢复数据，数据库会还原到一致的状态。</li>\n</ul>\n</li>\n</ol>\n<p>综上所述，<strong>在一致性的核心是约束的语意下，Redis 的事务可以保证一致性</strong>。</p>\n<ol>\n<li>《设计数据密集型应用》</li>\n</ol>\n<p>这本书是分布式系统入门的神书。在事务这一章节有一段关于 ACID 的解释：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//zOQBAJrpdO.webp!large\" alt=\"img\" tabindex=\"0\"><figcaption>img</figcaption></figure>\n<blockquote>\n<p>Atomicity, isolation, and durability are properties of the database,whereas consistency (in the ACID sense) is a property of the application. The application may rely on the database’s atomicity and isolation properties in order to achieve consistency, but it’s not up to the database alone. Thus, the letter C doesn’t really belong in ACID.</p>\n</blockquote>\n<p>原子性，隔离性和持久性是数据库的属性，而一致性（在 ACID 意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离属性来实现一致性，但这并不仅取决于数据库。因此，字母 C 不属于 ACID 。</p>\n<p>很多时候，我们一直在纠结的一致性，其实就是指<strong>符合现实世界的一致性</strong>，现实世界的一致性才是事务追求的最终目标。</p>\n<p>为了实现现实世界的一致性，需要满足如下几点：</p>\n<ol>\n<li>保证原子性，持久性和隔离性，如果这些特征都无法保证，那么事务的一致性也无法保证；</li>\n<li>数据库本身的约束，比如字符串长度不能超过列的限制或者唯一性约束；</li>\n<li>业务层面同样需要进行保障 。</li>\n</ol>\n<h2> 2.5 事务特点</h2>\n<p>我们通常称 Redis 为内存数据库 ,  不同于传统的关系数据库，为了提供了更高的性能，更快的写入速度，在设计和实现层面做了一些平衡，并不能完全支持事务的 ACID。</p>\n<p>Redis 的事务具备如下特点：</p>\n<ul>\n<li>保证隔离性；</li>\n<li>无法保证持久性；</li>\n<li>具备了一定的原子性，但不支持回滚；</li>\n<li>一致性的概念有分歧，假设在一致性的核心是约束的语意下，Redis 的事务可以保证一致性。</li>\n</ul>\n<p>从工程角度来看，假设事务操作中每个步骤需要依赖上一个步骤返回的结果，则需要通过 watch 来实现乐观锁 。</p>\n<h1> 3 Lua 脚本</h1>\n<h2> 3.1 简介</h2>\n<figure><img src=\"https://www.javayong.cn/pics/temp//0g0mSCwReL.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>Lua 由标准 C 编写而成，代码简洁优美，几乎在所有操作系统和平台上都可以编译，运行。Lua 脚本可以很容易的被 C/C ++ 代码调用，也可以反过来调用 C/C++ 的函数，这使得 Lua 在应用程序中可以被广泛应用。</p>\n<p>Lua 脚本在游戏领域大放异彩，大家耳熟能详的《大话西游II》，《魔兽世界》都大量使用 Lua 脚本。Java 后端工程师接触过的 api 网关，比如 <strong>Openresty</strong> ，<strong>Kong</strong> 都可以看到 Lua 脚本的身影。</p>\n<p>从 Redis 2.6.0 版本开始， Redis内置的 Lua 解释器，可以实现在 Redis 中运行 Lua 脚本。</p>\n<p>使用 Lua 脚本的好处 ：</p>\n<ul>\n<li>减少网络开销。将多个请求通过脚本的形式一次发送，减少网络时延。</li>\n<li>原子操作。Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。</li>\n<li>复用。客户端发送的脚本会永久存在 Redis 中，其他客户端可以复用这一脚本而不需要使用代码完成相同的逻辑。</li>\n</ul>\n<p>Redis Lua 脚本常用命令：</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>命令及描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>EVAL script numkeys key [key ...] arg [arg ...] 执行 Lua 脚本。</td>\n</tr>\n<tr>\n<td>2</td>\n<td>EVALSHA sha1 numkeys key [key ...] arg [arg ...] 执行 Lua 脚本。</td>\n</tr>\n<tr>\n<td>3</td>\n<td>SCRIPT EXISTS script [script ...] 查看指定的脚本是否已经被保存在缓存当中。</td>\n</tr>\n<tr>\n<td>4</td>\n<td>SCRIPT FLUSH 从脚本缓存中移除所有脚本。</td>\n</tr>\n<tr>\n<td>5</td>\n<td>SCRIPT KILL 杀死当前正在运行的 Lua 脚本。</td>\n</tr>\n<tr>\n<td>6</td>\n<td>SCRIPT LOAD script 将脚本 script 添加到脚本缓存中，但并不立即执行这个脚本。</td>\n</tr>\n</tbody>\n</table>\n<h2> 3.2 EVAL 命令</h2>\n<p>命令格式：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>说明：</p>\n<ul>\n<li><code>script</code>是第一个参数，为 Lua 5.1脚本；</li>\n<li>第二个参数<code>numkeys</code>指定后续参数有几个 key；</li>\n<li><code>key [key ...]</code>，是要操作的键，可以指定多个，在 Lua 脚本中通过<code>KEYS[1]</code>, <code>KEYS[2]</code>获取；</li>\n<li><code>arg [arg ...]</code>，参数，在 Lua 脚本中通过<code>ARGV[1]</code>, <code>ARGV[2]</code>获取。</li>\n</ul>\n<p>简单实例：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>下面演示下 Lua 如何调用 Redis 命令 ，通过<code>redis.call()</code>来执行了 Redis 命令 。</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> 3.3 EVALSHA 命令</h2>\n<p>使用 EVAL 命令每次请求都需要传输 Lua 脚本 ，若 Lua 脚本过长，不仅会消耗网络带宽，而且也会对 Redis 的性能造成一定的影响。</p>\n<p>思路是先将 Lua 脚本先缓存起来 ,  返回给客户端 Lua 脚本的 sha1 摘要。 客户端存储脚本的 sha1 摘要 ，每次请求执行 EVALSHA  命令即可。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//zokNNe0Swx.webp!large\" alt=\"img\" tabindex=\"0\"><figcaption>img</figcaption></figure>\n<p>EVALSHA  命令基本语法如下：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>实例如下：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h1> 4 事务 VS Lua 脚本</h1>\n<blockquote>\n<p>从定义上来说， <strong>Redis 中的脚本本身就是一种事务</strong>， 所以任何在事务里可以完成的事， 在脚本里面也能完成。 并且一般来说， 使用<strong>脚本要来得更简单，并且速度更快</strong>。</p>\n<p>因为脚本功能是 Redis 2.6 才引入的， 而事务功能则更早之前就存在了， 所以 Redis 才会同时存在两种处理事务的方法。</p>\n<p>不过<strong>我们并不打算在短时间内就移除事务功能</strong>， 因为事务提供了一种即使不使用脚本， 也可以避免竞争条件的方法， 而且事务本身的实现并不复杂。</p>\n<p>--  https://redis.io/</p>\n</blockquote>\n<p>Lua 脚本是另一种形式的事务，他具备一定的原子性，但脚本报错的情况下，事务并不会回滚。Lua 脚本可以保证隔离性，而且可以完美的支持<strong>后面的步骤依赖前面步骤的结果</strong>。</p>\n<p><strong>Lua 脚本模式的身影几乎无处不在，比如分布式锁、延迟队列、抢红包等场景。</strong></p>\n<p>不过在编写 Lua 脚本时，要注意如下两点：</p>\n<ol>\n<li>为了避免 Redis 阻塞，Lua 脚本业务逻辑不能过于复杂和耗时；</li>\n<li>仔细检查和测试 Lua 脚本 ，因为执行 Lua 脚本具备一定的原子性，不支持回滚。</li>\n</ol>\n",
      "image": "https://www.javayong.cn/pics/temp//zgcHEZMogT.webp!large",
      "date_published": "2023-11-16T08:17:07.000Z",
      "date_modified": "2023-11-17T07:53:52.000Z",
      "authors": [],
      "tags": [
        "cache"
      ]
    },
    {
      "title": "1 缓存穿透",
      "url": "https://javayong.cn/cache/08cacherisk.html",
      "id": "https://javayong.cn/cache/08cacherisk.html",
      "summary": "1 缓存穿透 2 缓存击穿 3 缓存雪崩 缓存雪崩指的是因为某些原因导致缓存中大量的数据同时失效或过期，导致后续请求都落到数据源上，令数据源在短时间内压力剧增。 为什么会出现缓存大量数据同时失效或者过期呢？ 1、大量缓存数据同时过期",
      "content_html": "<figure><img src=\"https://javayong.cn/pics/cache/cacherisk.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h1> 1 缓存穿透</h1>\n<h1> 2 缓存击穿</h1>\n<h1> 3 缓存雪崩</h1>\n<p>缓存雪崩指的是因为某些原因导致缓存中大量的数据同时失效或过期，导致后续请求都落到数据源上，令数据源在短时间内压力剧增。</p>\n<p>为什么会出现缓存大量数据同时失效或者过期呢？</p>\n<p><strong>1、大量缓存数据同时过期</strong></p>\n<p><strong>2、缓存服务出现故障</strong></p>\n<p>出现这种情况，往往是系统有专门的缓存预热功能，也可能大量公共数据是由某一次冷操作加载的，这样都可能出现由此载入缓存的大批数据具有相同的过期时间，在同一时刻一起失效。</p>\n<p>还有一种情况是缓存服务由于某些原因崩溃后重启，此时也会造成大量数据同时失效，这种现象被称为缓存雪崩。要避免缓存雪崩问题，通常会采取下面的三种办法：</p>\n<p>解决方案通常包括使用分布式缓存部署、设置不同的过期时间、应用程序限流等措施来避免缓存失效时间集中在同一时间段，以及使用缓存预热和自动刷新机制等手段来减轻缓存压力。</p>\n<ol>\n<li>提升缓存系统可用性，建设分布式缓存的集群。</li>\n<li>启用透明多级缓存，各个服务节点一级缓存中的数据通常会具有不一样的加载时间，也就分散了它们的过期时间。</li>\n<li>将缓存的生存期从固定时间改为一个时间段内的随机时间，譬如原本是一个小时过期，那可以缓存不同数据时，设置生存期为 55 分钟到 65 分钟之间的某个随机时间。</li>\n</ol>\n<h1> 4 缓存污染</h1>\n",
      "image": "https://javayong.cn/pics/cache/cacherisk.png",
      "date_published": "2023-11-16T08:17:07.000Z",
      "date_modified": "2023-11-16T08:17:07.000Z",
      "authors": [],
      "tags": []
    },
    {
      "title": "品味Spring Cache设计之美",
      "url": "https://javayong.cn/cache/09SpringCache.html",
      "id": "https://javayong.cn/cache/09SpringCache.html",
      "summary": "最近负责教育类产品的架构工作，两位研发同学建议：“团队封装的Redis客户端可否适配Spring Cache，这样加缓存就会方便多了” 。 于是边查阅文档边实战，收获颇丰，写这篇文章，想和大家分享笔者学习的过程，一起品味Spring Cache设计之美。",
      "content_html": "<p>最近负责教育类产品的架构工作，两位研发同学建议：“团队封装的<strong>Redis</strong>客户端可否适配<strong>Spring Cache</strong>，这样加缓存就会方便多了” 。</p>\n<p>于是边查阅文档边实战，收获颇丰，写这篇文章，想和大家分享笔者学习的过程，一起品味Spring Cache设计之美。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//RK8gWPf7o2.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 硬编码</h2>\n<p>在学习Spring Cache之前，笔者经常会硬编码的方式使用缓存。</p>\n<p>举个例子，为了提升用户信息的查询效率，我们对用户信息使用了缓存，示例代码如下：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>相信很多同学都写过类似风格的代码，这种风格符合面向过程的编程思维，非常容易理解。但它也有一些缺点：</p>\n<ol>\n<li>\n<p>代码不够优雅。业务逻辑有四个典型动作：<strong>存储</strong>，<strong>读取</strong>，<strong>修改</strong>，<strong>删除</strong>。每次操作都需要定义缓存Key ，调用缓存命令的API，产生较多的<strong>重复代码</strong>；</p>\n</li>\n<li>\n<p>缓存操作和业务逻辑之间的代码<strong>耦合度高</strong>，对业务逻辑有较强的侵入性。</p>\n<p>侵入性主要体现如下两点：</p>\n<ul>\n<li>开发联调阶段，需要去掉缓存，只能注释或者临时删除缓存操作代码，也容易出错；</li>\n<li>某些场景下，需要更换缓存组件，每个缓存组件有自己的API，更换成本颇高。</li>\n</ul>\n</li>\n</ol>\n<h2> 2 缓存抽象</h2>\n<p>首先需要明确一点：Spring Cache不是一个具体的缓存实现方案，而是一个对(<strong>Cache Abstraction</strong>)。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//ZewikIryyK.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h3> 2.1 Spring AOP</h3>\n<p>Spring AOP是基于代理模式（<strong>proxy-based</strong>）。</p>\n<p>通常情况下，定义一个对象，调用它的方法的时候，方法是直接被调用的。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><figure><img src=\"https://www.javayong.cn/pics/temp//9PtqLGrXss.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>将代码做一些调整，pojo对象的引用修改成代理类。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><figure><img src=\"https://www.javayong.cn/pics/temp//y2L0WUBAkn.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>调用pojo的foo方法的时候，实际上是动态生成的代理类调用foo方法。</p>\n<p>代理类在方法调用前可以获取方法的参数，当调用方法结束后，可以获取调用该方法的返回值，通过这种方式就可以实现缓存的逻辑。</p>\n<h3> 2.2 缓存声明</h3>\n<p>缓存声明，也就是标识需要缓存的方法以及<strong>缓存策略</strong>。</p>\n<p>Spring Cache 提供了五个注解。</p>\n<ul>\n<li>@Cacheable：根据方法的请求参数对其结果进行缓存，下次同样的参数来执行该方法时可以直接从缓存中获取结果，而不需要再次执行该方法；</li>\n<li>@CachePut：根据方法的请求参数对其结果进行缓存，它每次都会触发真实方法的调用；</li>\n<li>@CacheEvict：根据一定的条件删除缓存；</li>\n<li>@Caching：组合多个缓存注解；</li>\n<li>@CacheConfig：类级别共享缓存相关的公共配置。</li>\n</ul>\n<p>我们重点讲解：@Cacheable，@CachePut，@CacheEvict三个核心注解。</p>\n<h4> 2.2.1 @Cacheable注解</h4>\n<p>@Cacheble注解表示这个方法有了缓存的功能。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>上面的代码片段里，<code>getUserById</code>方法和缓存<code>user_cache</code> 关联起来，若方法返回的User对象不为空，则缓存起来。第二次相同参数userId调用该方法的时候，直接从缓存中获取数据，并返回。</p>\n<p><strong>▍ 缓存key的生成</strong></p>\n<p>我们都知道，缓存的本质是<code>key-value</code>存储模式，每一次方法的调用都需要生成相应的Key, 才能操作缓存。</p>\n<p>通常情况下，@Cacheable有一个属性key可以直接定义缓存key，开发者可以使用<a href=\"https://docs.spring.io/spring-framework/docs/4.3.x/spring-framework-reference/html/expressions.html\" target=\"_blank\" rel=\"noopener noreferrer\">SpEL</a>语言定义key值。</p>\n<p>若没有指定属性key，缓存抽象提供了 <code>KeyGenerator</code>来生成key ，默认的生成器代码见下图：\n<img src=\"https://www.javayong.cn/pics/temp//C4vvh1Bv7s.webp!large\" alt=\"\"></p>\n<p>它的算法也很容易理解：</p>\n<ul>\n<li>如果没有参数，则直接返回<strong>SimpleKey.EMPTY</strong>；</li>\n<li>如果只有一个参数，则直接返回该参数；</li>\n<li>若有多个参数，则返回包含多个参数的<strong>SimpleKey</strong>对象。</li>\n</ul>\n<p>当然Spring Cache也考虑到需要自定义Key生成方式，需要我们实现<code>org.springframework.cache.interceptor.KeyGenerator</code> 接口。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>然后指定@Cacheable的keyGenerator属性。</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>▍ 缓存条件</strong></p>\n<p>有的时候，方法执行的结果是否需要缓存，依赖于方法的参数或者方法执行后的返回值。</p>\n<p>注解里可以通过<code>condition</code>属性，通过Spel表达式返回的结果是true 还是false 判断是否需要缓存。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>上面的代码片段里，当参数的长度小于32，方法执行的结果才会缓存。</p>\n<p>除了condition，<code>unless</code>属性也可以决定结果是否缓存，不过是在执行方法后。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>上面的代码片段里，当返回的结果为null则不缓存。</p>\n<h4> 2.2.2 @CachePut注解</h4>\n<p>@CachePut注解作用于缓存需要被更新的场景，和 @Cacheable 非常相似，但被注解的方法每次都会被执行。</p>\n<p>返回值是否会放入缓存，依赖于condition和unless，默认情况下结果会存储到缓存。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>当调用updateUser方法时，每次方法都会被执行，但是因为unless属性每次都是true，所以并没有将结果缓存。当去掉unless属性，则结果会被缓存。</p>\n<h4> 2.2.3 @CacheEvict注解</h4>\n<p>@CacheEvict 注解的方法在调用时会从缓存中移除已存储的数据。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>当调用deleteUserById方法完成后，缓存key等于参数id的缓存会被删除，而且方法的返回的类型是Void ，这和@Cacheable明显不同。</p>\n<h3> 2.3 缓存配置</h3>\n<p>Spring Cache是一个对，它提供了多种存储集成。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//OjMqsOn5dA.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>要使用它们，需要简单地声明一个适当的<code>CacheManager</code> - 一个控制和管理<code>Cache</code>的实体。</p>\n<p>我们以Spring Cache默认的缓存实现<strong>Simple</strong>例子，简单探索下CacheManager的机制。</p>\n<p>CacheManager非常简单：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>在CacheConfigurations配置类中，可以看到不同集成类型有不同的缓存配置类。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//vk9nmlzIbC.webp!large\" alt=\"\" tabindex=\"0\"><figcaption>Simple</figcaption></figure>\n<p>通过SpringBoot的自动装配机制，创建CacheManager的实现类<code>ConcurrentMapCacheManager</code>。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//GYJeXgi4Il.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>而<code>ConcurrentMapCacheManager</code>的getCache方法，会创建<code>ConcurrentCacheMap</code>。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//TTOwUF59LP.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><code>ConcurrentCacheMap</code>实现了<code>org.springframework.cache.Cache</code>接口。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//qd2d2wJdJz.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>从Spring Cache的<strong>Simple</strong>的实现，缓存配置需要实现两个接口：</p>\n<ul>\n<li>\n<p><strong>org.springframework.cache.CacheManager</strong></p>\n</li>\n<li>\n<p><strong>org.springframework.cache.Cache</strong></p>\n</li>\n</ul>\n<h2> 3 入门例子</h2>\n<p>首先我们先创建一个工程spring-cache-demo。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//QOyVUVjie7.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>caffeine和Redisson分别是本地内存和分布式缓存Redis框架中的佼佼者，我们分别演示如何集成它们。</p>\n<h3> 3.1 集成caffeine</h3>\n<h4> 3.1.1 maven依赖</h4>\n<div class=\"language-xml line-numbers-mode\" data-ext=\"xml\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h4> 3.1.2 Caffeine缓存配置</h4>\n<p>我们先创建一个缓存配置类MyCacheConfig。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>首先创建了一个Caffeine对象，该对象标识本地缓存的最大数量是10000条，每个缓存数据在写入60分钟后失效。</p>\n<p>另外，MyCacheConfig类上我们添加了注解：<strong>@EnableCaching</strong>。</p>\n<h4> 3.1.3 业务代码</h4>\n<p>根据<strong>缓存声明</strong>这一节，我们很容易写出如下代码。</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>这段代码与硬编码里的代码片段明显精简很多。</p>\n<p>当我们在Controller层调用 getUserById方法时，调试的时候，配置mybatis日志级别为DEBUG，方便监控方法是否会缓存。</p>\n<p>第一次调用会查询数据库，打印相关日志：</p>\n<div class=\"language-bash line-numbers-mode\" data-ext=\"sh\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>第二次调用查询方法的时候，数据库SQL日志就没有出现了， 也就说明缓存生效了。</p>\n<h3> 3.2 集成Redisson</h3>\n<h4> 3.2.1 maven依赖</h4>\n<div class=\"language-xml line-numbers-mode\" data-ext=\"xml\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h4> 3.2.2 Redisson缓存配置</h4>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>可以看到，从Caffeine切换到Redisson，只需要修改缓存配置类，定义<strong>CacheManager</strong> 对象即可。而业务代码并不需要改动。</p>\n<p>Controller层调用 getUserById方法，用户ID为1的时候，可以从Redis Desktop Manager里看到： 用户信息已被缓存，user_cache缓存存储是Hash数据结构。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//dWCrSBzXSc.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>因为Redisson默认的编解码是<strong>FstCodec</strong>， 可以看到key的名称是： \\xF6\\x01。</p>\n<p>在缓存配置代码里，可以修改编解码器。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>再次调用 getUserById方法 ，控制台就变成：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//Hh80EPVC0Z.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>可以观察到：缓存key已经变成了：[\"java.lang.Long\",1]，改变序列化后key和value已发生了变化。</p>\n<h3> 3.3 从列表缓存再次理解缓存抽象</h3>\n<p>列表缓存在业务中经常会遇到。通常有两种实现形式：</p>\n<ol>\n<li>整体列表缓存；</li>\n<li>按照每个条目缓存，通过redis，memcached的聚合查询方法批量获取列表，若缓存没有命中，则从数据库重新加载，并放入缓存里。</li>\n</ol>\n<p>那么Spring cache整合Redisson如何缓存列表数据呢？</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>执行getUserList方法，参数id列表为：[1，3] 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//mOd6M7BgeW.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>执行完成之后，控制台里可以看到：，用户列表缓存和用户条目缓存并<strong>没有共享</strong>，他们是平行的关系。</p>\n<p>这种情况下，缓存的颗粒度控制也没有那么细致。</p>\n<p>类似这样的思考，很多开发者也向Spring Framework研发团队提过。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//UkXRc7g8O2.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://www.javayong.cn/pics/temp//XHUWdfuvUv.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>官方的回答也很明确：对于缓存抽象来讲，它并不关心方法返回的数据类型，假如是集合，那么也就意味着需要把集合数据在缓存中保存起来。</p>\n<p>还有一位开发者，定义了一个@<strong>CollectionCacheable</strong>注解，并做出了原型，扩展了Spring Cache的列表缓存功能。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>官方也未采纳，因为<strong>缓存抽象并不想引入太多的复杂性</strong>。</p>\n<p>写到这里，相信大家对缓存抽象有了更进一步的理解。当我们想实现更复杂的缓存功能时，需要对Spring Cache做一定程度的扩展。</p>\n<h2> 4 自定义二级缓存</h2>\n<h3> 4.1 应用场景</h3>\n<p>笔者曾经在原来的项目，高并发场景下多次使用多级缓存。多级缓存是一个非常有趣的功能点，值得我们去扩展。</p>\n<p>多级缓存有如下优势：</p>\n<ol>\n<li>离用户越近，速度越快；</li>\n<li>减少分布式缓存查询频率，降低序列化和反序列化的CPU消耗；</li>\n<li>大幅度减少网络IO以及带宽消耗。</li>\n</ol>\n<p>进程内缓存做为一级缓存，分布式缓存做为二级缓存，首先从一级缓存中查询，若能查询到数据则直接返回，否则从二级缓存中查询，若二级缓存中可以查询到数据，则回填到一级缓存中，并返回数据。若二级缓存也查询不到，则从数据源中查询，将结果分别回填到一级缓存，二级缓存中。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//6jIXNdJbHp.webp!large\" alt=\"来自《凤凰架构》缓存篇\" tabindex=\"0\"><figcaption>来自《凤凰架构》缓存篇</figcaption></figure>\n<p>Spring Cache并没有二级缓存的实现，我们可以实现一个简易的二级缓存DEMO，加深对技术的理解。</p>\n<h3> 4.2 设计思路</h3>\n<ol>\n<li><strong>MultiLevelCacheManager</strong>：多级缓存管理器；</li>\n<li><strong>MultiLevelChannel</strong>：封装Caffeine和RedissonClient；</li>\n<li><strong>MultiLevelCache</strong>：实现org.springframework.cache.Cache接口；</li>\n<li><strong>MultiLevelCacheConfig</strong>：配置缓存过期时间等；</li>\n</ol>\n<p>MultiLevelCacheManager是最核心的类，需要实现<strong>getCache</strong>和<strong>getCacheNames</strong>两个接口。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//MlFyK4WSiF.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>创建多级缓存，第一级缓存是：Caffeine , 第二级缓存是：Redisson。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//JoL5oTXi6y.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>二级缓存，为了快速完成DEMO，我们使用Redisson对Spring Cache的扩展类<strong>RedissonCache</strong> 。它的底层是<strong>RMap</strong>，底层存储是Hash。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//Z4dbRzEVOa.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们重点看下缓存的「查询」和「存储」的方法：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>「<strong>查询</strong>」数据的流程：</p>\n<ol>\n<li>先从本地缓存中查询数据，若能查询到，直接返回；</li>\n<li>本地缓存查询不到数据，查询分布式缓存，若可以查询出来，回填到本地缓存，并返回；</li>\n<li>若分布式缓存查询不到数据，则默认会执行被注解的方法。</li>\n</ol>\n<p>下面来看下「<strong>存储</strong>」的代码：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>最后配置缓存管理器，原有的业务代码不变。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//6IEuaPkZ4h.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>执行下getUserById方法，查询用户编号为1的用户信息。</p>\n<div class=\"language-bash line-numbers-mode\" data-ext=\"sh\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>第二次执行相同的动作，从日志可用看到从优先会从本地内存中查询出结果。</p>\n<div class=\"language-bash line-numbers-mode\" data-ext=\"sh\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>等待30s ， 再执行一次，因为本地缓存会失效，所以执行的时候会查询二级缓存</p>\n<div class=\"language-bash line-numbers-mode\" data-ext=\"sh\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>一个简易的二级缓存就组装完了。</p>\n<h2> 5 什么场景选择Spring Cache</h2>\n<p>在做技术选型的时候，需要针对场景选择不同的技术。</p>\n<p>笔者认为Spring Cache的功能很强大，设计也非常优雅。特别适合缓存控制没有那么细致的场景。比如门户首页，偏静态展示页面，榜单等等。这些场景的特点是对数据实时性没有那么严格的要求，只需要将数据源缓存下来，过期之后自动刷新即可。 这些场景下，Spring Cache就是神器，能大幅度提升研发效率。</p>\n<p>但在高并发大数据量的场景下，精细的缓存颗粒度的控制上，还是需要做功能扩展。</p>\n<ol>\n<li>多级缓存；</li>\n<li>列表缓存；</li>\n<li>缓存变更监听器；</li>\n</ol>\n<p>笔者也在思考这几点的过程，研读了 j2cache , jetcache相关源码，受益匪浅。后续的文章会重点分享下笔者的心得。</p>\n<hr>\n<p>如果我的文章对你有所帮助，还请帮忙<strong>点赞、在看、转发</strong>一下，你的支持会激励我输出更高质量的文章，非常感谢！</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//vBrZNjbMur.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n",
      "image": "https://www.javayong.cn/pics/temp//RK8gWPf7o2.webp!large",
      "date_published": "2023-11-16T08:17:07.000Z",
      "date_modified": "2023-11-17T08:13:01.000Z",
      "authors": [],
      "tags": [
        "cache"
      ]
    },
    {
      "title": "RocketMQ 整体架构",
      "url": "https://javayong.cn/mq/rocketmq4/01RocketMQ4_artch.html",
      "id": "https://javayong.cn/mq/rocketmq4/01RocketMQ4_artch.html",
      "summary": "1 专业术语 Producer 消息生产者，负责产生消息，一般由业务系统负责产生消息。 Consumer 消息消费者，负责消费消息，一般是后台系统负责异步消费。 PushConsumer Consumer 的一种，应用通常向 Consumer 对象注册一个 Listener 接口，一旦收到消息，Consumer 对象立刻回调 Listener 接口方法。 PullConsumer Consumer 的一种，应用通常主动调用 Consumer 的拉消息方法从 Broker 拉消息，主动权由应用控制。 ProducerGroup 一类 Producer 的集合名称，这类 Producer 通常发送一类消息，且发送逻辑一致。 ConsumerGroup 一类 Consumer 的集合名称，这类 Consumer 通常消费一类消息，且消费逻辑一致。 Broker 消息中转角色，负责存储消息，转发消息，一般也称为 Server。在 JMS 规范中称为 Provider。 广播消费 一条消息被多个 Consumer 消费，即使这些 Consumer 属于同一个 Consumer Group，消息也会被 Consumer Group 中的每个 Consumer 都消费一次，广播消费中的 Consumer Group 概念可以认为在消息划分方面无意义。 集群消费 一个 Consumer Group 中的 Consumer 实例平均分摊消费消息。例如某个 Topic 有 9 条消息，其中一个 Consumer Group 有 3 个实例(可能是 3 个进程，或者 3 台机器)，那举每个实例只消费其中的 3 条消息。 顺序消息 消费消息的顺序要同发送消息的顺序一致，在 RocketMQ 中，主要是指的是局部顺序，即一类消息为满足顺序性，必须 Producer 单线程顺序发送，且发送到同一个队列，这样 Consumer 就可以按照 Producer 发送的顺序去消费消息。 Message Queue 在 RocketMQ 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用 Offset 来访问，offset 为 java long 类型，64 位，理论上在 100 年内不会溢出，另外队列中只保存最近几天的数据，之前的数据会按照过期时间来删除。也可以认为 Message Queue 是一个长度无限的数组，offset 就是下标。",
      "content_html": "<h2> 1 专业术语</h2>\n<ul>\n<li>\n<p>Producer 消息生产者，负责产生消息，一般由业务系统负责产生消息。</p>\n</li>\n<li>\n<p>Consumer 消息消费者，负责消费消息，一般是后台系统负责异步消费。</p>\n</li>\n<li>\n<p>PushConsumer\nConsumer 的一种，应用通常向 Consumer 对象注册一个 Listener 接口，一旦收到消息，Consumer 对象立刻回调 Listener 接口方法。</p>\n</li>\n<li>\n<p>PullConsumer</p>\n<p>Consumer 的一种，应用通常主动调用 Consumer 的拉消息方法从 Broker 拉消息，主动权由应用控制。</p>\n</li>\n<li>\n<p>ProducerGroup</p>\n<p>一类 Producer 的集合名称，这类 Producer 通常发送一类消息，且发送逻辑一致。</p>\n</li>\n<li>\n<p>ConsumerGroup</p>\n<p>一类 Consumer 的集合名称，这类 Consumer 通常消费一类消息，且消费逻辑一致。</p>\n</li>\n<li>\n<p>Broker</p>\n<p>消息中转角色，负责存储消息，转发消息，一般也称为 Server。在 JMS 规范中称为 Provider。</p>\n</li>\n<li>\n<p>广播消费</p>\n<p>一条消息被多个 Consumer 消费，即使这些 Consumer 属于同一个 Consumer Group，消息也会被 Consumer Group 中的每个 Consumer 都消费一次，广播消费中的 Consumer Group 概念可以认为在消息划分方面无意义。</p>\n</li>\n<li>\n<p>集群消费</p>\n<p>一个 Consumer Group 中的 Consumer 实例平均分摊消费消息。例如某个 Topic 有 9 条消息，其中一个 Consumer Group 有 3 个实例(可能是 3 个进程，或者 3 台机器)，那举每个实例只消费其中的 3 条消息。</p>\n</li>\n<li>\n<p>顺序消息\n消费消息的顺序要同发送消息的顺序一致，在 RocketMQ 中，主要是指的是局部顺序，即一类消息为满足顺序性，必须 Producer 单线程顺序发送，且发送到同一个队列，这样 Consumer 就可以按照 Producer 发送的顺序去消费消息。</p>\n</li>\n<li>\n<p>Message Queue\n在 RocketMQ 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用 Offset 来访问，offset 为 java long 类型，64 位，理论上在 100 年内不会溢出，另外队列中只保存最近几天的数据，之前的数据会按照过期时间来删除。也可以认为 Message Queue 是一个长度无限的数组，offset 就是下标。</p>\n</li>\n</ul>\n<h2> 2 核心功能</h2>\n<p>本节阐述消息中间件通常需要解决哪些问题，在解决这些问题当中会遇到什么困难，RocketMQ 是否可以解决，规范中如何定义这些问题。</p>\n<h3> 2.1 发布订阅</h3>\n<p>点对点（P2P）和发布订阅（Pub/Sub）是两种常见的消息队列模式，它们用于满足不同通信需求。</p>\n<ol>\n<li>点对点（P2P）模式：\n<ul>\n<li>在点对点模式中，消息发送者（生产者）将消息发送到一个特定的队列，而消息接收者（消费者）从该队列中接收消息。</li>\n<li>消息在队列中存储，一旦一个消息被消费者接收，它就从队列中移除，这确保了每个消息只被一个消费者处理。</li>\n<li>这种模式适用于一对一的通信，其中一个生产者向一个特定的消费者发送消息，确保消息的可靠传递和处理。</li>\n</ul>\n</li>\n<li>发布订阅（Pub/Sub）模式：\n<ul>\n<li>在发布订阅模式中，消息发送者将消息发布到一个主题（topic），而消息订阅者则订阅感兴趣的主题。</li>\n<li>每个主题可以有多个订阅者，因此消息会被广播到所有订阅了相同主题的消费者。</li>\n<li>这种模式适用于一对多或多对多的通信，允许多个消费者同时接收和处理相同主题的消息。</li>\n<li>发布订阅模式通常用于构建实时事件处理系统、日志处理、通知系统等，其中多个消费者需要订阅相同类型的消息并进行处理。</li>\n</ul>\n</li>\n</ol>\n<p>点对点模式适用于一对一的通信，确保消息的可靠传递给一个特定的消费者，而发布订阅模式适用于一对多或多对多的通信，允许多个消费者同时接收相同主题的消息，用于构建实时事件系统和广播通信。</p>\n<h3> 2.2 消息优先级</h3>\n<p>规范中描述的优先级是指在一个消息队列中，每条消息都有不同的优先级，一般用整数来描述，优先级高的消 息先投递，如果消息完全在一个内存队列中，那么在投递前可以按照优先级排序，令优先级高的先投递。</p>\n<p>由于 RocketMQ 所有消息都是持久化的，所以如果按照优先级来排序，开销会非常大，因此 RocketMQ 没有特意支持消息优先级，但是可以通过变通的方式实现类似功能，即单独配置一个优先级高的队列，和一个普通优先级 的队列， 将不同优先级发送到不同队列即可。</p>\n<p>对于优先级问题，可以归纳为 2 类：</p>\n<ol>\n<li>只要达到优先级目的即可，不是严格意义上的优先级，通常将优先级划分为高、中、低，或者再多几个级别。每个优先级可以用不同的 topic 表示，发消息时，指定不同的 Topic 来表示优先级，这种方式可以解决绝大部分的优先级问题，但是对业务的优先级精确性做了妥协。</li>\n<li>严格的优先级，优先级用整数表示，例如 0 ~ 65535，这种优先级问题一般使用不同 topic 解决就非常不合适。如果要让 MQ 解决此问题，会对 MQ 的性能造成非常大的影响。这里要确保一点，业务上是否确实需</li>\n</ol>\n<p>要这种严格的优先级，如果将优先级压缩成几个，对业务的影响有多大 ?</p>\n<h3> 2.3 消息有序</h3>\n<p>消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如:一个订单产生了 3 条消息，分别是订单创 建，订单付款，订单完成。消费时，要按照这个顺序消费才能有意义。但是同时订单之间是可以并行消费的。RocketMQ 可以严格的保证消息有序。</p>\n<h3> 2.4 消息过滤</h3>\n<ul>\n<li>\n<p>Broker 端消息过滤\n在 Broker 中，按照 Consumer 的要求做过滤，优点是减少了对于 Consumer 无用消息的网络传输。 缺点是增加了 Broker 的负担，实现相对复杂。</p>\n</li>\n<li>\n<p>Consumer 端消息过滤</p>\n<p>这种过滤方式可由应用完全自定义实现，但是缺点是很多无用的消息要传输到 Consumer 端。</p>\n</li>\n</ul>\n<h3> 2.5 消息持久化</h3>\n<p>消息中间件通常采用的几种持久化方式:</p>\n<ol>\n<li>持久化到数据库，例如 Mysql 。</li>\n<li>持久化到 KV 存储，例如 levelDB、伯克利 DB 等 KV 存储系统。</li>\n<li>文件记录形式持久化，例如 Kafka，RocketMQ 。</li>\n<li>对内存数据做一个持久化镜像，例如 beanstalkd，VisiNotify 。</li>\n</ol>\n<p>1，2,  3 三种持久化方式都具有将内存队列 Buffer 进行扩展的能力，4 只是一个内存的镜像，作用是当 Broker 挂掉重启后仍然能将之前内存的数据恢复出来。</p>\n<p>JMS 与 CORBA Notification 规范没有明确说明如何持久化，但是持久化部分的性能直接决定了整个消息中间件 的性能。</p>\n<p>RocketMQ 参考了 Kafka 的持久化方式，充分利用 Linux 文件系统内存 cache 来提高性能。</p>\n<h3> 2.6 消息可靠性</h3>\n<p>影响消息可靠性的几种情况:</p>\n<ol>\n<li>\n<p>Broker 正常关闭</p>\n</li>\n<li>\n<p>Broker 异常 Crash</p>\n</li>\n<li>\n<p>OS Crash</p>\n</li>\n<li>\n<p>机器掉电，但是能立即恢复供电情况。</p>\n</li>\n</ol>\n<ol start=\"5\">\n<li>机器无法开机(可能是cpu、主板、内存等关键设备损坏)</li>\n<li>磁盘设备损坏。</li>\n</ol>\n<p>1、2、3、4  四种情况都属于硬件资源可立即恢复情况，RocketMQ 在这四种情况下能保证消息不丢，或者丢失少量数据(依赖刷盘方式是同步还是异步)。</p>\n<p>5、6 属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。</p>\n<p>RocketMQ 在这两种情况下，通过异步复制，可保证 99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点， 同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与金额相关的应用。</p>\n<h3> 2.7 低延迟消费</h3>\n<p>在消息不堆积情况下，消息到达 Broker 后，能立刻到达 Consumer。 RocketMQ 使用长轮询 Pull 方式，可保证消息非常实时，消息实时性不低于 Push。</p>\n<h3> 2.8 At least Once</h3>\n<p>是指每个消息必须投递一次。RocketMQ Consumer 先 pull 消息到本地，消费完成后，才向服务器返回 ack，如果没有消费一定不会 ack 消息， 所以 RocketMQ 可以很好的支持此特性。</p>\n<h3> 2.9 Exactly Only Once</h3>\n<p>1、发送消息阶段，不允许发送重复的消息。\n2、消费消息阶段，不允许消费重复的消息。\n只有以上两个条件都满足情况下，才能认为消息是“Exactly Only Once”，而要实现以上两点，在分布式系统环境下，不可避免要产生巨大的开销。所以 RocketMQ 为了追求高性能，并不保证此特性，<strong>要求在业务上进行去重， 也就是说消费消息要做到幂等性</strong>。RocketMQ 虽然不能严格保证不重复，但是正常情况下很少会出现重复发送、消 费情况，只有网络异常，Consumer 启停等异常情况下会出现消息重复。</p>\n<p><strong>此问题的本质原因是网络调用存在不确定性，即既不成功也不失败的第三种状态，所以才产生了消息重复性问题。</strong></p>\n<h3> 2.10 Broker <strong>的</strong> <strong>Buffer</strong> 满了怎么办?</h3>\n<p>Broker 的 Buffer 通常指的是 Broker 中一个队列的内存 Buffer 大小，这类 Buffer 通常大小有限，如果 Buffer 满 了以后怎么办?</p>\n<p>下面是 CORBA Notification 规范中处理方式:</p>\n<p>(1). RejectNewEvents 拒绝新来的消息，向 Producer 返回 RejectNewEvents 错误码。</p>\n<p>(2). 按照特定策略丢弃已有消息</p>\n<ol>\n<li>\n<p><strong>AnyOrder</strong> - Any event may be discarded on overflow. This is the default setting for this property.</p>\n</li>\n<li>\n<p><strong>FifoOrder</strong> - The first event received will be the first discarded.</p>\n</li>\n<li>\n<p><strong>LifoOrder</strong> - The last event received will be the first discarded.</p>\n</li>\n<li>\n<p><strong>PriorityOrder</strong> - Events should be discarded in priority order, such that lower priority events will be discarded before higher priority events.</p>\n</li>\n<li>\n<p><strong>DeadlineOrder</strong> - Events should be discarded in the order of shortest expiry deadline first. RocketMQ 没有内存 Buffer 概念，RocketMQ 的队列都是持久化磁盘，数据定期清除。</p>\n</li>\n</ol>\n<p>对于此问题的解决思路，RocketMQ 同其他 MQ 有非常显著的区别，RocketMQ 的内存 Buffer 抽象成一个无限长度的队列，不管有多少数据进来都能装得下，这个无限是有前提的，Broker 会定期删除过期的数据，例如 Broker 只保存 3 天的消息，那么这个 Buffer 虽然长度无限，但是 3 天前的数据会被从队尾删除。</p>\n<h3> 2.11 <strong>回溯消费</strong></h3>\n<p>回溯消费是指 Consumer 已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker 在向 Consumer 投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于 Consumer 系统故障， 恢复后需要重新消费 1 小时前的数据，那么 Broker 要提供一种机制，可以按照时间维度来回退消费进度。</p>\n<p>RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。</p>\n<h3> 2.12 消息堆积</h3>\n<p>消息中间件的主要功能是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性，这就要 求消息中间件具有一定的消息堆积能力，消息堆积分以下两种情况:</p>\n<ol>\n<li>消息堆积在内存 Buffer，一旦超过内存 Buffer，可以根据一定的丢弃策略来丢弃消息，如 CORBA Notification 规范中描述。适合能容忍丢弃消息的业务，这种情况消息的堆积能力主要在于内存 Buffer 大小，而且消息堆积后，性能下降不会太大，因为内存中数据多少对于对外提供的访问能力影响有限。</li>\n<li>消息堆积到持久化存储系统中，例如 DB ，KV 存储，文件记录形式。\n当消息不能在内存 Cache 命中时，要不可避免的访问磁盘，会产生大量读  IO，读 IO 的吞吐量直接决定了 消息堆积后的访问能力。</li>\n</ol>\n<p>评估消息堆积能力主要有以下四点:</p>\n<ol>\n<li>\n<p>消息能堆积多少条，多少字节 ? 即消息的堆积容量。</p>\n</li>\n<li>\n<p>消息堆积后，发消息的吞吐量大小，是否会受堆积影响 ?</p>\n</li>\n<li>\n<p>消息堆积后，正常消费的 Consumer 是否会受影响 ?</p>\n</li>\n<li>\n<p>消息堆积后，访问堆积在磁盘的消息时，吞吐量有多大 ?</p>\n</li>\n</ol>\n<h3> 2.13 分布式事务</h3>\n<p>已知的几个分布式事务规范，如 XA，JTA 等。其中 XA 规范被各大数据库厂商广泛支持，如 Oracle，Mysql 等。 其中 XA 的 TM 实现佼佼者如 Oracle Tuxedo，在金融、电信等领域被广泛应用。</p>\n<p>分布式事务涉及到两阶段提交问题，在数据存储方面的方面必然需要 KV 存储的支持，因为第二阶段的提交回滚需要修改消息状态，一定涉及到根据 Key 去查找 Message 的动作。RocketMQ 在第二阶段绕过了根据 Key 去查找 Message 的问题，采用第一阶段发送 Prepared 消息时，拿到了消息的 Offset，第二阶段通过 Offset 去访问消息， 并修改状态，Offset 就是数据的地址。</p>\n<p>RocketMQ 这种实现事务方式，没有通过 KV 存储做，而是通过 Offset 方式，存在一个显著缺陷，即通过 Offset 更改数据，会令系统的脏页过多，需要特别关注。</p>\n<h3> 2.14 定时消息</h3>\n<p>定时消息是指消息发到 Broker 后，不能立刻被 Consumer 消费，要到特定的时间点或者等待特定的时间后才能 被消费。</p>\n<p>如果要支持任意的时间精度，在 Broker 层面，必须要做消息排序，如果再涉及到持久化，那么消息排序要不 可避免的产生巨大性能开销。</p>\n<p>RocketMQ 支持定时消息，但是不支持任意时间精度，支持特定的 level，例如定时 5s，10s，1m 等。</p>\n<h3> 2.15 消息重试</h3>\n<p>Consumer 消费消息失败后，要提供一种重试机制，令消息再消费一次。</p>\n<p>消费失败通常可以认为有以下几种情况</p>\n<ol>\n<li>由于消息本身的原因，例如反序列化失败，消息数据本身无法处理(例如话费充值，当前消息的手机号被注销，无法充值)等。</li>\n</ol>\n<p>这种错误通常需要跳过这条消息，再消费其他消息，而这条失败的消息即使立刻重试消费，99%也不成功，</p>\n<p>所以最好提供一种定时重试机制，即过 10s 秒后再重试。</p>\n<ol start=\"2\">\n<li>由于依赖的下游应用服务不可用，例如 db 连接不可用，外系统网络不可达等。</li>\n</ol>\n<p>遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。这种情况建议应用 sleep 30s ，再消费下一条消息，这样可以减轻 Broker 重试消息的压力。</p>\n<h2> 3 架构概览</h2>\n<p>我们先对 RocketMQ 4.9.X 架构做一个概览。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//WmCfyfFaPD.webp!large.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>整体架构中包含<strong>四种角色</strong> :</p>\n<p><strong>1、NameServer</strong></p>\n<p>名字服务是是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。它是一个非常简单的 Topic 路由注册中心，其角色类似 Dubbo 中的 zookeeper ，支持 Broker 的动态注册与发现。</p>\n<p><strong>2、BrokerServer</strong></p>\n<p>Broker 主要负责消息的存储、投递和查询以及服务高可用保证 。</p>\n<p><strong>3、Producer</strong></p>\n<p>消息发布的角色，Producer 通过 MQ 的负载均衡模块选择相应的 Broker 集群队列进行消息投递，投递的过程支持快速失败并且低延迟。</p>\n<p><strong>4、Consumer</strong></p>\n<p>消息消费的角色，支持以 push 推，pull 拉两种模式对消息进行消费。</p>\n<p>RocketMQ 集群工作流程：</p>\n<p>1、<strong>启动 NameServer</strong>，NameServer 起来后监听端口，等待 Broker、Producer 、Consumer 连上来，相当于一个路由控制中心。</p>\n<p>2、<strong>Broker 启动</strong>，跟所有的 NameServer 保持长连接，定时发送心跳包。心跳包中包含当前 Broker信息( IP+端口等 )以及存储所有 Topic 信息。注册成功后，NameServer 集群中就有 Topic 跟 Broker 的映射关系。</p>\n<p>3、收发消息前，先<strong>创建 Topic</strong>，创建 Topic 时需要指定该 Topic 要存储在哪些 Broker 上，也可以在发送消息时自动创建 Topic。</p>\n<p>4、<strong>Producer 发送消息</strong>，启动时先跟 NameServer 集群中的其中一台建立长连接，并从 NameServer 中获取当前发送的 Topic 存在哪些 Broker 上，轮询从队列列表中选择一个队列，然后与队列所在的 Broker 建立长连接从而向 Broker 发消息。</p>\n<p>5、Consumer 跟 Producer 类似，跟其中一台 NameServer 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始<strong>消费消息</strong>。</p>\n",
      "image": "https://www.javayong.cn/pics/temp//WmCfyfFaPD.webp!large.png",
      "date_published": "2023-11-16T04:40:45.000Z",
      "date_modified": "2023-11-17T07:53:52.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "序言",
      "url": "https://javayong.cn/mq/rocketmq4/00RocketMQ4_introduce.html",
      "id": "https://javayong.cn/mq/rocketmq4/00RocketMQ4_introduce.html",
      "summary": "大家好，我是勇哥 。 20231024 , 程序员节，圆了我一个小小的梦。 花了半年时间，我写了一本电子书 ，书名是：《RocketMQ4.X设计精要》，我想在今天分享给各位。 这本书一共包含十五章，接近 10 万字，180 张图，按照 RocketMQ 的知识体系一章一章展开。",
      "content_html": "<p>大家好，我是勇哥 。</p>\n<p>20231024 , 程序员节，圆了我一个小小的梦。</p>\n<p>花了半年时间，我写了一本电子书 ，书名是：《<strong>RocketMQ4.X设计精要</strong>》，我想在今天分享给各位。</p>\n<p>这本书一共包含十五章，接近 10 万字，180 张图，按照 RocketMQ 的知识体系一章一章展开。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/mybook.png?a=23\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>很多年前，一位七牛的资深架构师曾经说过这样一句话：</p>\n<blockquote>\n<p>Nginx+ 业务逻辑层 + 数据库 + 缓存层 + 消息队列 ，这种模型几乎能适配绝大部分的业务场景 。</p>\n</blockquote>\n<p>这么多年过去了，这句话或深或浅地影响了我的技术选择，以至于后来我花了很多时间去重点学习缓存、消息队列相关的技术。</p>\n<p>2014年，是我和 RocketMQ 结缘的一年。</p>\n<p>我那时服务于艺龙旅行网，深感自己能力的欠缺，我非常想学习消息队列的知识，但当时互联网上开源的消息队列并不能让我满意。</p>\n<p>读了子柳老师的《淘宝技术这十年》后，我搜罗了很多淘宝消息队列的资料，我知道MetaQ 的版本已经升级 MetaQ 3.0，只是开源版本还没有放出来。</p>\n<p>2014 年秋 ，当 RocketMQ 开源出来之后 ，我兴奋异常，迫不及待的一睹其风采，至今我都能记得当时内心的雀跃。</p>\n<p>我想学网络编程，RocketMQ 的通讯模块 remoting 底层也是 Netty 写的。我学习切入点是 RocketMQ 的通讯模块。</p>\n<p>首先我模仿 RocketMQ 的通讯模块写了一个玩具的<code>rpc</code>，在 IDEA 中丝滑打印生产者/消费者的日志，感觉自己充满了能量。</p>\n<p>不久之后，艺龙举办技术创新活动，我想想，要不尝试一下用 Netty 改写下 <code>Cobar</code> 的通讯模块。</p>\n<p>于是参考 <code>Cobar</code> 的源码花了两周写了个 netty 版的 <code>proxy</code>，其实非常粗糙，很多功能不完善。只是没有想到，活动颁给我一个<strong>鼓励奖</strong>，现在想想既有趣又有点激励。</p>\n<p>这就是我学习 RocketMQ 的起点，一个非常美好的起点。</p>\n<p>在接下来的职业生涯中 ，我不断在业务中使用 RocketMQ ：</p>\n<ol>\n<li>直播答题：RocketMQ 广播模式推送题目 ；</li>\n<li>参考阿里云 ONS 封装 RocketMQ 框架 ；</li>\n<li>使用 RocketMQ 通讯框架实现任务调度系统 ；</li>\n<li>使用 RocketMQ 作为短信平台的基座 ;</li>\n<li>重构 RocketMQ 控制台支持多集群 。</li>\n</ol>\n<p>通过 RocketMQ  ，我学习到了很多的编程知识，比如多线程技巧、网络编程 、文件存储，同时面对各种技术问题处理起来也更加从容和自信。</p>\n<p>缓存、分库分表、消息队列是高并发解决方案三剑客，是架构师必须掌握的知识点。</p>\n<p>我写这本电子书，是想帮助后端工程师快速掌握 RocketMQ 的相关知识点，提升他们的技术认知。</p>\n<p><strong>假如朋友们能通过这本电子书，快速成长，那将是一件令我非常快乐的事情。</strong></p>\n<p>因为我自己的能力有限，书中肯定存在纰漏和错误之处，欢迎沟通指正，非常感谢 ：）</p>\n<figure><img src=\"https://javayong.cn/pics/shipinhao/gongzhonghaonew.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>微信搜索「勇哥java实战分享」关注后，在后台回复「mq」即可获取《RocketMQ 4.X 设计精要》pdf 。</p>\n",
      "image": "https://javayong.cn/pics/rocketmq/mybook.png?a=23",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-16T13:16:12.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 网络通讯",
      "url": "https://javayong.cn/mq/rocketmq4/01RocketMQ4_network.html",
      "id": "https://javayong.cn/mq/rocketmq4/01RocketMQ4_network.html",
      "summary": "RocketMQ 的网络通讯模块负责生产者、消费者与 Broker 之间的网络通信。 笔者学习 RocketMQ 也是从通讯模块源码开始的，并且从源码里汲取了很多营养。 1 网络协议 客户端和服务端之间完成数据交互，需要约定数据协议。数据协议如下图：",
      "content_html": "<p>RocketMQ 的网络通讯模块负责生产者、消费者与 Broker 之间的网络通信。</p>\n<p>笔者学习 RocketMQ 也是从通讯模块源码开始的，并且从源码里汲取了很多营养。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/remotingcode.png?a=2\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 网络协议</h2>\n<p>客户端和服务端之间完成数据交互，需要约定数据协议。数据协议如下图：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/remotingprotocol.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>传输内容分为以下四个部分：</p>\n<p><strong>1、消息长度：</strong></p>\n<p>​\t  总长度，四个字节存储，占用一个 int 类型；</p>\n<p><strong>2、序列化类型 &amp; 消息头长度：</strong></p>\n<p>​\t  占用一个 int 类型，第一个字节表示序列化类型，后面三个字节表示消息头长度；</p>\n<p><strong>3、消息头数据</strong>：</p>\n<p>​\t  经过序列化后的消息头数据；</p>\n<p><strong>4、消息主体数据：</strong></p>\n<p>​\t  消息主体的二进制字节数据内容。</p>\n<p>消息头数据序列化默认是 <strong>JSON 格式</strong> ，示例如下：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/remotingheaderdemo.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/remotingheaderprotocol.png\" alt=\"header格式说明\" tabindex=\"0\"><figcaption>header格式说明</figcaption></figure>\n<p>网络协议设计的原则是<strong>便于编解码</strong>，这里我们温习下 TCP <strong>粘包</strong>和<strong>拆包</strong>的知识点。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/tcp.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>TCP 是面向字节流的协议，它会将应用层发送的数据拆分成 TCP 报文段进行传输，发送端和接收端都会维护一个 buffer ，发送的数据首先会存至缓冲区  buffer ，然后通过网络发送给接收端的 buffer 中。</p>\n<ul>\n<li><strong>粘包</strong></li>\n</ul>\n<p>如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP 则会将多个请求合并为同一个请求进行发送 。</p>\n<ul>\n<li><strong>拆包</strong></li>\n</ul>\n<p>如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP 就会将其拆分为多次发送。</p>\n<p>Netty 通过以下几种方式来解决粘包问题：</p>\n<p><strong>1、消息定长：FixedLengthFrameDecoder</strong></p>\n<p>发送的消息都是固定长度的，接收方根据固定长度来解析消息，这样可以有效避免粘包和拆包问题。</p>\n<p><strong>2、特定分隔符：DelimiterBasedFrameDecoder</strong></p>\n<p>在消息的末尾添加特定的分隔符，接收方根据分隔符来切分消息。</p>\n<p><strong>3、消息头长度：LenghtFieldBasedFrameDecode</strong></p>\n<p>在消息的头部添加表示消息长度的字段，接收方先读取消息头部的长度字段，然后根据长度字段的值来读取消息内容，从而正确地解析出完整的消息。</p>\n<p>RocketMQ 的解码器就是使用了 <strong>LenghtFieldBasedFrameDecode</strong> 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/nettydecoder.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 2 通讯方式</h2>\n<p>客户端通信方式支持<strong>同步 sync</strong> 、<strong>异步 async</strong> 、<strong>单向 oneway</strong> 三种方式 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/clientcode.png?a=12\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h3> 2.1 同步 sync</h3>\n<p>在同步通信中，客户端发送请求后会一直等待服务器响应，直到接收到响应或者超时。</p>\n<p>这意味着：客户端发送线程在发送请求后会被阻塞，直到收到服务器的响应，然后继续执行发送下一个请求。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/sync.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>同步请求的流程：</p>\n<p>1、客户端连接服务端，创建 channel ；</p>\n<p>2、客户端创建 responseFutrue 对象 ，主要由四个部分组成：<strong>响应结果、请求编号、回调函数、CountDownLatch</strong>。然后将  responseFutrue 对象加入到本地缓存 响应表 reponseTable 里 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/responseFuture.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>3、客户端将请求发送到服务端；</p>\n<p>4、服务端解析出请求命令 ；</p>\n<ol>\n<li>请求命令中包含命令类型、请求编号，服务端根据命令类型选择处理器 ，执行请求命令；</li>\n<li>服务端将响应数据返回给客户端；</li>\n<li>客户端将响应结果填充到响应表 reponseTable 里，同时因为是同步命令，并调用 countDownLatch 的 countDown 方法 , 这样发送消息线程就不再阻塞（<strong>实现同步请求的精髓</strong>）。</li>\n</ol>\n<h3> 2.2 异步 async</h3>\n<p>异步通信中，客户端发送请求后不会等待服务器的响应，而是继续执行后续代码。客户端会注册一个回调函数或者监听器，用于处理服务器响应。当服务器响应返回时，会触发回调函数的执行。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/asyn.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>异步请求的流程 ：</p>\n<p>1、客户端连接服务端，创建 channel ；</p>\n<p>2、通过信号量 <code>semaphoreAsync</code> 限制正在进行的异步请求的最大数量 ;</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>3、客户端创建 responseFutrue 对象 ，主要由四个部分组成：<strong>响应结果、请求编号、回调函数、CountDownLatch</strong>。然后将  responseFutrue 对象加入到本地缓存 响应表 reponseTable 里 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/responseFuture.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>4、客户端将请求发送到服务端，客户端异步方法结束 。</p>\n<p>5、服务端解析出请求命令 ；</p>\n<ol>\n<li>请求命令中包含命令类型、请求编号，服务端根据命令类型选择处理器 ，执行请求命令；</li>\n<li>服务端将响应数据返回给客户端；</li>\n</ol>\n<p>6、通讯框架收到服务端的响应数据后，通过回调线程执行回调函数。</p>\n<h3> 2.3 单向 oneway</h3>\n<p>单向通信发起调用后，不关心调用结果，不做超时控制，只要请求已经发出，就完成本次调用。</p>\n<p>通常用于可以重试，或者定时通知类的场景，调用过程是有可能因为网络问题，机器故障等原因，导致请求失败。业务场景需要能接受这样的异常场景，才可以使用。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/oneway.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<blockquote>\n<p>需要注意的是，单向通信不能保证请求一定能够成功发送到服务器，也无法保证服务器是否正确地接收到了请求。</p>\n</blockquote>\n<p>oneway 请求的流程 :</p>\n<p>1、客户端连接服务端，创建 channel ；</p>\n<p>2、通过信号量 <code>semaphoreOneway</code> 限制正在进行的 oneway 请求的最大数量 ;</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>3、客户端将请求发送到服务端，客户端 oneway 请求方法结束 。</p>\n<p>4、服务端解析出请求命令 , 请求命令中包含命令类型、请求编号，服务端根据命令类型选择处理器 ，执行请求命令 , 并不会将响应数据返回给客户端 ；</p>\n<p>下表展示了<strong>同步</strong>、<strong>异步</strong>、<strong>单向</strong>这三种通讯方式的优劣点：</p>\n<table>\n<thead>\n<tr>\n<th><strong>方式</strong></th>\n<th><strong>发送TPS</strong></th>\n<th><strong>发送结果反馈</strong></th>\n<th><strong>可靠性</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>同步</td>\n<td>快</td>\n<td>有</td>\n<td>不丢失</td>\n</tr>\n<tr>\n<td>异步</td>\n<td>快</td>\n<td>有</td>\n<td>不丢失</td>\n</tr>\n<tr>\n<td>单向</td>\n<td>最快</td>\n<td>无</td>\n<td>可能丢失</td>\n</tr>\n</tbody>\n</table>\n<h2> 3 Reactor多线程设计</h2>\n<p>RocketMQ 的通信模块采用 Netty 组件作为底层通信库，同样也遵循了 Reactor 多线程模型，同时又在这之上做了一些扩展和优化。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/reactor.png?a=12\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>一个 Reactor 主线程 （ <code>eventLoopGroupBoss</code> ）责监听 TCP网络连接请求，建立好连接，创建 SocketChannel , 并注册到 selector 上。</p>\n<p>RocketMQ 源码会自动根据  OS 的类型选择 NIO 和 Epoll ，也可以通过参数配置 ）， 然后监听真正的网络数据。</p>\n<p>拿到网络数据后，再丢给 Worker 线程池（eventLoopGroupSelector ），再真正执行业务逻辑之前需要进行 SSL 验证、编解码、空闲检查、网络连接管理，这些工作都交给 defaultEventExecutorGroup 去做。</p>\n<p>而业务操作由业务线程池中处理，根据 RemotingCommand 的业务请求编号 requestCode ,  从处理器表 processorTable 这个本地缓存中找到对应的处理器 ， 然后封装成 task 任务后，提交到对应的业务处理器的线程池执行。</p>\n<p>从入口到业务逻辑的几个步骤里，线程池一直在增加，这跟每一步步骤逻辑复杂性相关 ，越复杂，需要的并发通道越宽。</p>\n<p>RocketMQ 的线程模型如下所示 ：</p>\n<table>\n<thead>\n<tr>\n<th>线程数</th>\n<th>线程名</th>\n<th>线程具体说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>NettyBoss_%d</td>\n<td>Reactor 主线程</td>\n</tr>\n<tr>\n<td>N</td>\n<td>NettyServerEPOLLSelector_%d_%d</td>\n<td>Reactor 线程池</td>\n</tr>\n<tr>\n<td>M1</td>\n<td>NettyServerCodecThread_%d</td>\n<td>Worker线程池</td>\n</tr>\n<tr>\n<td>M2</td>\n<td>RemotingExecutorThread_%d</td>\n<td>业务 processor 处理线程池</td>\n</tr>\n</tbody>\n</table>\n<h2> 4 写到最后</h2>\n<p>通讯模块核心知识点 ：</p>\n<p>1、网络协议设计原则便于编解码，Netty 的 LenghtFieldBasedFrameDecode 解码器非常容易得解决 TCP 粘包和拆包的问题；</p>\n<p>2、网络通讯框架支持<strong>同步</strong>、<strong>异步</strong>、<strong>单向</strong>这三种通讯方式 ；</p>\n<p>3、理解 Reactor 线程模型很关键 。</p>\n",
      "image": "https://javayong.cn/pics/rocketmq/remotingcode.png?a=2",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-16T07:55:06.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 名字服务",
      "url": "https://javayong.cn/mq/rocketmq4/02RocketMQ4_nameserver.html",
      "id": "https://javayong.cn/mq/rocketmq4/02RocketMQ4_nameserver.html",
      "summary": "NameServer 是专为 RocketMQ 设计的轻量级名字服务，它的源码非常精简，八个类 ，少于1000行代码。 这篇文章， 笔者会从基础概念、Broker发送心跳包、NameServer 维护路由、Zookeeper vs NameServer 四个模块揭秘名字服务的设计精髓。",
      "content_html": "<p>NameServer 是专为 RocketMQ 设计的<strong>轻量级名字服务</strong>，它的源码非常精简，八个类 ，少于1000行代码。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/nameserver.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>这篇文章， 笔者会从<strong>基础概念</strong>、<strong>Broker发送心跳包</strong>、<strong>NameServer 维护路由</strong>、<strong>Zookeeper vs NameServer</strong> 四个模块揭秘名字服务的设计精髓。</p>\n<h1> 1基础概念</h1>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/rocketmqjiagou.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>NameServer 是一个非常简单的 Topic 路由<strong>注册中心</strong>，其角色类似 Dubbo 中的 zookeeper ，支持 Broker 的动态注册与发现。</p>\n<p>RocketMQ 集群工作流程：</p>\n<p>1、NameServer 启动服务，监听 TCP 端口 ， 集群多节点之间无任何信息交互，然后等待 Broker、Producer 、Consumer 连上来；</p>\n<p>2、Broker 启动后，每隔 30 秒向所有的 NameServer 发送心跳命令 ；</p>\n<p>3、NameServer 接收到请求之后，保存路由信息在本地内存里 ，将响应结果返给 Broker 服务；</p>\n<p>4、Producer 启动之后，会随机的选择一个 NameServer ，并从 NameServer 中获取当前发送的 Topic 存在哪些 Broker 上，轮询从队列列表中选择一个队列，然后与队列所在的 Broker 建立长连接从而向 Broker 发消息；</p>\n<p>5、Consumer 跟 Producer 类似，跟其中一台 NameServer 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始消费消息。</p>\n<h1> 2 Broker发送心跳包</h1>\n<p>我们贴一段 Broker 发送心跳命令的源码 ，代码地址位于：<code>org.apache.rocketmq.broker.out.BrokerOuterAPI#registerBrokerAll</code>。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/brokerregister.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>1、Broker 会每隔 30 秒向所有的 NameServer 发送心跳命令 ；</strong></p>\n<blockquote>\n<p>使用 CountDownLatch 实现多线程同步，可以获取发往所有的 NameServer 的心跳命令的响应结果</p>\n</blockquote>\n<p><strong>2、心跳命令包含两个部分：请求头和请求体</strong></p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/brokerheartbeat.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h1> 3 NameServer 维护路由</h1>\n<p>NameServer 在接收到 Broker 发送的心跳请求之后，通过默认的处理器来处理请求，保存路由信息成功后，注册成功状态返回给 Broker 服务。</p>\n<p>源码中，我们可以看到路由信息保存在 <strong>HashMap</strong> 中 。</p>\n<figure><img src=\"https://javayong.cn/pics/cache/rocketmqhash.webp?\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>1、<strong>topicQueueTable</strong>：Topic 消息队列路由信息，包括 topic 所在的 broker 名称，读队列数量，写队列数量，同步标记等信息，rocketmq 根据 topicQueueTable 的信息进行负载均衡消息发送。</p>\n<p>2、<strong>brokerAddrTable</strong>：Broker 节点信息，包括 brokername，所在集群名称，还有主备节点信息。</p>\n<p>3、<strong>clusterAddrTable</strong>：Broker 集群信息，存储了集群中所有的 Brokername。</p>\n<p>4、<strong>brokerLiveTable</strong>：Broker 状态信息，NameServer 每次收到 Broker 的心跳包就会更新该信息。</p>\n<p>当 Broker 向 NameServer 发送心跳包（路由信息），NameServer 需要对 HashMap 进行数据更新，但我们都知道 HashMap 并不是线程安全的，高并发场景下，容易出现 CPU 100% 问题，所以更新 HashMap 时需要加锁，RocketMQ 使用了 JDK 的读写锁 ReentrantReadWriteLock 。</p>\n<p>下面我们看下路由信息如何更新和读取：</p>\n<p><strong>1、写操作：更新路由信息，操作写锁</strong></p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/registerbroker.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>2、读操作：查询主题信息，操作读锁</strong></p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/getalltopiclist.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<hr>\n<p>我们可以将 NameServer 实现注册中心的方式总结为： <strong>RPC 服务 + HashMap 存储容器 + 读写锁 + 定时任务</strong> 。</p>\n<p>1、NameServer 监听固定的端口，提供 RPC 服务</p>\n<p>2、HashMap 作为存储容器</p>\n<p>3、读写锁控制锁的颗粒度</p>\n<p>4、定时任务</p>\n<ul>\n<li>每个 Broker 每隔 30 秒注册<strong>主题的路由信息</strong>到所有 NameServer</li>\n<li>NameServer 定时任务每隔10 秒清除已宕机的 Broker , 判断宕机的标准是：当前时间减去 Broker 最后一次心跳时间大于2分钟</li>\n</ul>\n<h1> 4 NameServer vs Zookeeper</h1>\n<p>那为什么 RocketMQ 不用 Zookeeper 做为注册中心呢 ？</p>\n<p>我们先温习下 CAP 理论。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/cap.png?c=1\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>CAP 理论是分布式架构中重要理论。</p>\n<p>1、<strong>一致性( Consistency )</strong> ：所有节点在同一时间具有相同的数据 ;</p>\n<p>2、<strong>可用性( Availability )</strong> ：保证每个请求不管成功或者失败都有响应  (某个系统的某个节点挂了，但是并不影响系统的接受或者发出请求) ;</p>\n<p>3、<strong>分隔容忍( Partition tolerance )</strong> ：系统中任意信息的丢失或失败不会影响系统的继续运作。  (在整个系统中某个部分，挂掉了，或者宕机了，并不影响整个系统的运作或者说使用) 。</p>\n<p>Zookeeper 是一个典型的 CP 注册中心 ，通过使 ZAB 协议来保证节点之间数据的强一致性。</p>\n<p>笔者曾经遇到过一起神州专车服务宕机事故，<strong>zookeeper 集群不堪重负，一直在选主</strong> 。 架构负责人修改了 zookeeper 的 jvm 参数，重启集群后 , 才临时解决了问题。</p>\n<p>因为 MetaQ 集群和服务治理共用一组 zookeeper 集群 。</p>\n<ul>\n<li>MetaQ 消费者负载均衡时，会频繁的争抢锁 ，同时也会频繁的提交 offset  ；</li>\n<li>专车的注册服务也越来越多，注册信息通过Hession 序列化存储在 zookeeper 的节点。</li>\n</ul>\n<p>为了减少 zookeeper 集群的性能压力，架构团队将 MetaQ 使用的 zookeeper 集群独立出来。</p>\n<p>这次事故让我认识到： Zookeeper 作为 CP 注册中心，大规模使用场景下，它就变得很脆弱，我们要非常小心的使用。</p>\n<p>淘宝中间件博客出了一篇文章 :  <strong>阿里巴巴为什么不用 ZooKeeper 做服务发现</strong> ？</p>\n<p>文章有两个观点，笔者认为非常有借鉴意义。</p>\n<p>1、当数据中心服务规模超过一定数量 ( 服务规模=F{服务 pub 数,服务 sub 数} )，作为注册中心的 ZooKeeper 很快就会像下图的驴子一样不堪重负。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/zookeeper.png?c=1\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>2、<strong>可以使用 ZooKeeper，但是大数据请向左，而交易则向右，分布式协调向左，服务发现向右</strong>。</p>\n<p>相比 ZooKeeper ，NameServer 是一个典型的 AP 注册中心，它有如下优点：</p>\n<p>1、代码不到 1000 行，实现简单，易于维护 ;</p>\n<p>2、性能极好，除了网络消耗，基本都是本地内存操作 ;</p>\n<p>3、服务都是无状态，且节点之间并不交互，运维简单；</p>\n<p>RocketMQ 的设计者之所以选择自研名字服务，遵循着架构设计的准则，笔者总结为：<strong>简单</strong>、<strong>高效</strong>、<strong>适当妥协</strong>。</p>\n",
      "image": "https://javayong.cn/pics/rocketmq/nameserver.png",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-16T07:55:06.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 生产者",
      "url": "https://javayong.cn/mq/rocketmq4/03RocketMQ4_producer.html",
      "id": "https://javayong.cn/mq/rocketmq4/03RocketMQ4_producer.html",
      "summary": "这篇文章，我们从源码的角度探寻 RocketMQ Producer 的实现机制。 1 基础配置 我们先展示生产者发送消息的示例代码。 // 1. 初始化默认生产者，传递参数生产者组名 DefaultMQProducer producer = new DefaultMQProducer(PRODUCER_GROUP); // 2. 设置名字服务地址 producer.setNamesrvAddr(\"name-server1-ip:9876;name-server2-ip:9876\"); // 3. 启动生产者服务 producer.start(); // 4. 定义消息对象 Message msg = new Message(*TOPIC* /* Topic */, *TAG* /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.*DEFAULT_CHARSET*) /* Message body */ ); msg.setKeys(\"\"); // 5. 发送消息 // 示例普通消息 SendResult sendResult = producer.send(msg); // 示例异步回调 producer.send(msg, new SendCallback() { @Override public void onSuccess(SendResult sendResult) { // do something } @Override public void onException(Throwable e) { // do something } }); // 示例oneway发送 producer.sendOneway(msg);",
      "content_html": "<p>这篇文章，我们从源码的角度探寻 RocketMQ Producer 的实现机制。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/producer.png?b-12\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 基础配置</h2>\n<p>我们先展示生产者发送消息的示例代码。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>发送流程如下：</p>\n<ol>\n<li>初始化默认生产者，传递参数生产者组名；</li>\n<li>设置名字服务地址 ；</li>\n<li>启动生产者服务；</li>\n<li>定义消息对象 ；</li>\n<li>生产者支持<strong>普通发送</strong>、<strong>oneway 发送</strong>、<strong>异步回调</strong>三种方式发送消息 。</li>\n</ol>\n<h2> 2 发送消息流程</h2>\n<h3> 2.1 构造函数</h3>\n<p>下图展示了生产者<code>DefaultMQProducer</code> 类的构造函数，包装类 <code>DefaultMQProducerImpl</code> 是我们这一小节的核心。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/defaultmqproducer.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>构造函数包含两个部分：</p>\n<ol>\n<li>\n<p>初始化实现类 <strong>DefaultMQProducerImpl</strong> ;</p>\n</li>\n<li>\n<p>根据是否开启消息轨迹参数 <code>enableMsgTrace</code> 判断是否增加消息轨迹逻辑 。</p>\n</li>\n</ol>\n<h3> 2.2 启动生产者</h3>\n<p><code>DefaultMQProducer</code> 类的 start 方法，本质上是调用包装类 <code>DefaultMQProducerImpl</code> 的 start 方法。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/producerstart.png?a=1\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>进入 <code>DefaultMQProducerImpl</code> 类，查看该类的逻辑 。</p>\n<h4> 01 检测配置</h4>\n<p>判断生产者组是否合法，生产者名称不能和默认生产者组名称相同。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/producercheckconfig.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h4> 02 创建客户端实例</h4>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/mqclientinstance.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><code>MQClientInstance</code> 对象通过 <code>MQClientManager</code> 这个单例类创建 ，标志着一个客户端实例，是非常核心的类，每一个实例对象有一个唯一的 <code>clientId</code>。</p>\n<ul>\n<li>生产者表/消费者表引用</li>\n</ul>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/clientmap.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ul>\n<li>\n<p>路由信息</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/instanceroutertable.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n</li>\n</ul>\n<h4> 03 注册本地生产者</h4>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>注册本地生产者的本质是修改客户端实例的生产者表引用：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><h4> 04 启动客户端实例</h4>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/instancestart.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>实例启动后，会启动通讯模块、定时任务、负载均衡服务、消费者拉取服务。</p>\n<p>下图展示了生产者发送消息时，IDEA 里的线程 DUMP 图：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/producerdump.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们需要重点讲讲定时任务 <code>startScheduledTask</code>方法 , 定时任务如下图：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/instanceclientschedule.png?a=2\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们重点关注<strong>发送心跳</strong>和<strong>更新路由</strong>两个任务。</p>\n<ul>\n<li><strong>发送心跳</strong>： 定时任务每隔 30 秒将客户端信息发送到 Broker 。</li>\n</ul>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/HeartbeatData.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>当 Broker 收到心跳请求之后，会通过生产者管理器 <code>ProducerManager</code>、消费者管理器<code>ConsumerManager</code>分别更新生产者客户端缓存、消费者客户端缓存。</p>\n<ul>\n<li><strong>更新路由</strong></li>\n</ul>\n<p>对于生产者来讲，它需要知道需要发送消息的主题对应的路由信息 , 因此需要定时更新路由信息。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/updateTopicRouteInfoFromNameServer.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>更新逻辑比较简单，首先从名字服务获取主题路由信息对象 <code>topicRoute</code>，然后更新 <code>DefaultMQProducerImpl</code>的<strong>主题发布信息</strong><code>topicPublishInfoTable</code>对象 。</p>\n<h3> 2.3 发送消息</h3>\n<p>进入 <code>DefaultMQProducerImpl</code> 类，查看发送消息方法  <code>sendDefaultImpl </code>。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/sendimpl.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>笔者将发送消息流程简化如下：</p>\n<ul>\n<li>\n<p>获取主题发布信息；</p>\n</li>\n<li>\n<p>根据路由算法选择一个消息队列，也就是 <code>selectOneMessageQueue</code>方法；</p>\n</li>\n<li>\n<p>调用 <code>sendKernelImpl</code>发放消息对象，封装成发送结果对象 <code>sendResult</code>。</p>\n</li>\n</ul>\n<h4> 01 尝试获取主题发布信息</h4>\n<p>我们知道 <code>MQClientInstance</code> 的定时任务每隔30秒会更新生产者实现类的<code>topicPublishInfoTable  </code>，但若第一次发送消息时，若缓存中无数据时候，还是要重新拉取一次。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/trytofinidtopicpublishinfo.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h4> 02 根据路由算法选择一个消息队列</h4>\n<p>RocketMQ 存储模型包含三部分： <strong>数据文件 commitlog</strong> 、<strong>消费文件 consumequeue</strong> 、<strong>索引文件 indexfile</strong>。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/filelogic.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/filefileoverview.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>因此根据 RocketMQ 的存储模型设计，**对于生产者来讲，发送消息时，必须指定该主题对应的队列。**路由算法，我们会在路由机制这一节重点讲解。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><h4> 03 调用实例客户端 API 发送消息</h4>\n<p>通过路由机制选择一个 messageQueue 之后，调用实例客户端 API 发送消息。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/kernelimpl.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>Broker 端在收到发送消息请求后，调用处理器 <code>SendMessageProcessor</code>处理请求，处理完成后，将响应结果返回给生产者客户端，客户端将接收到的数据组装成 <code>SendResult</code>对象。</p>\n<h2> 3 路由机制</h2>\n<p>进入<code>DefaultMQProducerImpl#selectOneMessageQueue</code> 方法：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>路由机制通过调用 <code> MQFaultStrategy</code> 的 <code>selectOneMessageQueue</code> 方法 ，这里有一个 <code>sendLatencyFaultEnable</code>  开关变量，默认为 false 。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>这里有两个逻辑分支 ：</p>\n<ol>\n<li><code>sendLatencyFaultEnable</code> 为 false ， 通过 <code>TopicPublishInfo</code> 中的 <code> messageQueueList</code>  中选择一个队列（MessageQueue）进行发送消息 ；</li>\n<li><code>sendLatencyFaultEnable</code> 为 true ，开启<strong>延迟容错机制</strong>。</li>\n</ol>\n<h3> 3.1 默认机制</h3>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>默认机制有两个要点：</p>\n<ol>\n<li>循环遍历该主题下所有的队列 ；</li>\n<li>若上一个失败的 Broker 参数值存在，需要过滤掉上一个失败的 Broker 。</li>\n</ol>\n<h3> 3.2 延迟容错机制</h3>\n<p>所谓<strong>延迟容错机制</strong>，是指发送消息时，若某个队列对应的 Broker 宕机了，在默认机制下很可能下一次选择的队列还是在已经宕机的 broker ，没有办法规避故障的broker，因此消息发送很可能会再次失败，重试发送造成了不必要的性能损失。</p>\n<p>因此 producer 提供了<strong>延迟容错机制</strong>来规避故障的 Broker 。</p>\n<p>当<code> sendLatencyFaultEnable</code>  开关为 true 时，在随机递增取模的基础上，代码逻辑会再去过滤掉 not available 的 Broker 。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>所谓的\" <code>latencyFaultTolerance</code> \"，是指对之前失败的，按一定的时间做退避。</p>\n<p>例如，如果上次请求的latency超过 550Lms，就退避 3000Lms；超过1000L，就退避 60000L ；如果关闭，采用随机递增取模的方式选择一个队列（MessageQueue）来发送消息，<code>latencyFaultTolerance</code> 机制是实现消息发送高可用的核心关键所在。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>发送消息时捕捉到异常同样会调用 <code>updateFaultItem</code> 方法：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><code>endTimestamp - beginTimestampPrev</code>等于消息发送耗时，如果成功发送第三个参数传的是 false ，发送失败传  true。</p>\n<p>继续查看 <code>MQFaultStrategy#updateFaultItem </code> 源码：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><code>computeNotAvailableDuration</code>方法会判断当前消息发送耗时，位于哪一个延迟级别，然后选择对应的 duration 。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>如果<code> isolation</code> 为 true，该 broker 会得到一个10分钟规避时长 ，也就是 600000L 毫秒 。</p>\n<p>如果 <code>isolation</code> 为 false，假设 currentLatency 为 600L , 那么规避时间 30000L 毫秒。</p>\n<p>查看 <code>LatencyFaultToleranceImpl#updateFaultItem </code> 源码：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>FaultItem 为存储故障 broker 的类，称为失败条目，每个条目存储了 broker 的名称、消息发送延迟时长、故障规避开始时间。</p>\n<p>该方法主要是对失败条目的一些更新操作，如果失败条目已存在，那么更新失败条目，如果失败条目不存在，那么新建失败条目，其中失败条目的<code>startTimestamp</code>为当前系统时间加上规避时长，<code> startTimestamp</code> 是判断 broker 是否可用的时间值：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> 4 顺序消息</h2>\n<p>顺序消息可以保证消息的消费顺序和发送的顺序一致，即先发送的先消费，后发送的后消费，常用于金融证券、电商业务等对消息指令顺序有严格要求的场景。</p>\n<h3> 4.1 如何保证顺序消息</h3>\n<p>消息的顺序需要由以下三个阶段保证：</p>\n<ul>\n<li>\n<p><strong>消息发送</strong></p>\n<p>如上图所示，A1、B1、A2、A3、B2、B3 是订单 A 和订单 B 的消息产生的顺序，业务上要求同一订单的消息保持顺序，例如订单A的消息发送和消费都按照 A1、A2、A3 的顺序。</p>\n<p>如果是普通消息，订单A的消息可能会被轮询发送到不同的队列中，不同队列的消息将无法保持顺序，而顺序消息发送时 RocketMQ 支持将 Sharding Key 相同（例如同一订单号）的消息序路由到一个队列中。</p>\n<p>RocketMQ 版服务端判定消息产生的顺序性是参照同一生产者发送消息的时序。不同生产者、不同线程并发产生的消息，云消息队列 RocketMQ 版服务端无法判定消息的先后顺序。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//wsNXq03SCB.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n</li>\n<li>\n<p><strong>消息存储</strong></p>\n<p>顺序消息的 Topic 中，每个逻辑队列对应一个物理队列，当消息按照顺序发送到 Topic 中的逻辑队列时，每个分区的消息将按照同样的顺序存储到对应的物理队列中。</p>\n<p>对于 kafka 来讲，1个主题会有多个分区，数据存储在每个分区，分区里文件以 <code>Segment</code> 文件串联起来。</p>\n<p>对于 RocketMQ 来讲 ,  存储模型包含三部分： <strong>数据文件 commitlog</strong> 、<strong>消费文件 consumequeue</strong> 、<strong>索引文件 indexfile</strong>。</p>\n<p>kafka 和 RocketMQ 文件模型很类似，只不过 kafka 的文件数据都会存储在不同的分区里，而 RocketMQ 的数据都存储在 CommitLog 文件里 ，不同的消息会存储在不同的消费队列文件里，便于提升消费者性能（索引）。</p>\n<p>所以我们只需要将特定的消息发送到特定的逻辑队列里，对于 kafka 来讲是分区 partition ，对于 RocketMQ 来讲，就是消费队列 messageQueue 。</p>\n</li>\n<li>\n<p><strong>消息消费</strong></p>\n<p>RocketMQ 按照存储的顺序将消息投递给 Consumer，Consumer 收到消息后也不对消息顺序做任何处理，按照接收到的顺序进行消费。</p>\n<p>Consumer 消费消息时，同一 Sharding Key 的消息使用单线程消费，保证消息消费顺序和存储顺序一致，最终实现消费顺序和发布顺序的一致。</p>\n</li>\n</ul>\n<h3> 4.2. 生产者发送顺序消息</h3>\n<p>下面的代码展示生产者如何发生顺序消息 。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>发送顺序消息需要定制<code>队列选择器 MessageQueueSelector</code>。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>进入 <code>DefaultMQProducerImpl#sendSelectImpl  </code>, 查看顺序消费发送的实现逻辑。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>从上面的顺序消息发送代码，我们得到两点结论：</p>\n<ol>\n<li>顺序消息发送时，需要实现 <code> MessageQueueSelector</code> 的 <code>select</code>方法 ；</li>\n<li>发送顺序消息时，若发送失败没有重试。</li>\n</ol>\n<hr>\n<p>参考文档：</p>\n<blockquote>\n<p>https://developer.aliyun.com/article/918025</p>\n</blockquote>\n",
      "image": "https://javayong.cn/pics/rocketmq/producer.png?b-12",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-17T08:13:01.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 存储模型",
      "url": "https://javayong.cn/mq/rocketmq4/04RocketMQ4_store.html",
      "id": "https://javayong.cn/mq/rocketmq4/04RocketMQ4_store.html",
      "summary": "RocketMQ 优异的性能表现，必然绕不开其优秀的存储模型 。 这篇文章，笔者按照自己的理解 , 尝试分析 RocketMQ 的存储模型，希望对大家有所启发。 1 整体概览 首先温习下 RocketMQ 架构。",
      "content_html": "<p>RocketMQ 优异的性能表现，必然绕不开其优秀的存储模型 。</p>\n<p>这篇文章，笔者按照自己的理解 , 尝试分析 RocketMQ 的存储模型，希望对大家有所启发。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//4IBZMyztpU.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 整体概览</h2>\n<p>首先温习下 RocketMQ 架构。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//XYRrSnhfuT.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>整体架构中包含四种角色 :</p>\n<ul>\n<li>\n<p>Producer ：消息发布的角色，Producer 通过 MQ 的负载均衡模块选择相应的 Broker 集群队列进行消息投递，投递的过程支持快速失败并且低延迟。</p>\n</li>\n<li>\n<p>Consumer ：消息消费的角色，支持以 push 推，pull 拉两种模式对消息进行消费。</p>\n</li>\n<li>\n<p>NameServer ：名字服务是一个非常简单的 Topic 路由注册中心，其角色类似 Dubbo 中的 zookeeper ，支持 Broker 的动态注册与发现。</p>\n</li>\n<li>\n<p>BrokerServer ：Broker 主要负责消息的存储、投递和查询以及服务高可用保证 。</p>\n</li>\n</ul>\n<p>本文的重点在于分析 BrokerServer 的消息存储模型。我们先进入 broker 的文件存储目录 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//AWhYeCz1HL.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消息存储和下面三个文件关系非常紧密：</p>\n<ol>\n<li>\n<p><strong>数据文件 commitlog</strong></p>\n<p>消息主体以及元数据的存储主体 ；</p>\n</li>\n<li>\n<p><strong>消费文件 consumequeue</strong></p>\n<p>消息消费队列，引入的目的主要是提高消息消费的性能 ；</p>\n</li>\n<li>\n<p><strong>索引文件 indexfile</strong></p>\n<p>索引文件，提供了一种可以通过 key 或时间区间来查询消息。</p>\n</li>\n</ol>\n<p>RocketMQ 采用的是混合型的存储结构，Broker 单个实例下所有的队列共用一个数据文件（commitlog）来存储。</p>\n<p>生产者发送消息至 Broker 端，然后 Broker 端使用同步或者异步的方式对消息刷盘持久化，保存至 commitlog 文件中。只要消息被刷盘持久化至磁盘文件 commitlog 中，那么生产者发送的消息就不会丢失。</p>\n<p>Broker 端的后台服务线程会不停地分发请求并异步构建 consumequeue（消费文件）和 indexfile（索引文件）。</p>\n<h2> 2 数据文件</h2>\n<p>RocketMQ 的消息数据都会写入到数据文件中， 我们称之为 commitlog 。</p>\n<p><strong>所有的消息都会顺序写入数据文件，当文件写满了，会写入下一个文件</strong>。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//OXCR8q0haW.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>如上图所示，单个文件大小默认 1G , 文件名长度为 20 位，左边补零，剩余为起始偏移量，比如 00000000000000000000 代表了第一个文件，起始偏移量为 0 ，文件大小为1 G = 1073741824。</p>\n<p>当第一个文件写满了，第二个文件为 00000000001073741824，起始偏移量为 1073741824，以此类推。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//gzN5dRWsG7.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>从上图中，我们可以看到消息是一条一条写入到文件，每条消息的格式是固定的。</p>\n<p>这样设计有三点优势：</p>\n<ol>\n<li>\n<p>顺序写</p>\n<p>磁盘的存取速度相对内存来讲并不快，一次磁盘 IO 的耗时主要取决于：寻道时间和盘片旋转时间，提高磁盘 IO 性能最有效的方法就是：减少随机 IO，增加顺序 IO 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//EjZJC7giv1.webp!large\" alt=\"对比随机和顺序读写在内存和磁盘中的表现\" tabindex=\"0\"><figcaption>对比随机和顺序读写在内存和磁盘中的表现</figcaption></figure>\n<p>《 The Pathologies of Big Data 》这篇文章指出：内存随机读写的速度远远低于磁盘顺序读写的速度。磁盘顺序写入速度可以达到几百兆/s，而随机写入速度只有几百 KB /s，相差上千倍。</p>\n</li>\n<li>\n<p>快速定位</p>\n<p>因为消息是一条一条写入到 commitlog 文件 ，写入完成后，我们可以得到这条消息的物理偏移量。</p>\n<p>每条消息的物理偏移量是唯一的， commitlog 文件名是递增的，可以根据消息的物理偏移量通过<strong>二分查找</strong>，定位消息位于那个文件中，并获取到消息实体数据。</p>\n</li>\n<li>\n<p>通过消息 offsetMsgId 查询消息数据</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//xphlePAVT9.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消息 offsetMsgId 是由 Broker 服务端在写入消息时生成的 ，该消息编号包含两个部分：</p>\n<ul>\n<li>\n<p>Broker 服务端 ip + port  8个字节；</p>\n</li>\n<li>\n<p>commitlog 物理偏移量 8个字节 。</p>\n</li>\n</ul>\n<p>我们可以通过消息 offsetMsgId ，定位到 Broker 的 ip 地址 + 端口 ，传递物理偏移量参数 ，即可定位该消息实体数据。</p>\n</li>\n</ol>\n<h2> 3 消费文件</h2>\n<p>在介绍 consumequeue 文件之前， 我们先温习下消息队列的传输模型-<strong>发布订阅模型</strong> ， 这也是 RocketMQ 当前的传输模型。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//reIMgPJi1b.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>发布订阅模型具有如下特点：</p>\n<ul>\n<li>消费独立：相比队列模型的匿名消费方式，发布订阅模型中消费方都会具备的身份，一般叫做订阅组（订阅关系），不同订阅组之间相互独立不会相互影响。</li>\n<li>一对多通信：基于独立身份的设计，同一个主题内的消息可以被多个订阅组处理，每个订阅组都可以拿到全量消息。因此发布订阅模型可以实现一对多通信。</li>\n</ul>\n<p>因此，<strong>rocketmq 的文件设计必须满足发布订阅模型的需求。</strong></p>\n<p>那么仅仅 commitlog 文件是否可以满足需求吗 ？</p>\n<p>假如有一个 consumerGroup 消费者，订阅主题 my-mac-topic ，因为 commitlog 包含所有的消息数据，查询该主题下的消息数据，需要遍历数据文件 commitlog , 这样的效率是极其低下的。</p>\n<p>进入 rocketmq 存储目录，显示见下图：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//E7tgMi1WhB.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ol>\n<li>消费文件按照主题存储，每个主题下有不同的队列，图中 my-mac-topic 有 16 个队列 ;</li>\n<li>每个队列目录下 ，存储 consumequeue 文件，每个 consumequeue 文件也是顺序写入，数据格式见下图。</li>\n</ol>\n<figure><img src=\"https://www.javayong.cn/pics/temp//o4BiIVsDSs.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>每个 consumequeue 包含 30 万个条目，每个条目大小是 20 个字节，每个文件的大小是 30 万 * 20 = 60万字节，每个文件大小约5.72M 。和 commitlog 文件类似，consumequeue 文件的名称也是以偏移量来命名的，可以通过消息的逻辑偏移量定位消息位于哪一个文件里。</p>\n<p>消费文件按照<strong>主题-队列</strong>来保存 ，这种方式特别适配<strong>发布订阅模型</strong>。</p>\n<p>消费者从 broker 获取订阅消息数据时，不用遍历整个 commitlog 文件，只需要根据逻辑偏移量从 consumequeue 文件查询消息偏移量 ,  最后通过定位到 commitlog 文件， 获取真正的消息数据。</p>\n<p>这样就可以简化消费查询逻辑，同时因为同一主题下，消费者可以订阅不同的队列或者 tag ，同时提高了系统的可扩展性。</p>\n<h2> 4 索引文件</h2>\n<p>每个消息在业务层面的唯一标识码要设置到 keys 字段，方便将来定位消息丢失问题。服务器会为每个消息创建索引（哈希索引），应用可以通过 topic、key 来查询这条消息内容，以及消息被谁消费。</p>\n<p>由于是哈希索引，请务必保证key尽可能唯一，这样可以避免潜在的哈希冲突。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>从开源的控制台中根据主题和 key 查询消息列表：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//6OMAGHF1zX.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>进入索引文件目录 ，如下图所以：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//03v6Z5ZaES.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>索引文件名 fileName 是以创建时的时间戳命名的，固定的单个 IndexFile 文件大小约为 400 M 。</p>\n<p>IndexFile 的文件逻辑结构类似于 JDK 的 HashMap 的<strong>数组加链表</strong>结构。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//HBvvQgemjK.webp!large\" alt=\"HashMap数据结构\" tabindex=\"0\"><figcaption>HashMap数据结构</figcaption></figure>\n<p>索引文件主要由 Header、Slot Table (默认 500 万个条目)、Index Linked List（默认最多包含 2000万个条目）三部分组成 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//iigZg4mGG2.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>假如订单系统发送两条消息 A 和 B , 他们的 key 都是 \"1234567890\" ，我们依次存储消息 A  ,  消息 B 。</p>\n<p>因为这两个消息的 key 的 hash 值相同，它们对应的哈希槽（深黄色）也会相同，哈希槽会保存的最新的消息 B 的索引条目序号 , 序号值是 4 ，也就是第二个深绿色条目。</p>\n<p>而消息 B 的索引条目信息的最后 4 个字节会保存上一条消息对应的索引条目序号，索引序号值是 3  , 也就是消息 A 。</p>\n<h2> 5 写到最后</h2>\n<blockquote>\n<p>Databases are specializing – the “one size fits all” approach no longer applies ------ MongoDB设计哲学</p>\n</blockquote>\n<p>RocketMQ 存储模型设计得非常精巧，笔者觉得每种设计都有其底层思考，这里总结了三点 ：</p>\n<ol>\n<li>完美适配消息队列发布订阅模型 ；</li>\n<li>数据文件，消费文件，索引文件各司其职 ，同时以数据文件为核心，异步构建消费文件 + 索引文件这种模式非常容易扩展到主从复制的架构；</li>\n<li>充分考虑业务的查询场景，支持消息 key ，消息 offsetMsgId 查询消息数据。也支持消费者通过 tag 来订阅主题下的不同消息，提升了消费者的灵活性。</li>\n</ol>\n",
      "image": "https://www.javayong.cn/pics/temp//4IBZMyztpU.webp!large",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-17T07:53:52.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 消费者",
      "url": "https://javayong.cn/mq/rocketmq4/06RocketMQ4_consumer.html",
      "id": "https://javayong.cn/mq/rocketmq4/06RocketMQ4_consumer.html",
      "summary": "RocketMQ 是笔者非常喜欢的消息队列，4.9.X 版本是目前使用最广泛的版本，但它的消费逻辑相对较重，很多同学学习起来没有头绪。 这篇文章，笔者梳理了 RocketMQ 的消费逻辑，希望对大家有所启发。 1 架构概览 在展开集群消费逻辑细节前，我们先对 RocketMQ 4.X 架构做一个概览。",
      "content_html": "<p>RocketMQ 是笔者非常喜欢的消息队列，4.9.X 版本是目前使用最广泛的版本，但它的消费逻辑相对较重，很多同学学习起来没有头绪。</p>\n<p>这篇文章，笔者梳理了 RocketMQ 的消费逻辑，希望对大家有所启发。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//qaRc3GjFlL.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 架构概览</h2>\n<p>在展开集群消费逻辑细节前，我们先对 RocketMQ 4.X 架构做一个概览。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//WmCfyfFaPD-20231117160806702.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>整体架构中包含<strong>四种角色</strong> :</p>\n<p><strong>1、NameServer</strong></p>\n<p>名字服务是是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。它是一个非常简单的 Topic 路由注册中心，其角色类似 Dubbo 中的 zookeeper ，支持 Broker 的动态注册与发现。</p>\n<p><strong>2、BrokerServer</strong></p>\n<p>Broker 主要负责消息的存储、投递和查询以及服务高可用保证 。</p>\n<p><strong>3、Producer</strong></p>\n<p>消息发布的角色，Producer 通过 MQ 的负载均衡模块选择相应的 Broker 集群队列进行消息投递，投递的过程支持快速失败并且低延迟。</p>\n<p><strong>4、Consumer</strong></p>\n<p>消息消费的角色，支持以 push 推，pull 拉两种模式对消息进行消费。</p>\n<p>RocketMQ 集群工作流程：</p>\n<p>1、<strong>启动 NameServer</strong>，NameServer 起来后监听端口，等待 Broker、Producer 、Consumer 连上来，相当于一个路由控制中心。</p>\n<p>2、<strong>Broker 启动</strong>，跟所有的 NameServer 保持长连接，定时发送心跳包。心跳包中包含当前 Broker信息( IP+端口等 )以及存储所有 Topic 信息。注册成功后，NameServer 集群中就有 Topic 跟 Broker 的映射关系。</p>\n<p>3、收发消息前，先<strong>创建 Topic</strong>，创建 Topic 时需要指定该 Topic 要存储在哪些 Broker 上，也可以在发送消息时自动创建 Topic。</p>\n<p>4、<strong>Producer 发送消息</strong>，启动时先跟 NameServer 集群中的其中一台建立长连接，并从 NameServer 中获取当前发送的 Topic 存在哪些 Broker 上，轮询从队列列表中选择一个队列，然后与队列所在的 Broker 建立长连接从而向 Broker 发消息。</p>\n<p>5、Consumer 跟 Producer 类似，跟其中一台 NameServer 建立长连接，获取当前订阅 Topic 存在哪些 Broker 上，然后直接跟 Broker 建立连接通道，开始<strong>消费消息</strong>。</p>\n<h2> 2 发布订阅</h2>\n<p>RocketMQ 的传输模型是：<strong>发布订阅模型</strong> 。</p>\n<p>发布订阅模型具有如下特点：</p>\n<ul>\n<li>\n<p><strong>消费独立</strong></p>\n<p>相比队列模型的匿名消费方式，发布订阅模型中消费方都会具备的身份，一般叫做订阅组（订阅关系），不同订阅组之间相互独立不会相互影响。</p>\n</li>\n<li>\n<p><strong>一对多通信</strong></p>\n<p>基于独立身份的设计，同一个主题内的消息可以被多个订阅组处理，每个订阅组都可以拿到全量消息。因此发布订阅模型可以实现一对多通信。</p>\n</li>\n</ul>\n<p>RocketMQ 支持两种消息模式：<strong>集群消费</strong>（ Clustering ）和<strong>广播消费</strong>（ Broadcasting ）。</p>\n<p><strong>集群消费</strong>：<strong>同一 Topic 下的一条消息只会被同一消费组中的一个消费者消费</strong>。也就是说，消息被负载均衡到了同一个消费组的多个消费者实例上。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//YB1Famn1EF.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>广播消费</strong>：当使用广播消费模式时，每条消息推送给集群内所有的消费者，保证消息至少被每个消费者消费一次。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//32GDhELg1w.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>为了实现这种发布订阅模型 ， RocketMQ 精心设计了它的存储模型。先进入 Broker 的文件存储目录。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//AWhYeCz1HL-20231117160806691.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>RocketMQ 采用的是<strong>混合型</strong>的存储结构。</p>\n<p><strong>1、Broker 单个实例下所有的队列共用一个数据文件（commitlog）来存储</strong></p>\n<p>生产者发送消息至 Broker 端，然后 Broker 端使用同步或者异步的方式对消息刷盘持久化，保存至 commitlog 文件中。只要消息被刷盘持久化至磁盘文件 commitlog 中，那么生产者发送的消息就不会丢失。</p>\n<p>单个文件大小默认 1G , 文件名长度为 20 位，左边补零，剩余为起始偏移量，比如 00000000000000000000 代表了第一个文件，起始偏移量为 0 ，文件大小为1 G = 1073741824 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//OXCR8q0haW-20231117160806755.webp!large\" alt=\" commitlog 目录\" tabindex=\"0\"><figcaption> commitlog 目录</figcaption></figure>\n<p>这种设计有两个优点：</p>\n<ul>\n<li>\n<p>充分利用顺序写，大大提升写入数据的吞吐量；</p>\n</li>\n<li>\n<p>快读定位消息。</p>\n<p>因为消息是一条一条写入到 commitlog 文件 ，写入完成后，我们可以得到这条消息的<strong>物理偏移量</strong>。</p>\n<p>每条消息的物理偏移量是唯一的， commitlog 文件名是递增的，可以根据消息的物理偏移量通过<strong>二分查找</strong>，定位消息位于那个文件中，并获取到消息实体数据。</p>\n</li>\n</ul>\n<p><strong>2、Broker 端的后台服务线程会不停地分发请求并异步构建 consumequeue（消费文件）和 indexfile（索引文件）</strong></p>\n<p>进入消费文件存储目录 ：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//E7tgMi1WhB-20231117160806719.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>1、消费文件按照主题存储，每个主题下有不同的队列，图中主题 my-mac-topic 有 16 个队列 (0 到 15) ;</p>\n<p>2、每个队列目录下 ，存储 consumequeue 文件，每个 consumequeue 文件也是顺序写入，数据格式见下图。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//1y4ZNBbc3K.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>每个 consumequeue 文件包含 30 万个条目，每个条目大小是 20 个字节，每个文件的大小是 30 万 * 20 = 60万字节，每个文件大小约 5.72M 。</p>\n<p>和 commitlog 文件类似，consumequeue 文件的名称也是以偏移量来命名的，可以通过消息的逻辑偏移量定位消息位于哪一个文件里。</p>\n<p>消费文件按照<strong>主题-队列</strong>来保存 ，这种方式特别适配<strong>发布订阅模型</strong>。</p>\n<p>消费者从 Broker 获取订阅消息数据时，不用遍历整个 commitlog 文件，只需要根据逻辑偏移量从 consumequeue 文件查询消息偏移量 , 最后通过定位到 commitlog 文件， 获取真正的消息数据。</p>\n<p>要实现发布订阅模型，还需要一个重要文件：<strong>消费进度</strong>文件。原因有两点：</p>\n<ul>\n<li>\n<p>不同消费组之间相互独立，不会相互影响 ；</p>\n</li>\n<li>\n<p>消费者下次拉取数据时，需要知道从哪个进度开始拉取 ，就像我们小时候玩单机游戏存盘一样。</p>\n</li>\n</ul>\n<p>因此消费进度文件需要保存消费组所订阅主题的消费进度。</p>\n<p>我们浏览下集群消费场景下的 Broker 端的消费进度文件 <strong>consumerOffset.json</strong> 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//KdhMCdYePf.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://www.javayong.cn/pics/temp//jpfI145dyQ.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>在进度文件 consumerOffset.json 里，数据以 key-value 的结构存储，key 表示：主题@消费者组 ， value 是 consumequeue 中每个队列对应的逻辑偏移量 。</p>\n<p>写到这里，我们<strong>粗糙模拟</strong>下 RocketMQ <strong>存储模型如何满足发布订阅模型</strong> 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//cnRQMAQDa2.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>1、<strong>发送消息</strong>：生产者发送消息到 Broker ；</p>\n<p>2、<strong>保存消息</strong>：Broker 将消息存储到 commitlog 文件 ，异步线程会构建消费文件 consumequeue ；</p>\n<p>3、<strong>消费流程</strong>：消费者启动后，会通过负载均衡分配对应的队列，然后向 Broker 发送拉取消息请求。Broker 收到消费者拉取请求之后，根据订阅组，消费者编号，主题，队列名，逻辑偏移量等参数 ，从该主题下的 consumequeue 文件查询消息消费条目，然后从 commitlog 文件中获取消息实体。消费者在收到消息数据之后，执行消费监听器，消费完消息；</p>\n<p>4、<strong>保存进度</strong>：消费者将消费进度提交到 Broker ，Broker 会将该消费组的消费进度存储在进度文件里。</p>\n<h2> 3 消费流程</h2>\n<p>我们重点讲解下集群消费的消费流程 ，因为<strong>集群消费是使用最普遍的消费模式</strong>，理解了集群消费，广播消费也就能顺理成章的掌握了。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//JMHeWL51md.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>集群消费示例代码里，启动消费者，我们需要配置三个核心属性：<strong>消费组名</strong>、<strong>订阅主题</strong>、<strong>消息监听器</strong>，最后调用 start 方法启动。</p>\n<p>首先进入 <code>DefaultMQPushConsumerImpl</code> 类的 <code>start</code> 方法 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//pushconsumerstart.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费者启动后，我们可以将整个流程简化成：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//consumerliucheng.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 4 负载均衡</h2>\n<p>消费端的负载均衡是指<strong>将 Broker 端中多个队列按照某种算法分配给同一个消费组中的不同消费者，负载均衡是客户端开始消费的起点</strong>。</p>\n<p>RocketMQ 负载均衡的<strong>核心设计理念</strong>是</p>\n<ul>\n<li>\n<p>消费队列在同一时间只允许被同一消费组内的一个消费者消费</p>\n</li>\n<li>\n<p>一个消费者能同时消费多个消息队列</p>\n</li>\n</ul>\n<p>负载均衡是每个<strong>客户端独立进行计算</strong>，那么何时触发呢 ？</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//yxd8EaU0qS.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ul>\n<li>\n<p>消费端启动时，立即进行负载均衡；</p>\n</li>\n<li>\n<p>消费端定时任务每隔 20 秒触发负载均衡；</p>\n</li>\n<li>\n<p>消费者上下线，Broker 端通知消费者触发负载均衡。</p>\n</li>\n</ul>\n<p>负载均衡流程如下：</p>\n<p><strong>1、发送心跳</strong></p>\n<p>消费者启动后，它就会通过定时任务不断地向 RocketMQ 集群中的所有 Broker 实例发送心跳包（<strong>消息消费分组名称</strong>、<strong>订阅关系集合</strong>、<strong>消息通信模式</strong>和<strong>客户端实例编号</strong>等信息）。</p>\n<p>Broker 端在收到消费者的心跳消息后，会将它维护在 ConsumerManager 的本地缓存变量 consumerTable，同时并将封装后的客户端网络<strong>通道信息</strong>保存在本地缓存变量 channelInfoTable 中，为之后做消费端的负载均衡提供可以依据的元数据信息。</p>\n<p><strong>2、启动负载均衡服务</strong></p>\n<p>负载均衡服务会根据消费模式为”广播模式”还是“集群模式”做不同的逻辑处理，这里主要来看下集群模式下的主要处理流程：</p>\n<p>(1) 获取该主题下的消息消费队列集合；</p>\n<p>(2) 查询 Broker 端获取该消费组下消费者 Id 列表；</p>\n<p>(3) 先对 Topic 下的消息消费队列、消费者 Id 排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列；</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//iYLyVcUAt4.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://www.javayong.cn/pics/temp//4OHEa2jquR.webp!large\" alt=\"平均分配算法\" tabindex=\"0\"><figcaption>平均分配算法</figcaption></figure>\n<p>这里的平均分配算法，类似于分页的算法，将所有 MessageQueue 排好序类似于记录，将所有消费端排好序类似页数，并求出每一页需要包含的平均 size 和每个页面记录的范围 range ，最后遍历整个 range 而计算出当前消费端应该分配到的记录。</p>\n<p>(4) 分配到的消息队列集合与 processQueueTable 做一个过滤比对操作。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//xs0dDuzfwc.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费者实例内 ，processQueueTable 对象存储着当前负载均衡的队列 ，以及该队列的处理队列 processQueue (消费快照)。</p>\n<ol>\n<li>\n<p>标红的 Entry 部分表示与分配到的消息队列集合互不包含，则需要将这些红色队列 Dropped 属性为 true , 然后从 processQueueTable 对象中移除。</p>\n</li>\n<li>\n<p>绿色的 Entry 部分表示与分配到的消息队列集合的交集，processQueueTable 对象中已经存在该队列。</p>\n</li>\n<li>\n<p>黄色的 Entry 部分表示这些队列需要添加到 processQueueTable 对象中，为每个分配的新队列创建一个消息拉取请求 <code>pullRequest</code> , 在消息拉取请求中保存一个处理队列 <code>processQueue</code> （队列消费快照），内部是红黑树（<code>TreeMap</code>），用来保存拉取到的消息。</p>\n</li>\n</ol>\n<p>最后创建拉取消息请求列表，并<strong>将请求分发到消息拉取服务，进入拉取消息环节</strong>。</p>\n<h2> 5 长轮询</h2>\n<p>在负载均衡这一小节，我们已经知道<strong>负载均衡触发了拉取消息的流程</strong>。</p>\n<p>消费者启动的时候，会创建一个<strong>拉取消息服务 PullMessageService</strong> ，它是一个单线程的服务。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//9lQ0kqqgMV.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>核心流程如下：</p>\n<p>1、负载均衡服务将消息拉取请求放入到拉取请求队列 pullRequestQueue , 拉取消息服务从队列中获取<strong>拉取消息请求</strong> ；</p>\n<p>2、拉取消息服务向 Brorker 服务发送拉取请求 ，拉取请求的通讯模式是<strong>异步回调模式</strong> ;</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//wU7kAPifpi.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费者的拉取消息服务本身就是一个单线程，使用异步回调模式，发送拉取消息请求到 Broker 后，<strong>拉取消息线程并不会阻塞</strong> ，可以继续处理队列 pullRequestQueue 中的其他拉取任务。</p>\n<p>3、Broker 收到消费者拉取消息请求后，从存储中查询出消息数据，然后返回给消费者；</p>\n<p>4、消费者的网络通讯层会执行<strong>拉取回调函数</strong>相关逻辑，首先会将消息数据存储在队列消费快照 processQueue 里；</p>\n<p>消费快照使用<strong>红黑树 msgTreeMap</strong> 存储拉取服务拉取到的消息 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//XdYYK2Hqk2.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>5、回调函数将<strong>消费请求</strong>提交到<strong>消息消费服务</strong> ，而消息消费服务会<strong>异步</strong>的消费这些消息；</p>\n<p>6、回调函数会将处理中队列的拉取请放入到定时任务中；</p>\n<p>7、定时任务再次将消息拉取请求放入到队列 pullRequestQueue 中，<strong>形成了闭环</strong>：负载均衡后的队列总会有任务执行拉取消息请求，不会中断。</p>\n<p>细心的同学肯定有疑问：<strong>既然消费端是拉取消息，为什么是长轮询呢</strong> ？</p>\n<p>虽然拉模式的主动权在消费者这一侧，但是缺点很明显。</p>\n<p>因为消费者并不知晓 Broker 端什么时候有新的消息 ，所以会不停地去 Broker 端拉取消息，但拉取频率过高， Broker 端压力就会很大，频率过低则会导致消息延迟。</p>\n<p>所以<strong>要想消费消息的延迟低，服务端的推送必不可少</strong>。</p>\n<p>下图展示了 RocketMQ 如何通过长轮询减小拉取消息的延迟。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//c53QfosbB2.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>核心流程如下：</p>\n<p>1、Broker 端接收到消费者的拉取消息请求后，拉取消息处理器开始处理请求，根据拉取请求查询消息存储 ；</p>\n<p>2、从消息存储中获取消息数据 ，若存在新消息 ，则将消息数据通过网络返回给消费者。若无新消息，则将拉取请求放入到<strong>拉取请求表 pullRequestTable</strong> 。</p>\n<p>3、<strong>长轮询请求管理服务</strong> pullRequestHoldService 每隔 5 秒从拉取请求表中判断拉取消息请求的队列是否有新的消息。</p>\n<p>判定标准是：拉取消息请求的偏移量是否小于当前消费队列最大偏移量，如果条件成立则说明有新消息了。</p>\n<p>若存在新的消息 , <strong>长轮询请求管理服务</strong>会触发拉取消息处理器重新处理该拉取消息请求。</p>\n<p>4、当 commitlog 中新增了新的消息，消息分发服务会构建消费文件和索引文件，并且会通知<strong>长轮询请求管理服务</strong>，触发<strong>拉取消息处理器重新处理该拉取消息请求</strong>。</p>\n<h2> 6 消费消息</h2>\n<p>在拉取消息的流程里， Broker 端返回消息数据，消费者的通讯框架层会执行回调函数。</p>\n<p>回调线程会将数据存储在队列消费快照 processQueue（内部使用<strong>红黑树 msgTreeMap</strong>）里，然后将消息提交到消费消息服务，消费消息服务会异步消费这些消息。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//aWJXs9ZF6L.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消息消费服务有两种类型：<strong>并发消费服务</strong>和<strong>顺序消费服务</strong> 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//FC4h3oP2zB.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h3> 6.1 并发消费</h3>\n<p>并发消费是指<strong>消费者将并发消费消息，消费的时候可能是无序的</strong>。</p>\n<p>消费消息并发服务启动后，会初始化三个组件：<strong>消费线程池</strong>、<strong>清理过期消息定时任务</strong>、<strong>处理失败消息定时任务</strong>。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//7ZT6DQW1K1.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>核心流程如下：</p>\n<p><strong>0、通讯框架回调线程会将数据存储在消费快照里，然后将消息列表 msgList 提交到消费消息服务</strong></p>\n<p><strong>1、 消息列表 msgList 组装成消费对象</strong></p>\n<p><strong>2、将消费对象提交到消费线程池</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//B1tBLvh3fV.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>我们看到10 条消息被组装成三个消费请求对象，不同的消费线程会执行不同的消费请求对象。</p>\n<p><strong>3、消费线程执行消息监听器</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//CK2wsCfJg3.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>执行完消费监听器，会返回消费结果。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//m2OC0khwGU.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>4、处理异常消息</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//V4g5vXlLc7.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>当消费异常时，异常消息将重新发回 Broker 端的重试队列（ RocketMQ 会为每个 topic 创建一个重试队列，以 %RETRY% 开头），达到重试时间后将消息投递到重试队列中进行消费重试。</p>\n<blockquote>\n<p>我们将在<strong>重试机制</strong>这一节重点讲解 RocketMQ 如何实现延迟消费功能 。</p>\n</blockquote>\n<p>假如异常的消息发送到 Broker 端失败，则重新将这些失败消息通过<strong>处理失败消息定时任务</strong>重新提交到消息消费服务。</p>\n<p><strong>5、更新本地消费进度</strong></p>\n<p>消费者消费一批消息完成之后，需要保存消费进度到进度管理器的本地内存。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//4UWT3ECS5W.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>首先我们会从队列消费快照 processQueue 中移除消息，返回消费快照 msgTreeMap 第一个偏移量 ，然后调用消费消息进度管理器 offsetStore 更新消费进度。</p>\n<p><strong>待更新的偏移量</strong>是如何计算的呢？</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//Br4RznOnaN.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ul>\n<li>\n<p>场景1：快照中1001（消息1）到1010（消息10）消费了，快照中没有了消息，返回已消费的消息最大偏移量 + 1 也就是1011。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//5Nhp8CddxY.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n</li>\n<li>\n<p>场景2：快照中1001（消息1）到1008（消息8）消费了，快照中只剩下两条消息了，返回最小的偏移量 1009。</p>\n</li>\n</ul>\n<figure><img src=\"https://www.javayong.cn/pics/temp//kdKZew4JsR.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ul>\n<li>场景3：1001（消息1）在消费对象中因为某种原因一直没有被消费，即使后面的消息1005-1010都消费完成了，返回的最小偏移量是1001。</li>\n</ul>\n<figure><img src=\"https://www.javayong.cn/pics/temp//1N0EP94TWG.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>在场景3，RocketMQ 为了保证消息肯定被消费成功，消费进度只能维持在1001（消息1），直到1001也被消费完，本地的消费进度才会一下子更新到1011。</p>\n<p>假设1001（消息1）还没有消费完成，消费者实例<strong>突然退出（机器断电，或者被 kill ）</strong>，就存在重复消费的风险。</p>\n<p>因为队列的消费进度还是维持在1001，当队列重新被分配给新的消费者实例的时候，新的实例从 Broker 上拿到的消费进度还是维持在1001，这时候就会又从1001开始消费，1001-1010这批消息实际上已经被消费过还是会投递一次。</p>\n<p>所以<strong>业务必须要保证消息消费的幂等性</strong>。</p>\n<p>写到这里，我们会有一个疑问：<strong>假设1001（消息1）因为加锁或者消费监听器逻辑非常耗时，导致极长时间没有消费完成，那么消费进度就会一直卡住 ，怎么解决呢 ？</strong></p>\n<p>RocketMQ 提供两种方式一起配合解决：</p>\n<ul>\n<li>\n<p><strong>拉取服务根据并发消费间隔配置限流</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//1h0U1AjiN1.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>拉取消息服务在拉取消息时候，会判断当前队列的 processQueue 消费快照里消息的最大偏移量 - 消息的最小偏移量大于消费并发间隔（2000）的时候 , 就会触发流控 , 这样就可以避免消费者无限循环的拉取新的消息。</p>\n</li>\n<li>\n<p><strong>清理过期消息</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//MvanDXLXjS.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费消息并发服务启动后，会定期扫描所有消费的消息，若当前时间减去开始消费的时间大于消费超时时间，首先会将过期消息发送 sendMessageBack 命令发送到 Broker ，然后从快照中删除该消息。</p>\n</li>\n</ul>\n<h3> 6.2 顺序消费</h3>\n<p>顺序消息是指对于一个指定的 Topic ，消息严格按照先进先出（FIFO）的原则进行消息发布和消费，即先发布的消息先消费，后发布的消息后消费。</p>\n<p>顺序消息分为<strong>分区顺序消息</strong>和<strong>全局顺序消息</strong>。</p>\n<p><strong>1、分区顺序消息</strong></p>\n<p>对于指定的一个 Topic ，所有消息根据 Sharding Key 进行区块分区，同一个分区内的消息按照严格的先进先出（FIFO）原则进行发布和消费。同一分区内的消息保证顺序，不同分区之间的消息顺序不做要求。</p>\n<ul>\n<li>\n<p>适用场景：适用于性能要求高，以 Sharding Key 作为分区字段，在同一个区块中严格地按照先进先出（FIFO）原则进行消息发布和消费的场景。</p>\n</li>\n<li>\n<p>示例：电商的订单创建，以订单 ID 作为 Sharding Key ，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照发布的先后顺序来消费。</p>\n</li>\n</ul>\n<p><strong>2、全局顺序消息</strong></p>\n<p>对于指定的一个 Topic ，所有消息按照严格的先入先出（FIFO）的顺序来发布和消费。</p>\n<ul>\n<li>\n<p>适用场景：适用于性能要求不高，所有的消息严格按照 FIFO 原则来发布和消费的场景。</p>\n</li>\n<li>\n<p>示例：在证券处理中，以人民币兑换美元为 Topic，在价格相同的情况下，先出价者优先处理，则可以按照 FIFO 的方式发布和消费全局顺序消息。</p>\n</li>\n</ul>\n<blockquote>\n<p>全局顺序消息实际上是一种特殊的分区顺序消息，即 Topic 中只有一个分区，因此<strong>全局顺序和分区顺序的实现原理相同</strong>。</p>\n<p>因为分区顺序消息有多个分区，所以<strong>分区顺序消息比全局顺序消息的并发度和性能更高</strong>。</p>\n</blockquote>\n<figure><img src=\"https://www.javayong.cn/pics/temp//wsNXq03SCB.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消息的顺序需要由两个阶段保证：</p>\n<ul>\n<li>\n<p><strong>消息发送</strong></p>\n<p>如上图所示，A1、B1、A2、A3、B2、B3 是订单 A 和订单 B 的消息产生的顺序，业务上要求同一订单的消息保持顺序，例如订单 A 的消息发送和消费都按照 A1、A2、A3 的顺序。</p>\n<p>如果是普通消息，订单A 的消息可能会被轮询发送到不同的队列中，不同队列的消息将无法保持顺序，而顺序消息发送时 RocketMQ 支持将 Sharding Key 相同（例如同一订单号）的消息序路由到同一个队列中。</p>\n<p>下图是生产者发送顺序消息的封装，原理是发送消息时，实现 MessageQueueSelector 接口， <strong>根据 Sharding Key 使用 Hash 取模法来</strong>选择待发送的队列。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//zmZRavOqOB.webp!large\" alt=\"生产者顺序发送消息封装\" tabindex=\"0\"><figcaption>生产者顺序发送消息封装</figcaption></figure>\n</li>\n<li>\n<p><strong>消息消费</strong></p>\n<p>消费者消费消息时，需要保证<strong>单线程</strong>消费每个队列的消息数据，从而实现消费顺序和发布顺序的一致。</p>\n</li>\n</ul>\n<p>顺序消费服务的类是 <strong>ConsumeMessageOrderlyService</strong> ，在负载均衡阶段，并发消费和顺序消费并没有什么大的差别。</p>\n<p>最大的差别在于：<strong>顺序消费会向 Borker 申请锁</strong> 。消费者根据分配的队列 messageQueue ，向 Borker 申请锁 ，如果申请成功，则会拉取消息，如果失败，则定时任务每隔20秒会重新尝试。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//RYjgvNzqYU.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>顺序消费核心流程如下：</p>\n<p><strong>1、 组装成消费对象</strong></p>\n<p><strong>2、 将请求对象提交到消费线程池</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//L0Fg8TEUfu.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>和并发消费不同的是，这里的消费请求包含消费快照 processQueue ，消息队列 messageQueue 两个对象，并不对消息列表做任何处理。</p>\n<p><strong>3、 消费线程内，对消费队列加锁</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//BSgV66dvT9.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>顺序消费也是通过线程池消费的，synchronized 锁用来保证同一时刻对于同一个队列只有一个线程去消费它</strong></p>\n<p><strong>4、 从消费快照中取得待消费的消息列表</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//fw62aVv3ei.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费快照 processQueue 对象里，创建了一个红黑树对象 consumingMsgOrderlyTreeMap 用于临时存储的待消费的消息。</p>\n<p><strong>5、 执行消息监听器</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//htlZQC5Egi.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费快照的<strong>消费锁 consumeLock</strong> 的作用是：防止负载均衡线程把当前消费的 MessageQueue 对象移除掉。</p>\n<p><strong>6、 处理消费结果</strong></p>\n<p>消费成功时，首先计算需要提交的偏移量，然后更新本地消费进度。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//05kFcsIfVN.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费失败时，分两种场景：</p>\n<ul>\n<li>\n<p>假如已消费次数小于最大重试次数，则将对象 consumingMsgOrderlyTreeMap 中临时存储待消费的消息，重新加入到消费快照<strong>红黑树 msgTreeMap</strong> 中，然后使用定时任务尝试重新消费。</p>\n</li>\n<li>\n<p>假如已消费次数大于等于最大重试次数，则将失败消息发送到 Broker ，Broker 接收到消息后，会加入到死信队列里 , 最后计算需要提交的偏移量，然后更新本地消费进度。</p>\n</li>\n</ul>\n<p>我们做一个关于顺序消费的总结 ：</p>\n<ol>\n<li>\n<p>顺序消费需要由两个阶段<strong>消息发送</strong>和<strong>消息消费</strong>协同配合，底层支撑依靠的是 RocketMQ 的存储模型；</p>\n</li>\n<li>\n<p>顺序消费服务启动后，队列的数据都会被消费者实例单线程的执行消费；</p>\n</li>\n<li>\n<p>假如消费者扩容，消费者重启，或者 Broker 宕机 ，顺序消费也会有一定几率较短时间内乱序，所以消费者的业务逻辑还是要<strong>保障幂等</strong>。</p>\n</li>\n</ol>\n<h2> 7 保存进度</h2>\n<p>RocketMQ 消费者消费完一批数据后， 会将队列的进度保存在本地内存，但还需要将队列的消费进度持久化。</p>\n<p><strong>1、 集群模式</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//lIlhh7LCc4.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>集群模式下，分两种场景：</p>\n<ul>\n<li>\n<p>拉取消息服务会在拉取消息时，携带该队列的消费进度，提交给 Broker 的<strong>拉取消息处理器</strong>。</p>\n</li>\n<li>\n<p>消费者定时任务，每隔5秒将本地缓存中的消费进度提交到 Broker 的<strong>消费者管理处理器</strong>。</p>\n</li>\n</ul>\n<p>Broker 的这两个处理器都调用消费者进度管理器 consumerOffsetManager 的 commitOffset 方法，定时任务异步将消费进度持久化到消费进度文件 consumerOffset.json 中。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//jpfI145dyQ.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>2、 广播模式</strong></p>\n<p>广播模式消费进度存储在消费者本地，定时任务每隔 5 秒通过 LocalFileOffsetStore 持久化到本地文件<code>offsets.json</code> ，数据格式为 <code>MessageQueue:Offset</code>。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//VDuc9BZwz3.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>广播模式下，消费进度和消费组没有关系，本地文件 <code>offsets.json</code> 存储在配置的目录，文件中包含订阅主题中所有的队列以及队列的消费进度。</p>\n<h2> 8 重试机制</h2>\n<p>集群消费下，<strong>重试机制</strong>的本质是 RocketMQ 的延迟消息功能。</p>\n<p>消费消息失败后，消费者实例会通过 <strong>CONSUMER_SEND_MSG_BACK</strong> 请求，将失败消息发回到 Broker 端。</p>\n<p>Broker 端会为每个 topic 创建一个<strong>重试队列</strong> ，队列名称是：%RETRY% + 消费者组名 ，达到重试时间后将消息投递到重试队列中进行消费重试（消费者组会自动订阅重试 Topic）。最多重试消费 16 次，重试的时间间隔逐渐变长，若达到最大重试次数后消息还没有成功被消费，则消息将被投递至死信队列。</p>\n<table>\n<thead>\n<tr>\n<th>第几次重试</th>\n<th>与上次重试的间隔时间</th>\n<th>第几次重试</th>\n<th>与上次重试的间隔时间</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td>10 秒</td>\n<td>9</td>\n<td>7 分钟</td>\n</tr>\n<tr>\n<td>2</td>\n<td>30 秒</td>\n<td>10</td>\n<td>8 分钟</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1 分钟</td>\n<td>11</td>\n<td>9 分钟</td>\n</tr>\n<tr>\n<td>4</td>\n<td>2 分钟</td>\n<td>12</td>\n<td>10 分钟</td>\n</tr>\n<tr>\n<td>5</td>\n<td>3 分钟</td>\n<td>13</td>\n<td>20 分钟</td>\n</tr>\n<tr>\n<td>6</td>\n<td>4 分钟</td>\n<td>14</td>\n<td>30 分钟</td>\n</tr>\n<tr>\n<td>7</td>\n<td>5 分钟</td>\n<td>15</td>\n<td>1 小时</td>\n</tr>\n<tr>\n<td>8</td>\n<td>6 分钟</td>\n<td>16</td>\n<td>2 小时</td>\n</tr>\n</tbody>\n</table>\n<figure><img src=\"https://www.javayong.cn/pics/temp//a4AW6Gxhxm.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>开源 RocketMQ 4.X 支持延迟消息，默认支持18 个 level 的延迟消息，这是通过 broker 端的 messageDelayLevel 配置项确定的，如下：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//JcmLurnXsq.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>Broker 在启动时，内部会创建一个内部主题：SCHEDULE_TOPIC_XXXX，根据延迟 level 的个数，创建对应数量的队列，也就是说18个 level 对应了18个队列。</p>\n<p>我们先梳理下延迟消息的实现机制。</p>\n<p><strong>1、生产者发送延迟消息</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>2、Broker端存储延迟消息</strong></p>\n<p>延迟消息在 RocketMQ Broker 端的流转如下图所示：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//JLBtkWlUdG.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>第一步：修改消息 Topic 名称和队列信息</strong></p>\n<p>Broker 端接收到生产者的写入消息请求后，首先都会将消息写到 commitlog 中。假如是正常非延迟消息，MessageStore 会根据消息中的 Topic 信息和队列信息，将其转发到目标 Topic 的指定队列 consumequeue 中。</p>\n<p>但由于消息一旦存储到 consumequeue 中，消费者就能消费到，而延迟消息不能被立即消费，所以 RocketMQ 将 Topic 的名称修改为SCHEDULE_TOPIC_XXXX，并根据延迟级别确定要投递到哪个队列下。</p>\n<p>同时，还会将消息原来要发送到的目标 Topic 和队列信息存储到消息的属性中。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//s4kZohhZun.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>第二步：构建 consumequeue 文件时，计算并存储投递时间</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//LgKhMaqAvc.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://www.javayong.cn/pics/temp//NfFXmlG1DS.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>上图是 consumequeue 文件一条消息的格式，最后 8 个字节存储 Tag 的哈希值，此时存储消息的投递时间。</p>\n<p><strong>第三步：定时调度服务启动</strong></p>\n<p>ScheduleMessageService 类是一个定时调度服务，读取 SCHEDULE_TOPIC_XXXX 队列的消息，并将消息投递到目标 Topic 中。</p>\n<p>定时调度服务启动时，创建一个定时调度线程池 ，并根据延迟级别的个数，启动对应数量的 HandlePutResultTask ，每个 HandlePutResultTask 负责一个延迟级别的消费与投递。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//ywsgDHPRc2.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>第四步：投递时间到了，将消息数据重新写入到 commitlog</strong></p>\n<p>消息到期后，需要投递到目标 Topic 。第一步已经记录了原来的 Topic 和队列信息，这里需要重新设置，再存储到 commitlog 中。</p>\n<p><strong>第五步：将消息投递到目标 Topic 中</strong></p>\n<p>Broker 端的后台服务线程会不停地分发请求并异步构建 consumequeue（消费文件）和 indexfile（索引文件）。因此消息会直接投递到目标 Topic 的 consumequeue 中，之后消费者就可以消费到这条消息。</p>\n<hr>\n<p>回顾了延迟消息的机制，消费消息失败后，消费者实例会通过 <strong>CONSUMER_SEND_MSG_BACK</strong> 请求，将失败消息发回到 Broker 端。</p>\n<p>Broker 端 SendMessageProcessor 处理器会调用 asyncConsumerSendMsgBack 方法。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//zdjbfFwN0S.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>首先判断消息的当前重试次数是否大于等于最大重试次数，如果达到最大重试次数，或者配置的重试级别小于0，则重新创建 Topic ，规则是 <strong>%DLQ% + consumerGroup</strong>，后续处理消息发送到死信队列。</p>\n<p>正常的消息会进入 else 分支，对于首次重试的消息，默认的 delayLevel 是 0 ，RocketMQ 会将 delayLevel + 3，也就是加到 3 ，这就是说，如果没有显示的配置延时级别，消息消费重试首次，是延迟了第三个级别发起的重试，也就是距离首次发送 10s 后重试，其主题的默认规则是 <strong>%RETRY% + consumerGroup</strong>。</p>\n<p>当延时级别设置完成，刷新消息的重试次数为当前次数加 1 ，Broker 端将该消息刷盘，逻辑如下：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//E3CYBrG5AY.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>延迟消息写入到 commitlog 里 ，这里其实和延迟消息机制的第一步类似，后面按照延迟消息机制的流程执行即可（第二步到第六步）。</p>\n<h2> 9 总结</h2>\n<p>下图展示了集群模式下消费者并发消费流程 ：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//ASwgqxnuB7.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>核心流程如下：</p>\n<ol>\n<li>\n<p>消费者启动后，触发负载均衡服务 ，负载均衡服务为消费者实例分配对应的队列 ；</p>\n</li>\n<li>\n<p>分配完队列后，负载均衡服务会为每个分配的新队列创建一个消息拉取请求 <code>pullRequest</code> , 拉取请求保存一个处理队列 <code>processQueue</code>，内部是红黑树（<code>TreeMap</code>），用来保存拉取到的消息 ；</p>\n</li>\n<li>\n<p>拉取消息服务单线程从拉取请求队列 <code>pullRequestQueue</code> 中弹出拉取消息，执行拉取任务 ，拉取请求是异步回调模式，将拉取到的消息放入到处理队列；</p>\n</li>\n<li>\n<p>拉取请求在一次拉取消息完成之后会复用，重新被放入拉取请求队列 <code>pullRequestQueue</code> 中 ；</p>\n</li>\n<li>\n<p>拉取完成后，调用消费消息服务 <code>consumeMessageService</code> 的 <code>submitConsumeRequest</code> 方法 ，消费消息服务内部有一个消费线程池；</p>\n</li>\n<li>\n<p>消费线程池的消费线程从消费任务队列中获取消费请求，执行消费监听器 <code>listener.consumeMessage</code> ；</p>\n</li>\n<li>\n<p>消费完成后，若消费成功，则更新偏移量 <code>updateOffset</code>，先更新到内存 <code>offsetTable</code>，定时上报到 Broker ；若消费失败，则将失败消费发送到 Broker 。</p>\n</li>\n<li>\n<p>Broker 端接收到请求后， 调用消费进度管理器的 <code>commitOffset</code> 方法修改内存的消费进度，定时刷盘到 <code>consumerOffset.json</code>。</p>\n</li>\n</ol>\n<p>RocketMQ 4.9.X 的消费逻辑有两个非常明显的特点：</p>\n<ol>\n<li>\n<p><strong>客户端代码逻辑较重</strong>。假如要支持一种新的编程语言，那么客户端就必须实现完整的负载均衡逻辑，此外还需要实现拉消息、位点管理、消费失败后将消息发回 Broker 重试等逻辑。这给多语言客户端的支持造成很大的阻碍。</p>\n</li>\n<li>\n<p><strong>保证幂等非常重要</strong>。当客户端升级或者下线时，或者 Broker 宕机，都要进行负载均衡操作，可能造成消息堆积，同时有一定几率造成重复消费。</p>\n</li>\n</ol>\n",
      "image": "https://www.javayong.cn/pics/temp//qaRc3GjFlL.webp!large",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-17T08:13:01.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 广播消费",
      "url": "https://javayong.cn/mq/rocketmq4/07RocketMQ4_broadcast_consumer.html",
      "id": "https://javayong.cn/mq/rocketmq4/07RocketMQ4_broadcast_consumer.html",
      "summary": "这篇文章我们聊聊广播消费，因为广播消费在某些场景下真的有奇效。笔者会从基础概念、实现机制、实战案例三个方面一一展开，希望能帮助到大家。 1 基础概念 RocketMQ 支持两种消息模式：集群消费（ Clustering ）和广播消费（ Broadcasting ）。 集群消费： 同一 Topic 下的一条消息只会被同一消费组中的一个消费者消费。也就是说，消息被负载均衡到了同一个消费组的多个消费者实例上。",
      "content_html": "<p>这篇文章我们聊聊广播消费，因为广播消费在某些场景下真的有奇效。笔者会从<strong>基础概念</strong>、<strong>实现机制</strong>、<strong>实战案例</strong>三个方面一一展开，希望能帮助到大家。</p>\n<h1> 1 基础概念</h1>\n<p>RocketMQ 支持两种消息模式：<code>集群消费</code>（ Clustering ）和<code>广播消费</code>（ Broadcasting ）。</p>\n<p><strong>集群消费</strong>：</p>\n<p>同一 Topic 下的一条消息只会被同一消费组中的一个消费者消费。也就是说，消息被负载均衡到了同一个消费组的多个消费者实例上。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/cluster.png?a=1\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>广播消费</strong>：</p>\n<p>当使用广播消费模式时，每条消息推送给集群内所有的消费者，保证消息至少被每个消费者消费一次。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/broadcast.png?b=3\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h1> 2 源码解析</h1>\n<p>首先下图展示了广播消费的代码示例。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>和集群消费不同的点在于下面的代码：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>接下来，我们从源码角度来看看广播消费和集群消费有哪些差异点 ？</p>\n<p>首先进入 <code>DefaultMQPushConsumerImpl</code> 类的 <code>start</code> 方法 , 分析启动流程中他们两者的差异点：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/pushconsumerstart.png?a=341\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>▍ 差异点1：拷贝订阅关系</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>在集群模式下，会自动订阅重试队列，而广播模式下，并没有这段代码。也就是说<strong>广播模式下，不支持消息重试</strong>。</p>\n<p><strong>▍ 差异点2：本地进度存储</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>我们可以看到消费进度存储的对象是： <code>LocalFileOffsetStore</code> , 进度文件存储在如下的主目录<code> /{用户主目录}/.rocketmq_offsets</code>。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>进度文件是 <code>/mqClientId/{consumerGroupName}/offsets.json</code> 。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>笔者创建了一个主题 <code>mytest</code> , 包含4个队列，进度文件内容如下：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/broadcastoffset.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费者启动后，我们可以将整个流程简化如下图，并继续整理差异点：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/consumerbroadcastliucheng.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>▍ 差异点3：负载均衡消费该主题的所有 MessageQueue</strong></p>\n<p>进入负载均衡抽象类 <code>RebalanceImpl</code> 的<code>rebalanceByTopic</code>方法 。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>从上面代码我们可以看到消息模式为广播消费模式时，消费者会消费该主题下所有的队列，这一点也可以从本地的进度文件 <code>offsets.json</code> 得到印证。</p>\n<p><strong>▍ 差异点4：不支持顺序消息</strong></p>\n<p>我们知道<strong>消费消息顺序服务会向 Borker 申请锁</strong> 。消费者根据分配的队列 messageQueue ，向 Borker 申请锁 ，如果申请成功，则会拉取消息，如果失败，则定时任务每隔 20 秒会重新尝试。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>但是从上面的代码，我们发现只有在集群消费的时候才会定时申请锁，这样就会导致广播消费时，无法为负载均衡的队列申请锁，导致拉取消息服务一直无法获取消息数据。</p>\n<p>笔者修改消费例子，在消息模式为广播模式的场景下，将消费模式从并发消费修改为顺序消费。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><figure><img src=\"https://javayong.cn/pics/rocketmq/broadcastcantorder.gif\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>通过 IDEA DEBUG 图，笔者观察到因为负载均衡后的队列无法获取到锁，所以拉取消息的线程无法发起拉取消息请求到 Broker , 也就不会走到消费消息的流程。</p>\n<p>因此，<strong>广播消费模式并不支持顺序消息</strong>。</p>\n<p><strong>▍ 差异点5：并发消费消费失败时，没有重试</strong></p>\n<p>进入并发消息消费类<code>ConsumeMessageConcurrentlyService</code> 的处理消费结果方法 <code>processConsumeResult</code>。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>消费消息失败后，集群消费时，消费者实例会通过 <strong>CONSUMER_SEND_MSG_BACK</strong> 请求，将失败消息发回到 Broker 端。</p>\n<p>但在广播模式下，仅仅是打印了消息信息。因此，<strong>广播模式下，并没有消息重试</strong>。</p>\n<h1> 3 实战案例</h1>\n<p>广播消费主要用于两种场景：<strong>消息推送</strong>和<strong>缓存同步</strong>。</p>\n<h2> 3.1 消息推送</h2>\n<p>笔者第一次接触广播消费的业务场景是神州专车司机端的消息推送。</p>\n<p>用户下单之后，订单系统生成专车订单，派单系统会根据相关算法将订单派给某司机，司机端就会收到派单推送。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/drivercarpush.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>推送服务是一个 TCP 服务（自定义协议），同时也是一个消费者服务，消息模式是广播消费。</p>\n<p>司机打开司机端 APP 后，APP 会通过负载均衡和推送服务创建长连接，推送服务会保存 TCP 连接引用 （比如司机编号和 TCP channel 的引用）。</p>\n<p>派单服务是生产者，将派单数据发送到 MetaQ ,  每个推送服务都会消费到该消息，推送服务判断本地内存中是否存在该司机的 TCP channel ， 若存在，则通过 TCP 连接将数据推送给司机端。</p>\n<p>肯定有同学会问：假如网络原因，推送失败怎么处理 ？有两个要点：</p>\n<ol>\n<li>\n<p>司机端 APP 定时主动拉取派单信息；</p>\n</li>\n<li>\n<p>当推送服务没有收到司机端的 ACK 时 ，也会一定时限内再次推送，达到阈值后，不再推送。</p>\n</li>\n</ol>\n<h2> 3.2 缓存同步</h2>\n<p>高并发场景下，很多应用使用本地缓存，提升系统性能 。</p>\n<p>本地缓存可以是 HashMap 、ConcurrentHashMap ，也可以是缓存框架 Guava Cache 或者 Caffeine cache 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/broadcastcachepush.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>如上图，应用A启动后，作为一个 RocketMQ 消费者，消息模式设置为广播消费。为了提升接口性能，每个应用节点都会将字典表加载到本地缓存里。</p>\n<p>当字典表数据变更时，可以通过业务系统发送一条消息到 RocketMQ ，每个应用节点都会消费消息，刷新本地缓存。</p>\n<h1> 4 总结</h1>\n<p>集群消费和广播消费模式下，各功能的支持情况如下：</p>\n<table>\n<thead>\n<tr>\n<th>功能</th>\n<th>集群消费</th>\n<th>广播消费</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>顺序消息</td>\n<td>支持</td>\n<td>不支持</td>\n</tr>\n<tr>\n<td>重置消费位点</td>\n<td>支持</td>\n<td>不支持</td>\n</tr>\n<tr>\n<td>消息重试</td>\n<td>支持</td>\n<td>不支持</td>\n</tr>\n<tr>\n<td>消费进度</td>\n<td>服务端维护</td>\n<td>客户端维护</td>\n</tr>\n</tbody>\n</table>\n<br>\n<p>广播消费主要用于两种场景：<strong>消息推送</strong>和<strong>缓存同步</strong>。</p>\n<hr>\n<p>参考资料 ：</p>\n<blockquote>\n<p>https://www.51cto.com/article/714277.html</p>\n<p>https://ost.51cto.com/posts/21100</p>\n</blockquote>\n<hr>\n<p>如果我的文章对你有所帮助，还请帮忙<strong>点赞、在看、转发</strong>一下，你的支持会激励我输出更高质量的文章，非常感谢！</p>\n<figure><img src=\"https://javayong.cn/pics/zhihu/gongzhonghao.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n",
      "image": "https://javayong.cn/pics/rocketmq/cluster.png?a=1",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-16T07:55:06.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 主从同步",
      "url": "https://javayong.cn/mq/rocketmq4/08RocketMQ4_masterslave.html",
      "id": "https://javayong.cn/mq/rocketmq4/08RocketMQ4_masterslave.html",
      "summary": "RocketMQ 主从复制是 RocketMQ 高可用机制之一，数据可以从主节点复制到一个或多个从节点。 这篇文章，我们聊聊 RocketMQ 的主从复制，希望大家读完之后，能够理解主从复制的精髓。 1 同步与异步 在 RocketMQ 的集群模式中，Broker 分为 Master 与 Slave，一个 Master 可以对应多个 Slave，但是一个 Slave 只能对应一个 Master。",
      "content_html": "<p>RocketMQ 主从复制是 RocketMQ 高可用机制之一，数据可以从主节点复制到一个或多个从节点。</p>\n<p>这篇文章，我们聊聊 RocketMQ 的主从复制，希望大家读完之后，能够理解主从复制的精髓。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//NlcPeBacCl.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 同步与异步</h2>\n<p>在 RocketMQ 的集群模式中，Broker 分为 Master 与 Slave，一个 Master 可以对应多个 Slave，但是一个 Slave 只能对应一个 Master。</p>\n<p>每个 Broker 与 Name Server 集群中的所有节点建立长连接，定时注册 Topic 信息到所有 Name Server。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//XYRrSnhfuT-20231117160830289.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>Master 节点负责接收客户端的写入请求，并将消息持久化到磁盘上。而 Slave 节点则负责从 Master 节点复制消息数据，并保持与 Master 节点的同步。</p>\n<p><strong>1、同步复制</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//9OihpRQCeY.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>每个 Master 配置一个 Slave ，有多对 Master-Slave ，HA 采用同步双写方式，即只有主备都写成功，才向应用返回成功。</p>\n<p>这种模式的优缺点如下：</p>\n<ul>\n<li>\n<p>优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；</p>\n</li>\n<li>\n<p>缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的 RT 会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。</p>\n</li>\n</ul>\n<p><strong>2、异步复制</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//aeuWWwwVF6.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>每个 Master 配置一个 Slave ，有多对 Master-Slave ，HA 采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下：</p>\n<ul>\n<li>\n<p>优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多 Master 模式几乎一样；</p>\n</li>\n<li>\n<p>缺点：Master 宕机，磁盘损坏情况下会丢失少量消息 。</p>\n</li>\n</ul>\n<p>复制流程分为两个部分：<strong>元数据复制</strong>和<strong>消息数据复制</strong>。</p>\n<ul>\n<li>主从服务器同步主题，消费者进度，延迟消费进度，消费者配置数据</li>\n<li>主从服务器同步消息数据</li>\n</ul>\n<h2> 2 元数据复制</h2>\n<p>Slave Broker 定时任务每隔 10 秒会同步元数据，包括<strong>主题</strong>，<strong>消费进度</strong>，<strong>延迟消费进度</strong>，<strong>消费者配置</strong>。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//UlZOjOQHKC.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>同步主题时, Slave Broker 向 Master Broker 发送 RPC 请求，返回数据后，首先加入本地缓存里，然后持久化到本地。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//同步rpc.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 3 消息数据复制</h2>\n<p>下图是 Master 和 Slave 消息数据同步的流程图。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//消息数据复制.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>1、Master 启动后监听指定端口；</strong></p>\n<p>Master 启动后创建 AcceptSocketService 服务  ,  用来创建客户端到服务端的 TCP 链接。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//master监听端口.webp\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>RocketMQ 抽象了链接对象 HAConnection , HAConnection 会启动两个线程，分别用于读服务和写服务：</p>\n<ul>\n<li>读服务：处理 Slave 发送的请求</li>\n<li>写服务：用于向 Slave 传输数据</li>\n</ul>\n<figure><img src=\"https://www.javayong.cn/pics/temp//L9VeTg1Q1b.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>2、Slave 启动后，尝试连接 Master ，建立 TCP 连接；</strong></p>\n<p>HAClient 是客户端 Slave 的核心类 ，负责和 Master 创建连接和数据交互。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//FdlRK75VMA.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>客户端在启动后，首先尝试连接 Master , 查询当前消息存储中最大的物理偏移量 ，并存储在变量 currentReportedOffset 里。</p>\n<p><strong>3、Slave 向 Master 汇报拉取消息偏移量；</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//tT8zDrnRDf.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>上报进度的数据格式是一个 Long 类型的 Offset ,  8个字节 ,  非常简洁 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//jTVTgyPKmh.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>发送到 Socket 缓冲区后 ,  修改最后一次的写时间 lastWriteTimestamp 。</p>\n<p><strong>4、Master 解析请求偏移量，从消息文件中检索该偏移量后的所有消息；</strong></p>\n<p>当 Slave 上报数据到 Master 时，<strong>触发 SelectionKey.OP_READ 事件</strong>，Master 将请求交由 ReadSocketService 服务处理：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//Q1VaKEvY5a.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>当 Slave Broker 传递了自身 commitlog 的 maxPhyOffset 时，Master 会马上中断 <code>selector.select(1000) </code>，执行 <code>processReadEvent</code> 方法。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//p6dZ2wKxCi.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>processReadEvent 方法的核心逻辑是设置 Slave 的当前进度 offset ，然后通知复制线程当前的复制进度。</p>\n<p>写服务 WriteSocketService 从消息文件中检索该偏移量后的所有消息（传输批次数据大小限制），并将消息数据发送给 Slave。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//V6JxwPbZYw.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong>5、Slave 接收到数据，将消息数据 append 到消息文件 commitlog 里 。</strong></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//zSWojrUdMO.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>首先 HAClient 类中调用 dispatchReadRequest 方法 ， 解析出消息数据 ；</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//hso6cZvs8w.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>然后将消息数据 append 到本地的消息存储。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//Lp9XW6snxn.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 4 同步的实现</h2>\n<p>从数据复制流程图，我们发觉数据复制本身就是一个异步执行的，但是同步是如何实现的呢？</p>\n<p>Master Broker 接收到写入消息的请求后 ，调用 Commitlog 的 aysncPutMessage 方法写入消息。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//sBPU66GFD1.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>这段代码中，当 commitLog 执行完 appendMessage 后， 需要执行<strong>刷盘任务</strong>和<strong>同步复制</strong>两个任务。</p>\n<p>但这两个任务并不是同步执行，而是异步的方式，<strong>使用了 CompletableFuture 这个异步神器</strong>。</p>\n<p>当 HAConnection 读服务接收到 Slave 的进度反馈，发现消息数据复制成功，则唤醒 future 。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//uATvF8ZCew.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>最后 Broker 组装响应命令 ，并将响应命令返回给客户端。</p>\n<h2> 5 总结</h2>\n<p>RocketMQ 主从复制的实现思路非常简单，Slave 启动一个线程，不断从 Master 拉取 Commit Log 中的数据，然后在异步 build 出 Consume Queue 数据结构。</p>\n<p>核心要点如下：</p>\n<p><strong>1、主从复制包含元数据复制和消息数据复制两个部分；</strong></p>\n<p><strong>2、元数据复制</strong></p>\n<p>​\t  Slave Broker 定时任务每隔 10 秒向 Master Broker 发送 RPC 请求，将元数据同步到缓存后，然后持久化到磁盘里；</p>\n<p><strong>3、消息数据复制</strong></p>\n<ol>\n<li>\n<p>Master 启动监听指定端口</p>\n</li>\n<li>\n<p>Slave  启动 HaClient 服务，和 Master 创建 TCP 链接</p>\n</li>\n<li>\n<p>Slave 向 Master 上报存储进度</p>\n</li>\n<li>\n<p>Master 接收进度，消息文件中检索该偏移量后的所有消息，并传输给 Slave</p>\n</li>\n<li>\n<p>Slave 接收到数据后，将消息数据 append 到本地的消息存储。</p>\n</li>\n</ol>\n<p><strong>4、同步的实现</strong></p>\n<p>​\t当 commitLog 执行完 appendMessage 后， 需要执行<strong>刷盘任务</strong>和<strong>同步复制</strong>两个任务，这里用到了 CompletableFuture 这个异步神器。\n​\t当 HAConnection 读服务接收到 Slave 的进度反馈，发现消息数据复制成功，则唤醒 future 。最后 Broker 组装响应命令 ，并将响应命令\t返回给客户端 。</p>\n",
      "image": "https://www.javayong.cn/pics/temp//NlcPeBacCl.png",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-17T08:13:01.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 事务原理",
      "url": "https://javayong.cn/mq/rocketmq4/10RocketMQ4_transaction.html",
      "id": "https://javayong.cn/mq/rocketmq4/10RocketMQ4_transaction.html",
      "summary": "事务消息是 RocketMQ 的高级特性之一，相信很多同学都对于其实现机制很好奇。 这篇文章，笔者会从应用场景、功能原理、实战例子、实现细节四个模块慢慢为你揭开事务消息的神秘面纱。",
      "content_html": "<p>事务消息是 RocketMQ 的高级特性之一，相信很多同学都对于其实现机制很好奇。</p>\n<p>这篇文章，笔者会从<strong>应用场景</strong>、<strong>功能原理</strong>、<strong>实战例子</strong>、<strong>实现细节</strong>四个模块慢慢为你揭开事务消息的神秘面纱。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/rocketmqcategory.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h2> 1 应用场景</h2>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionchangjing.png?d=14\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>以电商交易场景为例，<strong>用户支付订单</strong>这一核心操作的同时会涉及到下游物流发货、积分变更、购物车状态清空等多个子系统的变更。</p>\n<p>当前业务的处理分支包括：</p>\n<ul>\n<li>主分支订单系统状态更新：由未支付变更为支付成功。</li>\n<li>物流系统状态新增：新增待发货物流记录，创建订单物流记录。</li>\n<li>积分系统状态变更：变更用户积分，更新用户积分表。</li>\n<li>购物车系统状态变更：清空购物车，更新用户购物车记录。</li>\n</ul>\n<p><strong>1、传统XA事务方案：性能不足</strong></p>\n<p>为了保证上述四个分支的执行结果一致性，典型方案是基于 XA 协议的分布式事务系统来实现。将四个调用分支封装成包含四个独立事务分支的大事务。基于 XA 分布式事务的方案可以满足业务处理结果的正确性，但最大的缺点是多分支环境下资源锁定范围大，并发度低，随着下游分支的增加，系统性能会越来越差。</p>\n<p><strong>2、基于普通消息方案：一致性保障困难</strong></p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionnormalmessage.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>该方案中消息下游分支和订单系统变更的主分支很容易出现不一致的现象，例如：</p>\n<ul>\n<li>消息发送成功，订单没有执行成功，需要回滚整个事务。</li>\n<li>订单执行成功，消息没有发送成功，需要额外补偿才能发现不一致。</li>\n<li>消息发送超时未知，此时无法判断需要回滚订单还是提交订单变更。</li>\n</ul>\n<p><strong>3、基于 RocketMQ 分布式事务消息：支持最终一致性</strong></p>\n<p>上述普通消息方案中，普通消息和订单事务无法保证一致的原因，本质上是由于普通消息无法像单机数据库事务一样，具备提交、回滚和统一协调的能力。</p>\n<p>而基于 RocketMQ 实现的分布式事务消息功能，在普通消息基础上，支持二阶段的提交能力。将二阶段提交和本地事务绑定，实现全局提交结果的一致性。</p>\n<h2> 2 功能原理</h2>\n<p>RocketMQ 事务消息是支持在分布式场景下<strong>保障消息生产和本地事务的最终一致性</strong>。交互流程如下图所示：</p>\n<figure><img src=\"https://www.javayong.cn/pics/rocketmq/transactionyuanli.png?a\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>1、生产者将消息发送至 Broker 。</p>\n<p>2、Broker 将消息持久化成功之后，向生产者返回 Ack 确认消息已经发送成功，此时消息被标记为\"<strong>暂不能投递</strong>\"，这种状态下的消息即为<strong>半事务消息</strong>。</p>\n<p>3、生产者开始<strong>执行本地事务逻辑</strong>。</p>\n<p>4、生产者根据本地事务执行结果向服务端<strong>提交二次确认结果</strong>（ Commit 或是 Rollback ），Broker 收到确认结果后处理逻辑如下：</p>\n<ul>\n<li>二次确认结果为 Commit ：Broker 将半事务消息标记为可投递，并投递给消费者。</li>\n<li>二次确认结果为 Rollback ：Broker 将回滚事务，不会将半事务消息投递给消费者。</li>\n</ul>\n<p>5、在断网或者是生产者应用重启的特殊情况下，若 Broker 未收到发送者提交的二次确认结果，或 Broker 收到的二次确认结果为 Unknown 未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起<strong>消息回查</strong>。</p>\n<ol>\n<li>生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li>\n<li>生产者根据检查到的本地事务的最终状态<strong>再次提交二次确认</strong>，服务端仍按照步骤4对半事务消息进行处理。</li>\n</ol>\n<h2> 3 实战例子</h2>\n<p>为了便于大家理解事务消息 ，笔者新建一个工程用于模拟<strong>支付订单创建</strong>、<strong>支付成功</strong>、<strong>赠送积分</strong>的流程。</p>\n<p>首先，我们创建一个真实的订单主题：<strong>order-topic</strong> 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactiontopic.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>然后在数据库中创建三张表 <strong>订单表</strong>、<strong>事务日志表</strong>、<strong>积分表</strong>。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactiondemotables.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>最后我们创建一个 Demo 工程，生产者模块用于创建支付订单、修改支付订单成功，消费者模块用于新增积分记录。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionprojectdemo.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>接下来，我们展示事务消息的实现流程。</p>\n<p><strong style=\"font-size: 15px;line-height: inherit;color: black;\">1、创建支付订单</strong></p>\n<p>调用订单生产者服务创建订单接口 ，在 t_order 表中插入一条支付订单记录。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactioncreateorder.png?\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p><strong style=\"font-size: 15px;line-height: inherit;color: black;\">2、调用生产者服务修改订单状态接口</strong></p>\n<p>接口的逻辑就是执行事务生产者的 <code> sendMessageInTransaction</code>  方法。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionupdatepayordersuccess.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>生产者端需要配置<strong>事务生产者</strong>和<strong>事务监听器</strong>。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionrocketmqconfig.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>发送事务消息的方法内部包含三个步骤 ：</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionupdateorderliucheng.png?a\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>事务生产者首先<strong>发送半事务消息</strong>，发送成功后，生产者才开始<strong>执行本地事务逻辑</strong>。</p>\n<p>事务监听器实现了两个功能：<strong>执行本地事务</strong>和<strong>供 Broker 回查事务状态</strong> 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionlistenerimpl.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>执行本地事务的逻辑内部就是执行<code> orderService.updateOrder</code> 方法。</p>\n<p>方法执行成功则返回 <code>LocalTransactionState.COMMIT_MESSAGE</code> , 若执行失败则返回 <code> LocalTransactionState.ROLLBACK_MESSAGE</code> 。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionupdateorder.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>需要注意的是：<code> orderService.updateOrder</code> 方法添加了事务注解，并将修改订单状态和插入事务日志表放进一个事务内，避免订单状态和事务日志表的数据不一致。</p>\n<p>最后，生产者根据本地事务执行结果向 Broker <strong>提交二次确认结果</strong>。</p>\n<p>Broker 收到生产者确认结果后处理逻辑如下：</p>\n<ul>\n<li>二次确认结果为 Commit ：Broker 将半事务消息标记为可投递，并投递给消费者。</li>\n<li>二次确认结果为 Rollback ：Broker 将回滚事务，不会将半事务消息投递给消费者。</li>\n</ul>\n<p><strong style=\"font-size: 15px;line-height: inherit;color: black;\">3、积分消费者消费消息，添加积分记录</strong></p>\n<p>当 Broker 将半事务消息标记为可投递时，积分消费者就可以开始消费主题 order-topic 的消息了。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionconsumerconfig.png?a=1\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>积分消费者服务，我们定义了<strong>消费者组名</strong>，以及<strong>订阅主题</strong>和<strong>消费监听器</strong>。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionconsumerjifen.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>在消费监听器逻辑里，<code>幂等非常重要</code> 。当收到订单信息后，首先判断该订单是否有积分记录，若没有记录，才插入积分记录。</p>\n<p>而且我们在创建积分表时，订单编号也是唯一键，数据库中也必然不会存在相同订单的多条积分记录。</p>\n<h2> 4 实现细节</h2>\n<p><strong style=\"font-size: 16px;line-height: inherit;color: black;\">1、事务 half 消息对用户不可见</strong></p>\n<p>下图展示了 RocketMQ 的存储模型，RocketMQ 采用的是混合型的存储结构，Broker 单个实例下所有的队列共用一个日志数据文件（即为 CommitLog ）来存储。</p>\n<p>消息数据写入到 commitLog 后，通过分发线程异步构建 ConsumeQueue（逻辑消费队列）和 IndexFile（索引文件）数据。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/rocketmqstoredemo.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>Broker 在接受到发送消息请求后，如果消息是 half 消息，先备份原消息的主题与消息消费队列，然后改变主题为 <code>RMQ_SYS_TRANS_HALF_TOPIC</code> 。</p>\n<p>而该主题并不被消费者订阅，所以对于消费者是不可见的。</p>\n<p>然后 RocketMQ 会开启一个定时任务，从 Topic 为 <code>RMQ_SYS_TRANS_HALF_TOPIC</code> 中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。</p>\n<blockquote>\n<p>改变消息主题是 RocketMQ 的常用“套路”，延时消息的实现机制也是如此。</p>\n</blockquote>\n<p><strong style=\"font-size: 16px;line-height: inherit;color: black;\">2、Commit 和 Rollback 操作</strong></p>\n<p>RocketMQ 事务消息方案中引入了 <strong>Op 消息</strong>的概念，用 Op 消息标识事务消息已经确定的状态（ Commit 或者 Rollback ）, Op 消息对应的主题是： <code>RMQ_SYS_TRANS_OP_HALF_TOPIC</code>  。</p>\n<p>如果一条事务消息没有对应的 Op 消息，说明这个事务的状态还无法确定（可能是二阶段失败了）。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/endtransactionopmessage.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>引入 Op 消息后，事务消息无论是 Commit 或者 Rollback 都会记录一个 Op 操作。</p>\n<ul>\n<li>\n<p><strong>Commit</strong></p>\n<p>Broker 写入 OP 消息，OP 消息的 body 指定 Commit 消息的 queueOffset，标记之前 Half 消息已被删除；同时，Broker 读取原 Half 消息，把 Topic 还原，重新写入 CommitLog，消费者则可以拉取消费；</p>\n</li>\n<li>\n<p><strong>Rollback</strong></p>\n<p>Broker 同样写入 OP 消息，流程和 Commit 一样。但后续不会读取和还原 Half 消息。这样消费者就不会消费到该消息。</p>\n</li>\n</ul>\n<p><strong style=\"font-size: 16px;line-height: inherit;color: black;\">3、事务消息状态回查</strong></p>\n<p>若生产者根据本地事务执行结果向 Broker <strong>提交二次确认结果</strong>时，出现网络问题导致提交失败，那么需要通过一定的策略使这条消息最终被 Commit 或者 Rollback 。</p>\n<p>Broker 采用了一种补偿机制，称为“状态回查”。</p>\n<p>Broker 端对未确定状态的消息发起回查，将消息发送到对应的 Producer 端（同一个 Group 的 Producer ），由 Producer 根据消息来检查本地事务的状态，进而执行 Commit 或者 Rollback 。</p>\n<p>Broker 端通过对比 Half 消息和 Op 消息进行事务消息的回查并且推进 CheckPoint（记录那些事务消息的状态是确定的）。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/transactionbrokerchecklogic.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>事务消息 check 流程扫描当前的 OP 消息队列，读取已经被标记删除的 Half 消息的 queueOffset 。如果发现某个 Half 消息没有 OP 消息对应标记，并且已经超时（ transactionTimeOut 默认 6 秒），则读取该 Half 消息重新写入 half 队列，并且发送 check 命令到原发送方检查事务状态；如果没有超时，则会等待后读取 OP 消息队列，获取新的 OP 消息。</p>\n<p>值得注意的是，Broker 并不会无休止的的信息事务状态回查，默认回查15次，如果15次回查还是无法得知事务状态，Broker 默认回滚该消息。</p>\n<h2> 5 总结</h2>\n<p>我们理解了事务消息的原理，编写一个实战例子并不复杂。</p>\n<p>笔者需要强调的是，事务消息也具备一定的局限性：</p>\n<p>1、事务生产者和消费者共同协作才能保证最终一致性；</p>\n<p>2、事务生产者需要实现事务监听器，并且保存事务的执行结果（比如事务日志表） ；</p>\n<p>3、消费者要保证幂等。消费失败时，通过<strong>重试</strong>、<strong>告警+人工介入</strong>等手段保证消费结果正确。</p>\n<p>同时，由于事务消息的机制原因，我们在使用 RocketMQ 事务功能时，也需要注意如下两点：</p>\n<p>1、避免大量未决事务导致超时</p>\n<p>Broker 在事务提交阶段异常的情况下会发起事务回查，从而保证事务一致性。但生产者应该尽量避免本地事务返回未知结果，大量的事务检查会导致系统性能受损，容易导致事务处理延迟。</p>\n<p>2、事务超时机制</p>\n<p>半事务消息被生产者发送 Broker 后，如果在指定时间内服务端无法确认提交或者回滚状态，则消息默认会被回滚。</p>\n<hr>\n<p>实战代码地址：</p>\n<blockquote>\n<p>https://github.com/makemyownlife/rocketmq4-learning</p>\n</blockquote>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/rocketmq4-learning.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>参考资料：</p>\n<blockquote>\n<p>阿里云云栖号：https://zhuanlan.zhihu.com/p/554481474</p>\n</blockquote>\n",
      "image": "https://javayong.cn/pics/rocketmq/rocketmqcategory.png",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-16T13:37:25.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 消息轨迹",
      "url": "https://javayong.cn/mq/rocketmq4/11RocketMQ4_messagetrack.html",
      "id": "https://javayong.cn/mq/rocketmq4/11RocketMQ4_messagetrack.html",
      "summary": "这篇文章，我们聊一聊 RocketMQ 的消息轨迹设计思路。 查询消息轨迹可作为生产环境中排查问题强有力的数据支持 ，也是研发同学解决线上问题的重要武器之一。 1 基础概念 消息轨迹是指一条消息从生产者发送到 Broker , 再到消费者消费，整个过程中的各个相关节点的时间、状态等数据汇聚而成的完整链路信息。",
      "content_html": "<p>这篇文章，我们聊一聊 RocketMQ 的<strong>消息轨迹</strong>设计思路。</p>\n<p>查询消息轨迹可作为生产环境中排查问题强有力的数据支持 ，也是研发同学解决线上问题的重要武器之一。</p>\n<h1> 1 基础概念</h1>\n<p>消息轨迹是指一条消息从生产者发送到 Broker , 再到消费者消费，整个过程中的各个相关节点的时间、状态等数据汇聚而成的完整链路信息。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/rocketmqtrack.png?a=1\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>当我们需要查询消息轨迹时，需要明白一点：<strong>消息轨迹数据是存储在 Broker 服务端，我们需要定义一个主题，在生产者，消费者端定义轨迹钩子</strong>。</p>\n<h1> 2 开启轨迹</h1>\n<h2> 2.1 修改 Broker 配置文件</h2>\n<div class=\"language-properties line-numbers-mode\" data-ext=\"properties\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> 2.2 生产者配置</h2>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>在生产者的构造函数里，有两个核心参数：</p>\n<ul>\n<li><strong>enableMsgTrace</strong>：是否开启消息轨迹</li>\n<li><strong>customizedTraceTopic</strong>：记录消息轨迹的 Topic  , 默认是：<code> RMQ_SYS_TRACE_TOPIC</code> 。</li>\n</ul>\n<p>执行如下的生产者代码：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><blockquote>\n<p>在生产者代码中，我们指定了消息的 key 属性， 便于对于消息进行高性能检索。</p>\n</blockquote>\n<p>执行成功之后，我们从控制台查看轨迹信息。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/dashboardtrack.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/traceproducer.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>从图中可以看到，消息轨迹中存储了消息的<code> 存储时间</code> 、<code> 存储服务器IP</code>  、<code>发送耗时</code> 。</p>\n<h2> 2.3 消费者配置</h2>\n<p>和生产者类似，消费者的构造函数可以传递轨迹参数：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>执行如下的消费者代码：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><figure><img src=\"https://javayong.cn/pics/rocketmq/consumertrack.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h1> 3 实现原理</h1>\n<p>轨迹的实现原理主要是在生产者发送、消费者消费时添加相关的钩子。 因此，我们只需要了解钩子的实现逻辑即可。</p>\n<p>下面的代码是 <code>DefaultMQProducer </code> 的构造函数。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>当是否<strong>开启轨迹开关</strong>打开时，创建<strong>异步轨迹分发器</strong> <code>AsyncTraceDispatcher</code> ，然后给默认的生产者实现类在发送消息的钩子 <code>SendMessageTraceHookImpl</code>。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>我们把生产者发送消息的流程简化如下代码 ：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>进入<code>SendMessageTraceHookImpl</code> 类 ，该类主要有两个方法 <code>sendMessageBefore</code> 和 <code> sendMessageAfter</code> 。</p>\n<p><strong>1、sendMessageBefore 方法</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>发送消息之前，先收集消息的 topic 、tag、key 、存储 Broker 的 IP 地址、消息体的长度等基础信息，并将消息轨迹数据存储在调用上下文中。</p>\n<p><strong>2、sendMessageAfter 方法</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>跟踪对象里会保存 <code>costTime</code> (消息发送时间)、<code>success</code> （是否发送成功）、<code>regionId</code> (发送到 Broker 所在的分区) 、 <code>msgId</code> (消息 ID，全局唯一)、<code>offsetMsgId</code> (消息物理偏移量) ，<code>storeTime</code> (存储时间 ) 。</p>\n<blockquote>\n<p>存储时间并没有取消息的实际存储时间，而是估算出来的：客户端发送时间的一般的耗时表示消息的存储时间。</p>\n</blockquote>\n<p>最后将跟踪上下文添加到本地轨迹分发器：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>下面我们分析下轨迹分发器的原理：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>上面的代码展示了分发器的构造函数和启动方法，构造函数创建了一个发送消息的线程池 <code>traceExecutor</code> ，启动 start 后会启动一个 <code>worker线程</code>。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>worker 启动后，会从轨迹上下文队列 traceContextQueue 中不断的取出轨迹上下文，并将上下文转换成轨迹数据片段  <code>TraceDataSegment </code>。</p>\n<p>为了提升系统的性能，并不是每一次从队列中获取到数据就直接发送到 MQ ，而是积累到一定程度的临界点才触发这个操作，我们可以简单的理解为<strong>批量操作</strong>。</p>\n<p>这里面有两个维度 :</p>\n<ol>\n<li>\n<p>轨迹数据片段的数据大小大于某个数据大小阈值。笔者认为这段 RocketMQ 4.9.4 版本代码存疑，因为最新的 5.0 版本做了优化。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></li>\n<li>\n<p>当前时间 - 轨迹数据片段的首次存储时间 是否大于刷新时间 ，也就是每500毫秒刷新一次。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></li>\n</ol>\n<p>轨迹数据存储的格式如下：</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>下图展示了事务轨迹消息数据，每个数据字段是按照 <code>CONTENT_SPLITOR</code> 分隔。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/tracedatademo.png\" alt=\"轨迹消息数据\" tabindex=\"0\"><figcaption>轨迹消息数据</figcaption></figure>\n<blockquote>\n<p>注意：</p>\n<p>分隔符  CONTENT_SPLITOR  = (char) 1  它在内存中的值是：00000001 , 但是 char i = '1' 它在内存中的值是 49 ，即 00110001。</p>\n</blockquote>\n<hr>\n<p>参考资料：</p>\n<blockquote>\n<p>阿里云文档：</p>\n<p>https://help.aliyun.com/zh/apsaramq-for-rocketmq/cloud-message-queue-rocketmq-4-x-series/user-guide/query-a-message-trace</p>\n<p>石臻臻:</p>\n<p>https://mp.weixin.qq.com/s/saYD3mG9F1z-oAU6STxewQ</p>\n</blockquote>\n",
      "image": "https://javayong.cn/pics/rocketmq/rocketmqtrack.png?a=1",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-16T07:55:06.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 消息堆积",
      "url": "https://javayong.cn/mq/rocketmq4/12RocketMQ4_messagecumulate.html",
      "id": "https://javayong.cn/mq/rocketmq4/12RocketMQ4_messagecumulate.html",
      "summary": "很多同学都在使用 RocketMQ 时，经常会遇到消息堆积的问题。这篇文章，我们聊聊消息堆积的概念，以及如何应对消息堆积。 1 基础概念 消费者在消费的过程中，消费的速度跟不上服务端的发送速度，未处理的消息会越来越多，消息出现堆积进而会造成消息消费延迟。 虽然笔者经常讲：RocketMQ 、Kafka 具备堆积的能力，但是以下场景需要重点关注消息堆积和延迟的问题：",
      "content_html": "<p>很多同学都在使用 RocketMQ 时，经常会遇到消息堆积的问题。这篇文章，我们聊聊消息堆积的概念，以及如何应对消息堆积。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/messageduiji.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<h1> 1 基础概念</h1>\n<p>消费者在消费的过程中，消费的速度跟不上服务端的发送速度，未处理的消息会越来越多，消息出现堆积进而会造成消息消费延迟。</p>\n<p>虽然笔者经常讲：RocketMQ 、Kafka 具备堆积的能力，但是以下场景需要重点关注消息堆积和延迟的问题：</p>\n<ol>\n<li>\n<p>业务系统上下游能力不匹配造成的持续堆积，且无法自行恢复。</p>\n</li>\n<li>\n<p>业务系统对消息的消费实时性要求较高，即使是短暂的堆积造成的消息延迟也无法接受。</p>\n</li>\n</ol>\n<h1> 2 消费原理</h1>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/pullmessageandconsume.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>客户端使用 <code>Push 模式 </code>启动后，消费消息时，分为以下两个阶段：</p>\n<ul>\n<li>\n<p>阶段一：<strong>拉取消息</strong></p>\n<p>客户端通过长轮询批量拉取的方式从 Broker 服务端获取消息，将拉取到的消息缓存到本地缓冲队列中。</p>\n<p>客户端批量拉取消息，常见内网环境下都会有很高的吞吐量，例如：1个单线程单分区的低规格机器（4C8GB）可以达到几万 TPS ，如果是多个分区可以达到几十万 TPS 。所以这一阶段一般不会成为消息堆积的瓶颈。</p>\n</li>\n<li>\n<p>阶段二：<strong>消费消息</strong></p>\n<p>提交消费线程，客户端将本地缓存的消息提交到消费线程中，使用业务消费逻辑进行处理。</p>\n<p>此时客户端的消费能力就完全依赖于业务逻辑的复杂度（<strong>消费耗时</strong>）和消费逻辑<strong>并发度</strong>了。如果业务处理逻辑复杂，处理单条消息耗时都较长，则整体的消息吞吐量肯定不会高，此时就会导致客户端本地缓冲队列达到上限，停止从服务端拉取消息。</p>\n</li>\n</ul>\n<p>通过以上客户端消费原理可以看出，消息堆积的主要瓶颈在于本地客户端的消费能力，即<strong>消费耗时</strong>和<strong>消费并发度</strong>。</p>\n<p>想要避免和解决消息堆积问题，必须合理的控制消费耗时和消息并发度，其中消费耗时的优先级高于消费并发度，必须先保证消费耗时的合理性，再考虑消费并发度问题。</p>\n<h1> 3 消费瓶颈</h1>\n<h2> 3.1 消费耗时</h2>\n<p>影响消费耗时的消费逻辑主要分为 CPU 内存计算和外部 I/O 操作，通常情况下代码中如果没有复杂的递归和循环的话，内部计算耗时相对外部 I/O 操作来说几乎可以忽略。</p>\n<p>外部 I/O 操作通常包括如下业务逻辑：</p>\n<ul>\n<li>读写外部数据库，例如 MySQL 数据库读写。</li>\n<li>读写外部缓存等系统，例如 Redis 读写。</li>\n<li>下游系统调用，例如 Dubbo 调用或者下游 HTTP 接口调用。</li>\n</ul>\n<p>这类外部调用的逻辑和系统容量需要提前梳理，掌握每个调用操作预期的耗时，这样才能判断消费逻辑中I/O操作的耗时是否合理。</p>\n<p>通常消费堆积都是由于这些下游系统出现了服务异常、容量限制导致的消费耗时增加。</p>\n<p>例如：某业务消费逻辑中需要调用下游 Dubbo 接口 ，单次消费耗时为 20 ms，平时消息量小未出现异常。业务侧进行大促活动时，下游 Dubbo 服务未进行优化，消费单条消息的耗时增加到 200 ms，业务侧可以明显感受到消费速度大幅下跌。此时，通过提升消费并行度并不能解决问题，需要大幅提高下游 Dubbo 服务性能才行。</p>\n<h2> 3.2 消费并发度</h2>\n<p>绝大部分消息消费行为都属于 IO 密集型，即可能是操作数据库，或者调用 RPC，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。</p>\n<p>所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法：</p>\n<ul>\n<li>同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。</li>\n<li>提高单个 Consumer 实例的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax 实现。</li>\n</ul>\n<h1> 4 解决策略</h1>\n<p>当面对消息堆积问题时，我们需要明确到底哪个环节出现问题了，不要慌张，也不要贸然动手。</p>\n<h2> 4.1 确认消息的消费耗时是否合理</h2>\n<p>首先，我们需要查看<strong>消费耗时</strong>，确认消息的消费耗时是否合理。查看消费耗时一般来讲有两种方式：</p>\n<p><strong>1、打印日志</strong></p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p><strong>2、查看消息轨迹</strong></p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/consumertrackcosttime.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>当确定好消费耗时后，可以根据耗时大小，采取不同的措施。</p>\n<ul>\n<li>若查看到消费耗时较长，则需要查看客户端堆栈信息排查具体业务逻辑，需查看客户端 JVM 的堆栈 。</li>\n<li>若查看到消费耗时正常，则有可能是因为消费并发度不够导致消息堆积，需要逐步调大消费线程或扩容节点来解决。</li>\n</ul>\n<h2> 4.2 查看客户端 JVM 的堆栈</h2>\n<p><strong>假如消费耗时非常高，需要查看 Consumer 实例 JVM 的堆栈 。</strong></p>\n<ol>\n<li>\n<p>通过 <code>jps -m</code> 或者 <code>ps -ef | grep java</code> 命令获取当前正在运行的 Java 程序，通过启动主类即可获得应用的进程 pid ;</p>\n</li>\n<li>\n<p>通过 <code>jstack pid &gt; stack.log</code> 命令获取线程的堆栈。</p>\n</li>\n<li>\n<p>执行以下命令，查看 <code>ConsumeMessageThread</code> 的信息 。</p>\n</li>\n</ol>\n<div class=\"language-bash line-numbers-mode\" data-ext=\"sh\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>常见的异常堆栈信息如下：</p>\n<ul>\n<li>\n<p>示例1：<strong>空闲无堆积的堆栈</strong> 。</p>\n<p>消费空闲情况下消费线程都会处于 <code>WAITING</code> 状态等待从消费任务队里中获取消息。</p>\n</li>\n</ul>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/waiting.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ul>\n<li>\n<p>示例2：<strong>消费逻辑有抢锁休眠等待等情况</strong> 。</p>\n<p>消费线程阻塞在内部的一个睡眠等待上，导致消费缓慢。</p>\n</li>\n</ul>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/time_waiting.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ul>\n<li>\n<p>示例3：<strong>消费逻辑操作数据库等外部存储卡住</strong> 。</p>\n<p>消费线程阻塞在外部的 HTTP 调用上，导致消费缓慢。</p>\n<figure><img src=\"https://javayong.cn/pics/rocketmq/runnable.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n</li>\n</ul>\n<h1> 5 总结</h1>\n<p>客户端使用 <code>Push模式 </code>启动后，消费消息时，分为以下两个阶段：<strong>拉取消息</strong>和<strong>消费消息</strong>。</p>\n<p>客户端消费原理可以看出，消息堆积的主要瓶颈在于本地客户端的消费能力，即<strong>消费耗时</strong>和<strong>消费并发度</strong>。</p>\n<p>当遇到堆积问题，首先分析消费耗时，然后根据耗时大小，采取不同的措施。</p>\n<ul>\n<li>若查看到消费耗时较长，则需要查看客户端堆栈信息排查具体业务逻辑，需查看客户端 JVM 的堆栈 。</li>\n<li>若查看到消费耗时正常，则有可能是因为消费并发度不够导致消息堆积，需要逐步调大消费线程或扩容节点来解决。</li>\n</ul>\n<hr>\n<p>参考文档：</p>\n<blockquote>\n<p>万字长文讲透RocketMQ 消费逻辑：</p>\n<p>https://mp.weixin.qq.com/s/mlqhXCHfhEht7je8n0rArA</p>\n<p>阿里云官方文档：</p>\n<p>https://help.aliyun.com/zh/apsaramq-for-rocketmq/cloud-message-queue-rocketmq-4-x-series/use-cases/message-accumulation-and-latency#concept-2004064</p>\n</blockquote>\n",
      "image": "https://javayong.cn/pics/rocketmq/messageduiji.png",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-16T07:55:06.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "RocketMQ 订阅关系保持一致",
      "url": "https://javayong.cn/mq/rocketmq4/13RocketMQ4_subscribe_consistent.html",
      "id": "https://javayong.cn/mq/rocketmq4/13RocketMQ4_subscribe_consistent.html",
      "summary": "这篇文章，笔者想聊聊 RocketMQ 最佳实践之一：保证订阅关系一致。 订阅关系一致指的是同一个消费者 Group ID 下所有 Consumer 实例所订阅的 Topic 、Tag 必须完全一致。 如果订阅关系不一致，消息消费的逻辑就会混乱，甚至导致消息丢失。 1 订阅关系演示 首先我们展示正确的订阅关系：多个 Group ID 订阅了多个 Topic，并且每个 Group ID 里的多个消费者的订阅关系保持了一致。 正确的订阅关系",
      "content_html": "<p>这篇文章，笔者想聊聊 RocketMQ 最佳实践之一：<strong>保证订阅关系一致</strong>。</p>\n<p>订阅关系一致指的是同一个消费者 Group ID 下所有 Consumer 实例所订阅的 Topic 、Tag 必须完全一致。</p>\n<p>如果订阅关系不一致，消息消费的逻辑就会混乱，甚至导致消息丢失。</p>\n<h2> 1 订阅关系演示</h2>\n<p>首先我们展示正确的订阅关系：多个 Group ID 订阅了多个 Topic，并且每个 Group ID 里的多个消费者的订阅关系保持了一致。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//5rMR9gIPHK.png\" alt=\"正确的订阅关系\" tabindex=\"0\"><figcaption>正确的订阅关系</figcaption></figure>\n<p>接下来，我们展示错误的订阅关系。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//YlPFIv5qG4.png\" alt=\"错误的订阅关系\" tabindex=\"0\"><figcaption>错误的订阅关系</figcaption></figure>\n<p>从上图中，单个 Group ID 订阅了多个 Topic，但是该 Group ID 里的多个消费者的订阅关系并没有保持一致。</p>\n<p>代码逻辑角度来看，<strong>每个消费者实例内订阅方法的主题、 TAG、监听逻辑都需要保持一致</strong>。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//yXSu2AdWE0.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>接下来，我们实验相同消费组，两种不正确的场景，看看消费者和 Broker 服务有什么异常。</p>\n<ul>\n<li>订阅主题不同，标签相同</li>\n<li>订阅主题相同，标签不同</li>\n</ul>\n<h2> 2 订阅主题不同，标签相同</h2>\n<figure><img src=\"https://www.javayong.cn/pics/temp//p149T2PspM.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>当我们启动两个消费者后，消费者组名：<code>myconsumerGroup</code>。C1消费者订阅主题 <code>TopicTest</code> , C2消费者订阅主题 <code>mytest</code>。</p>\n<p>在 Broker 端的日志里，会不停的打印拉取消息失败的日志 ：</p>\n<div class=\"language-bash line-numbers-mode\" data-ext=\"sh\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>那么在这种情况下，C1 消费者是不可能拉取到消息，也就不可能消费到最新的消息。</p>\n<p>为什么呢 ？ 我们知道客户端会定时的发送心跳包到 Broker 服务，心跳包中会包含<strong>消费者订阅信息</strong>，数据格式样例如下：</p>\n<div class=\"language-bash line-numbers-mode\" data-ext=\"sh\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>Broker 服务会调用 <code>ClientManageProcessor</code> 的 <code>heartBeat</code>方法处理心跳请求。</p>\n<p>最终跟踪到代码： <code>org.apache.rocketmq.broker.client.ConsumerManager#registerConsumer</code></p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//jeyu9ERNJh.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>Broker 服务的会保存消费者信息，消费者信息存储在消费者表 <code>consumerTable</code> 。消费者表以消费组名为 key , 值为消费者组信息 <code>ConsumerGroupInfo</code> 。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>如果消费组的消费者信息 ConsumerGroupInfo 为空，则新建新的对象。</p>\n<p>更新订阅信息时，订阅信息是按照消费组存放的，这步骤就会导致同一个消费组内的各个消费者客户端的订阅信息相互被覆盖。</p>\n<p>回到消费者客户端，当消费者拉取消息时，Broker 服务会调用 <code>PullMessageProcessor</code> 的 <code>processRequest </code>方法 。</p>\n<p>首先会进行前置判断，查询当前的主题的订阅信息若该主题的订阅信息为空，则打印告警日志，并返回异常的响应结果。</p>\n<div class=\"language-java line-numbers-mode\" data-ext=\"java\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>通过调研 Broker 端的代码，我们发现：<strong>相同消费组的订阅信息必须保持一致 , 否则同一个消费组内的各个消费者客户端的订阅信息相互被覆盖，从而导致某个消费者客户端无法拉取到新的消息</strong>。</p>\n<p>C1消费者无法消费主题 <code>TopicTest</code> 的消息数据，那么 C2 消费者订阅主题 <code>mytest</code>，消费会正常吗 ？</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//ayW5Bjyplu.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>从上图来看，依然有问题。 主题 mytest 有四个队列，但只有两个队列被分配了， 另外两个队列的消息就没有办法消费了。</p>\n<p>要解释这个问题，我们需要重新温习<strong>负载均衡</strong>的原理。</p>\n<hr>\n<p>负载均衡服务会根据消费模式为”广播模式”还是“集群模式”做不同的逻辑处理，这里主要来看下集群模式下的主要处理流程：</p>\n<p>(1) 获取该主题下的消息消费队列集合；</p>\n<p>(2) 查询 Broker 端获取该消费组下消费者 Id 列表；</p>\n<p>(3) 先对 Topic 下的消息消费队列、消费者 Id 排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列；</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//iYLyVcUAt4-20231117160818531.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>这里的平均分配算法，类似于分页的算法，将所有 MessageQueue 排好序类似于记录，将所有消费端排好序类似页数，并求出每一页需要包含的平均 size 和每个页面记录的范围 range ，最后遍历整个 range 而计算出当前消费端应该分配到的记录。</p>\n<p>(4) 分配到的消息队列集合与 processQueueTable 做一个过滤比对操作。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//xs0dDuzfwc-20231117160818528.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>消费者实例内 ，processQueueTable 对象存储着当前负载均衡的队列 ，以及该队列的处理队列 processQueue (消费快照)。</p>\n<ol>\n<li>\n<p>标红的 Entry 部分表示与分配到的消息队列集合互不包含，则需要将这些红色队列 Dropped 属性为 true , 然后从 processQueueTable 对象中移除。</p>\n</li>\n<li>\n<p>绿色的 Entry 部分表示与分配到的消息队列集合的交集，processQueueTable 对象中已经存在该队列。</p>\n</li>\n<li>\n<p>黄色的 Entry 部分表示这些队列需要添加到 processQueueTable 对象中，为每个分配的新队列创建一个消息拉取请求 <code>pullRequest</code> , 在消息拉取请求中保存一个处理队列 <code>processQueue</code> （队列消费快照），内部是红黑树（<code>TreeMap</code>），用来保存拉取到的消息。</p>\n</li>\n</ol>\n<p>最后创建拉取消息请求列表，并<strong>将请求分发到消息拉取服务，进入拉取消息环节</strong>。</p>\n<hr>\n<p>通过上面的介绍 ，通过负载均衡的原理推导，原因就显而易见了。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//UFkBIMqRuE.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>C1消费者被分配了队列 0、队列 1 ，但是 C1消费者本身并没有订阅主题 mytest , 所以无法消费该主题的数据。</p>\n<p>从本次实验来看，C1消费者无法消费主题 <code>TopicTest</code> 的消息数据 , C2 消费者只能部分消费主题 <code>mytest</code>的消息数据。</p>\n<p>但是因为在 Broker 端，同一个消费组内的各个消费者客户端的订阅信息相互被覆盖，所以这种消费状态非常混乱，偶尔也会切换成：C1消费者可以部分消费主题 <code>TopicTest</code> 的消息数据 , C2消费者无法消费主题 <code>mytest</code>的消息数据。</p>\n<h2> 3 订阅主题相同，标签不同</h2>\n<figure><img src=\"https://www.javayong.cn/pics/temp//MLEOohsjbL.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>如图，C1 消费者和 C2 消费者订阅主题 <code>TopicTest</code> ，但两者的标签 TAG 并不相同。</p>\n<p>启动消费者服务之后，从控制台观察，负载均衡的效果也如预期一般正常。</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//kGvVrHStP7.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>笔者在 Broker 端打印埋点日志，发现主题 <code>TopicTest</code> 的订阅信息为 ：</p>\n<div class=\"language-json line-numbers-mode\" data-ext=\"json\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>那么这种状态，消费正常吗 ？笔者做了一组实验，消费依然混乱：</p>\n<p><strong>C1 消费者无法消费 TAG 值为 A 的消息 ，C2 消费者只能消费部分 TAG 值为 B 的消息。</strong></p>\n<p>想要理解原因，我们需要梳理消息过滤机制。</p>\n<p>首先 ConsumeQueue 文件的格式如下 ：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//o4BiIVsDSs-20231117160818552.webp!large\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<ol>\n<li>Broker 端在接收到拉取请求后，根据请求参数定位 ConsumeQueue 文件，然后遍历 ConsumeQueue 待检索的条目， 判断条目中存储 Tag 的 hashcode 是否和订阅信息中 TAG 的 hashcode 是否相同，若不符合，则跳过，继续对比下一个， 符合条件的聚合后返回给消费者客户端。</li>\n<li>消费者在收到过滤后的消息后，也要执行过滤机制，只不过过滤的是 TAG 字符串的值，而不是 hashcode 。</li>\n</ol>\n<p>我们模拟下消息过滤的过程：</p>\n<figure><img src=\"https://www.javayong.cn/pics/temp//aGylJz255T.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n<p>首先，生产者将不同的消息发送到 Broker 端，不同的 TAG 的消息会发送到保存的不同的队列中。</p>\n<p>C1 消费者从队列 0 ，队列 1 中拉取消息时，因为 Broker 端该主题的订阅信息中 TAG 值为 B ，经过服务端过滤后， C1 消费者拉取到的消息的 TAG 值都是 B  , 但消费者在收到过滤的消息后，也需要进行客户端过滤，A 并不等于 B ，所以 C1 消费者无法消费 TAG 值为 A 的消息。</p>\n<p>C2 消费者从队列 2， 队列 3 中拉取消息，整个逻辑链路是正常的 ，但是因为负载均衡的缘故，它无法消费队列 0 ，队列 1的消息。</p>\n<h2> 4 总结</h2>\n<p>什么是消费组 ？消费同一类消息且消费逻辑一致 。</p>\n<p><strong>RocketMQ 4.X 源码实现就是为了和消费组的定义保持一致</strong> ，假如订阅关系不一致，那么代码执行逻辑就会出现混乱。</p>\n<p>规避订阅关系不一致这个问题有两种方式:</p>\n<ul>\n<li><strong>合理定义好主题和标签</strong></li>\n</ul>\n<p>当我们定义好主题和标签后，需要添加新的标签时，是否可以换一个思路：换一个新的消费组或者新建一个主题。</p>\n<ul>\n<li><strong>严格规范上线流程</strong></li>\n</ul>\n<p>在上线之前，梳理好相关依赖服务，梳理好上线流程，做好上线评审，并严格按照流程执行。</p>\n<p>最后的思考：</p>\n<p>假如从基础架构层面来思考，将订阅关系信息中心化来设计，应该也可以实现 ，但成本较高，对于中小企业来讲，并不合算。</p>\n<hr>\n<p>参考资料：</p>\n<blockquote>\n<p>RocketMQ为什么要保证订阅关系的一致性 :</p>\n<p>https://cloud.tencent.com/developer/article/1474885</p>\n<p>RocketMQ最佳实践之坑？</p>\n<p>https://mp.weixin.qq.com/s/Ypk-U8uVu4aZKMinbfU3xQ</p>\n<p>源码分析RocketMQ消息过滤机制</p>\n<p>https://blog.csdn.net/prestigeding/article/details/79255328</p>\n</blockquote>\n",
      "image": "https://www.javayong.cn/pics/temp//5rMR9gIPHK.png",
      "date_published": "2023-11-16T02:18:17.000Z",
      "date_modified": "2023-11-17T08:13:01.000Z",
      "authors": [],
      "tags": [
        "RocketMQ"
      ]
    },
    {
      "title": "阅读目录",
      "url": "https://javayong.cn/home.html",
      "id": "https://javayong.cn/home.html",
      "summary": "缓存实战 聊聊本地缓存和分布式缓存 四种强大的JDK本地缓存 聊聊分页列表缓存 详解布隆过滤器 聊聊Redis事务 品味SpringCache设计之美",
      "content_html": "<hr>\n<h2> 缓存实战</h2>\n<ul>\n<li><a href=\"/cache/00localandclustercache.html\" target=\"blank\">聊聊本地缓存和分布式缓存</a></li>\n<li><a href=\"/cache/01fourJDKlocalcache.html\" target=\"blank\">四种强大的JDK本地缓存</a></li>\n<li><a href=\"/cache/02pagelistcache.html\" target=\"blank\">聊聊分页列表缓存</a></li>\n<li><a href=\"/cache/05boolfilter.html\" target=\"blank\">详解布隆过滤器</a></li>\n<li><a href=\"/cache/07Redistransaction.html\" target=\"blank\">聊聊Redis事务</a></li>\n<li><a href=\"/cache/09SpringCache.html\" target=\"blank\">品味SpringCache设计之美</a></li>\n</ul>\n<h2> 消息队列</h2>\n<h3> RocketMQ4.X设计精要</h3>\n<ul>\n<li><a href=\"/mq/rocketmq4/00RocketMQ4_introduce.html\" target=\"blank\">序言</a></li>\n<li><a href=\"/mq/rocketmq4/01RocketMQ4_artch.html\" target=\"blank\">RocketMQ整体架构</a></li>\n<li><a href=\"/mq/rocketmq4/01RocketMQ4_network.html\" target=\"blank\">RocketMQ网络通讯</a></li>\n<li><a href=\"/mq/rocketmq4/02RocketMQ4_nameserver.html\" target=\"blank\">RocketMQ名字服务</a></li>\n<li><a href=\"/mq/rocketmq4/03RocketMQ4_producer.html\" target=\"blank\">RocketMQ生产者</a></li>\n<li><a href=\"/mq/rocketmq4/04RocketMQ4_store.html\" target=\"blank\">RocketMQ存储模型</a></li>\n<li><a href=\"/mq/rocketmq4/06RocketMQ4_consumer.html\" target=\"blank\">RocketMQ消费者</a></li>\n<li><a href=\"/mq/rocketmq4/07RocketMQ4_broadcast_consumer.html\" target=\"blank\">RocketMQ广播消费</a></li>\n<li><a href=\"/mq/rocketmq4/08RocketMQ4_masterslave.html\" target=\"blank\">RocketMQ主从同步</a></li>\n<li><a href=\"/mq/rocketmq4/10RocketMQ4_transaction.html\" target=\"blank\">RocketMQ事务原理</a></li>\n<li><a href=\"/mq/rocketmq4/11RocketMQ4_messagetrack.html\" target=\"blank\">RocketMQ消息轨迹</a></li>\n<li><a href=\"/mq/rocketmq4/13RocketMQ4_subscribe_consistent.html\" target=\"blank\">RocketMQ订阅关系保证一致</a></li>\n</ul>\n<h2> 公众号</h2>\n<p>如果大家想要实时关注我更新的文章以及分享的干货的话，可以关注我的公众号“<strong>勇哥java实战分享</strong>”。</p>\n<figure><img src=\"https://javayong.cn/pics/shipinhao/gongzhonghaonew.png\" alt=\"\" tabindex=\"0\"><figcaption></figcaption></figure>\n",
      "image": "https://javayong.cn/pics/shipinhao/gongzhonghaonew.png",
      "date_published": "2023-06-29T07:18:23.000Z",
      "date_modified": "2023-11-17T13:49:18.000Z",
      "authors": [],
      "tags": []
    }
  ]
}